{"cells":[{"cell_type":"markdown","id":"hcsKVBPS1Ruj","metadata":{"id":"hcsKVBPS1Ruj"},"source":["\n","## Part 0: Prerequisites:\n","\n","\n"]},{"cell_type":"code","execution_count":null,"id":"34L2uh7E1P75","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":37057,"status":"ok","timestamp":1651011075958,"user":{"displayName":"Haydar Mehryar","userId":"09990703679773155769"},"user_tz":240},"id":"34L2uh7E1P75","outputId":"6ca0e65b-7fce-407d-d5bc-96b8723d92d9"},"outputs":[{"ename":"","evalue":"","output_type":"error","traceback":["\u001b[1;31mFailed to start the Kernel. \n","Unable to start Kernel 'tensorflow_gpuenv_v2 (Python 3.7.7)' due to connection timeout. \n","View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."]}],"source":["import sys\n","# sys.stdout = open(\"output.txt\", \"w\")\n","\n","print('Loading/Installing Package => Begin\\n\\n')\n","# Commonly used modules\n","import numpy as np\n","import os\n","from os import path, makedirs\n","import time\n","from time import time\n","import subprocess\n","\n","\n","def install(package):\n","  print(\"Installing \"+package) \n","  subprocess.check_call([sys.executable,\"-m\" ,\"pip\", \"install\", package])\n","  print(\"Installed \"+package+\"\\n\") \n","\n","\n","\n","# Images, plots, display, and visualization\n","import matplotlib.cm as cm\n","import matplotlib.pyplot as plt\n","import pandas as pd\n","\n","#reading/writing into files\n","# !pip3 install pickle5\n","install(\"pickle5\")\n","import pickle5 as pickle\n","\n","print('\\n########################################################################')\n","print('Checking the running platforms\\n')\n","import platform\n","running_os=platform.system()\n","print(\"OS: \"+running_os)\n","print(\"OS version: \"+platform.release())\n","\n","try:\n","  from google.colab import drive\n","  COLAB = True\n","except:\n","  COLAB = False\n","print(\"running on Colab: \"+str(COLAB))\n","\n","# if 'google.colab' in str(get_ipython()):\n","#   print('Running on CoLab')\n","#   install(\"google.colab\")\n","#   from google.colab import drive\n","#   drive.mount('/content/drive')\n","# else:\n","#   print('Not running on CoLab')\n","\n","\n","print(\"Python version: \"+platform.python_version())\n","\n","\n","dataset_directory_path=''\n","simulation_directory_path=''\n","\n","if COLAB == True:\n","  drive.mount('/content/drive')\n","  dataset_directory_path='/content/drive/MyDrive/Projects/110_JetscapeMl/hm.jetscapeml.data/'\n","  simulation_directory_path=dataset_directory_path+'simulation_results/'\n","elif 'Linux' in running_os:\n","  dataset_directory_path='/wsu/home/gy/gy40/gy4065/hm.jetscapeml.data/'\n","  simulation_directory_path=dataset_directory_path+'simulation_results/'\n","else:\n","  dataset_directory_path= 'G:\\\\My Drive\\\\Projects\\\\110_JetscapeMl\\\\hm.jetscapeml.data\\\\'\n","  simulation_directory_path=dataset_directory_path+'simulation_results\\\\'\n","print('Dataset Directory Path: '+dataset_directory_path)\n","\n","\n","\n","if not path.exists(simulation_directory_path):\n","    makedirs(simulation_directory_path)\n","print('Simulation Results Path: '+simulation_directory_path)\n","print('########################################################################\\n')\n","\n","\n","print('\\nLoading/Installing Package => End\\n\\n')"]},{"cell_type":"code","execution_count":null,"id":"29370d58","metadata":{},"outputs":[],"source":["class DatasetBuilderSingleFileAnalyzer:\n","   # class attribute\n","  \n","    # Instance attribute\n","    def __init__(self, input_file_name_hadrons,data_size,y_class_label_items,output_dataset_file_name):\n","        self.input_file_name_hadrons=x_train\n","        self.data_size=y_train\n","        self.y_class_label_items=x_test\n","        self.output_dataset_file_name=y_test"]},{"cell_type":"markdown","id":"fdc50e81","metadata":{},"source":["## Part 0: Input Params:"]},{"cell_type":"markdown","id":"645e0a0d","metadata":{},"source":["getting inputs parameters from command line"]},{"cell_type":"code","execution_count":null,"id":"e7b3b682","metadata":{},"outputs":[],"source":["print('########################################################################\\n')\n","print(\"Parsing parameters from command line and initializing the input parameters\")\n","# Python program to demonstrate\n","# command line arguments\n"," \n"," \n","import getopt, sys\n"," \n"," \n","# Remove 1st argument from the\n","# list of command line arguments\n","argumentList = sys.argv[1:]\n"," \n","# Options\n","options = \"hi:d:y:o:n:c:p:\"\n"," \n","# Long options\n","long_options = [\"Help\", \"Input_file_name_hadrons\",\"Data_size\",\"Y_class_label_items\",\"output_dataset_file_name=\", \"number_of_partition\",\"configuration_directory\",\"configuration_number\"]\n"," \n","try:\n","    # Parsing argument\n","    arguments, values = getopt.getopt(argumentList, options, long_options)\n","    print(arguments)\n","    print(values)\n","    # checking each argument\n","    for currentArgument, currentValue in arguments:\n","        print(currentArgument)\n","        if currentArgument in (\"-h\", \"--Help\"):\n","            print (\"Displaying Help\")   \n","        elif currentArgument in (\"-i\", \"--Input_file_name_hadrons\"):\n","            print (\"Input_file_name_hadrons: \", currentValue)\n","            file_name_hadrons=currentValue\n","            print('simulated events final state hadron file: '+file_name_hadrons)\n","        elif currentArgument in (\"-d\", \"--Data_size\"):\n","            print (\"Data_size: \", currentValue) \n","            data_size=int(currentValue)\n","            print('data_size: {} '.format(data_size))\n","        elif currentArgument in (\"-y\", \"--Y_class_label_items\"):\n","            print (\"Y_class_label_items: \", currentValue)\n","            y_class_label_items=[currentValue]     \n","            print(\"y_class_label_items\")\n","            print(y_class_label_items)\n","        elif currentArgument in (\"-o\", \"--output_dataset_file_name\"):\n","            print (\"output_dataset_file_name: \",currentValue)\n","            dataset_file_name=currentValue\n","            print(\"Dataset file name: \"+dataset_file_name)\n","        elif currentArgument in (\"-n\", \"--number_of_partition\"):\n","            print (\"number_of_partition: \",currentValue)\n","            number_of_partition=int(currentValue)\n","            print('Number of partition for splitting the events: {} '.format(number_of_partition))\n","        elif currentArgument in (\"-c\", \"--configuration_directory\"):\n","            print (\"configuration_directory: \",currentValue)\n","            configuration_directory=currentValue\n","            print('Configuration directory: ',configuration_directory)\n","        elif currentArgument in (\"-p\", \"--configuration_number\"):\n","            print (\"configuration_number: \",currentValue)\n","            configuration_number=int(currentValue)\n","            print('Configuration number to reference which dataset it is: {} '.format(configuration_number))\n","except getopt.error as err:\n","    # output error, and return with an error code\n","    print (str(err))\n","print('########################################################################\\n')"]},{"cell_type":"markdown","id":"8879fffb","metadata":{},"source":["##Setting the input parameters in hardcoded"]},{"cell_type":"code","execution_count":null,"id":"deed2c1d","metadata":{},"outputs":[],"source":["# print('########################################################################\\n')\n","\n","# # file_name_matter='finalStateHadrons-Matter.dat'\n","# # file_name_matter='finalStateHadrons-Matter-100k.dat'\n","# file_name_matter='finalStateHadrons-Matter-600k.dat'\n","# # file_name_matter_lbt='finalStateHadrons-MatterLbt.dat'\n","# # file_name_matter_lbt='finalStateHadrons-MatterLbt-100k.dat'\n","# file_name_matter_lbt='finalStateHadrons-MatterLbt-600k.dat'\n","\n","# file_name_hadrons='finalStateHadrons-Matter-1k.dat'\n","# print('simulated events final state hadron file: '+file_name_hadrons)\n","\n","# data_size=1000\n","# print('data_size: {} '.format(data_size))\n","# print\n","# # ['MVAC','MLBT']\n","# y_class_label_items=['MVAC']\n","# print(\"y_class_label_items\")\n","# print(y_class_label_items)\n","\n","# #dataset_file_name='jetscape-ml-benchmark-dataset-2k-randomized.pkl'\n","# # dataset_file_name='jetscape-ml-benchmark-dataset-matter-vs-lbt-2000.pkl'\n","# # dataset_file_name='jetscape-ml-benchmark-dataset-matter-vs-lbt-1200k-momentum.pkl'\n","# dataset_file_name='jetscape-ml-benchmark-dataset-1k-matter.pkl'\n","\n","# print(\"Dataset file name: \"+dataset_file_name)\n","# print('########################################################################\\n')"]},{"cell_type":"markdown","id":"c331c62b","metadata":{},"source":["Loading Events Image Item Chunck Item from Fies and Merge into one file"]},{"cell_type":"code","execution_count":null,"id":"d13e2847","metadata":{},"outputs":[],"source":["def save_dataset(file_name,dataset):\n","    with open(file_name, 'wb') as dataset_file:\n","        pickle.dump(dataset,dataset_file, protocol=pickle.HIGHEST_PROTOCOL)\n","\n","        \n","def load_dataset(file_name):\n","    with open(file_name, 'rb') as dataset_file:\n","        (x_train, y_train), (x_test, y_test) = pickle.load(dataset_file, encoding='latin1')\n","        dataset=((x_train, y_train), (x_test, y_test))\n","        return dataset"]},{"cell_type":"code","execution_count":null,"id":"9d3d7292","metadata":{"id":"9d3d7292"},"outputs":[],"source":["image_grid_count=32\n","def load_and_concatenate_datasets():\n","    print('\\n########################################################################')\n","    print('Loading separate datasets')\n","    y_class_label_items=['MMAT','MLBT']\n","\n","    file_name=\"config-0\"+str(configuration_number)+\"-\"+y_class_label_items[0]+\"-simulationsize\"+str(data_size)+\"-dataset.pkl\"\n","    file_name=simulation_directory_path+file_name\n","    # file_name=y_class_label_items[0]+\"-simulationsize\"+str(data_size)+\"-dataset.pkl\"\n","    # file_name=simulation_directory_path+file_name\n","    ((dataset_mvac_x_train,dataset_mvac_y_train),(dataset_mvac_x_test,dataset_mvac_y_test))= load_dataset(file_name)\n","    print(\"dataset_mvac.x_train:\",type(dataset_mvac_x_train), dataset_mvac_x_train.size, dataset_mvac_x_train.shape)\n","    print(\"dataset_mvac.x_test:\",type(dataset_mvac_x_test), dataset_mvac_x_test.size, dataset_mvac_x_test.shape)\n","    print(\"dataset_mvac.y_train:\",type(dataset_mvac_y_train), dataset_mvac_y_train.size,dataset_mvac_y_train.shape)\n","    print(\"dataset_mvac.y_test:\",type(dataset_mvac_y_test), dataset_mvac_y_test.size, dataset_mvac_y_test.shape)\n","    file_name=\"config-0\"+str(configuration_number)+\"-\"+y_class_label_items[1]+\"-simulationsize\"+str(data_size)+\"-dataset.pkl\"\n","    file_name=simulation_directory_path+file_name\n","    # file_name=y_class_label_items[1]+\"-simulationsize\"+str(data_size)+\"-dataset.pkl\"\n","    # file_name=simulation_directory_path+file_name\n","    ((dataset_mlbt_x_train,dataset_mlbt_y_train),(dataset_mlbt_x_test,dataset_mlbt_y_test))= load_dataset(file_name)\n","    print(\"dataset_mlbt.x_train:\",type(dataset_mlbt_x_train), dataset_mlbt_x_train.size, dataset_mlbt_x_train.shape)\n","    print(\"dataset_mlbt.x_test:\",type(dataset_mlbt_x_test), dataset_mlbt_x_test.size, dataset_mlbt_x_test.shape)\n","    print(\"dataset_mlbt.y_train:\",type(dataset_mlbt_y_train), dataset_mlbt_y_train.size,dataset_mlbt_y_train.shape)\n","    print(\"dataset_mlbt.y_test:\",type(dataset_mlbt_y_test), dataset_mlbt_y_test.size, dataset_mlbt_y_test.shape)\n","\n","    x_train =np.array(np.zeros((1,image_grid_count,image_grid_count))) \n","    x_train=dataset_mvac_x_train\n","    x_train=np.insert(x_train,0,dataset_mlbt_x_train,axis=0)\n","   \n","    \n","    y_train=[]\n","    y_train= np.append (y_train, dataset_mvac_y_train)\n","    y_train= np.append (y_train, dataset_mlbt_y_train)\n","    \n","    x_test =np.array(np.zeros((1,image_grid_count,image_grid_count))) \n","    x_test=dataset_mvac_x_test\n","    x_test=np.insert(x_test,0,dataset_mlbt_x_test,axis=0)\n","   \n","\n","    y_test=[]\n","    y_test= np.append (y_test, dataset_mvac_y_test)\n","    y_test= np.append (y_test, dataset_mlbt_y_test)\n","\n","    print(\"dataset.x_train:\",type(x_train), x_train.size, x_train.shape)\n","    print(\"dataset.x_test:\",type(x_test), x_test.size, x_test.shape)\n","    print(\"dataset.y_train:\",type(y_train), y_train.size,y_train.shape)\n","    print(\"dataset.y_test:\",type(y_test), y_test.size, y_test.shape)\n","    print('\\n########################################################################')\n","    dataset=((x_train,y_train),(x_test,y_test))\n","    return dataset\n","\n","def concatenate_and_store_dataset_into_single_file():\n","    print('\\n########################################################################')\n","    start = time() \n","    dataset=load_and_concatenate_datasets()\n","    print('\\n########################################################################')\n","    print('Saving Constructed Benchmark Dataset as a file')\n","    file_name=\"config-0\"+str(configuration_number)+\"-matter-vs-lbt-simulationsize\"+str(data_size)+\"-dataset-momentum.pkl\"\n","    # file_name=\"jetscape-ml-benchmark-dataset-matter-vs-lbt-1200k-momentum.pkl\"\n","    file_name=simulation_directory_path+file_name\n","    save_dataset(file_name,dataset)\n","    print('\\n########################################################################')\n","    elapsed = time() - start\n","    print('Concatenating and Storing Elapsed %.3f seconds.' % elapsed)\n","    print('\\n########################################################################')\n","\n","concatenate_and_store_dataset_into_single_file()"]},{"cell_type":"code","execution_count":null,"id":"6aff49cb","metadata":{},"outputs":[],"source":["def shuffle_training_dataset(x_train, y_train):\n","  \n","  print(\"Train Dataset Permutation Array:\")\n","  train_permutation_array_indices=np.random.permutation(y_train.size)\n","  #print(train_permutation_array_indices[1:100])\n","\n","  print(\"y_train:\")\n","  print(y_train, type(y_train),y_train.size, y_train.shape)\n","  #print(y_train[1:100])\n","\n","  print(\"y_train_shuffled:\")\n","  y_train_shuffled=np.take(y_train, train_permutation_array_indices)\n","  print(y_train_shuffled, type(y_train_shuffled),y_train_shuffled.size, y_train_shuffled.shape)\n","  #print(y_train_shuffled[1:100])\n","\n","  print(\"x_train:\")\n","  print(x_train, type(x_train),x_train.size, x_train.shape)\n","  #print(x_train[1:100])\n","\n","  print(\"x_train_shuffled:\")\n","  x_train_shuffled=np.take(x_train, train_permutation_array_indices,axis=0)\n","  print(x_train_shuffled, type(x_train_shuffled),x_train_shuffled.size, x_train_shuffled.shape)\n","  #print(x_train_shuffled[1:100])\n","\n","  dataset_train_shuffled=(x_train_shuffled, y_train_shuffled)\n","  return dataset_train_shuffled\n","\n","\n","#main method\n","\n","def shuffle_training_dataset_runner():\n","    print('\\n########################################################################')\n","    start_time = time() \n","\n","    # file_name=\"jetscape-ml-benchmark-dataset-matter-vs-lbt-1200k-momentum.pkl\"\n","    file_name=\"config-0\"+str(configuration_number)+\"-matter-vs-lbt-simulationsize\"+str(data_size)+\"-dataset-momentum.pkl\"\n","    file_name=simulation_directory_path+file_name\n","\n","    print(\"Loading Data Set\")\n","    (x_train, y_train), (x_test, y_test) =load_dataset(file_name)\n","\n","    print(\"Shuffling Data Set\")\n","    (x_train_shuffled, y_train_shuffled)=shuffle_training_dataset(x_train, y_train)\n","\n","    \n","    # file_name=\"jetscape-ml-benchmark-dataset-matter-vs-lbt-1200k-momentum-shuffled.pkl\"\n","    file_name=\"config-0\"+str(configuration_number)+\"-matter-vs-lbt-simulationsize\"+str(data_size)+\"-dataset-momentum-shuffled.pkl\"\n","    file_name=simulation_directory_path+file_name\n","    dataset=((x_train_shuffled,y_train_shuffled),(x_test,y_test))\n","    save_dataset(file_name,dataset)\n","    end_time=time()\n","\n","    print('\\n########################################################################')\n","    elapsed = time() - start_time\n","    print('Shuffling / Storing Elapsed %.3f seconds.' % elapsed)\n","    print('\\n########################################################################')\n","shuffle_training_dataset_runner()"]}],"metadata":{"colab":{"collapsed_sections":[],"name":"jetscape-ml-tensorflow-nn-dataset-builder.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3.7.6 ('tensorflow_env')","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.6 (default, Jan  8 2020, 19:59:22) \n[GCC 7.3.0]"},"vscode":{"interpreter":{"hash":"ada828d16365d2b22d3899327f52f8feba3feb56b4fde7279c1cd0b9201605e0"}}},"nbformat":4,"nbformat_minor":5}
