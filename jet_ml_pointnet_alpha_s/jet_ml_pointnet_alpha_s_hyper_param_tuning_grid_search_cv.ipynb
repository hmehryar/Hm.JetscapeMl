{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install --upgrade tensorflow\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #uncomment this cell when you are on COLAB\n",
    "# device_name = tf.test.gpu_device_name()\n",
    "# if device_name != '/device:GPU:0':\n",
    "#   raise SystemError('GPU device not found')\n",
    "# print('Found GPU at: {}'.format(device_name))\n",
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(1,'/wsu/home/gy/gy40/gy4065/hm.jetscapeml.source')\n",
    "sys.path.insert(1,'/content/drive/My Drive/Projects/110_JetscapeMl/hm.jetscapeml.source')\n",
    "sys.path.insert(1,'/content/drive/MyDrive/Projects/110_JetscapeMl/hm.jetscapeml.source')\n",
    "sys.path.insert(1,'/g/My Drive/Projects/110_JetscapeMl/hm.jetscapeml.source')\n",
    "sys.path.insert(1,'G:\\\\My Drive\\\\Projects\\\\110_JetscapeMl\\\\hm.jetscapeml.source')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "########################################################################\n",
      "Checking the running platforms and setting the directory path\n",
      "\n",
      "Python version: 3.11.5\n",
      "OS: Windows\n",
      "OS version: 10\n",
      "running on Colab: False\n",
      "Dataset Directory Path: D:\\Projects\\110_JetscapeMl\\hm.jetscapeml.data\\\n",
      "Simulation Results Path: D:\\Projects\\110_JetscapeMl\\hm.jetscapeml.data\\simulation_results\\\n",
      "########################################################################\n",
      "\n",
      "Aggregatring all parameters values\n",
      "label_items:\n",
      " {'y_class_label_items': ['MMAT', 'MLBT'], 'alpha_s_items': [0.2, 0.3, 0.4], 'q0_items': [1.5, 2.0, 2.5]}\n",
      "Building required params for the loading the dataset file\n",
      "labels_str:\n",
      " {'class_labels_str': 'MMAT_MLBT', 'alpha_s_items_str': '0.2_0.3_0.4', 'q0_items_str': '1.5_2.0_2.5'}\n"
     ]
    }
   ],
   "source": [
    "from jet_ml_dataset_builder.jet_ml_dataset_builder_utilities import set_directory_paths\n",
    "dataset_directory_path, simulation_directory_path = set_directory_paths()\n",
    "from jet_ml_dataset_builder.jet_ml_dataset_builder_utilities import get_labels_str\n",
    "label_str_dict=get_labels_str()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading the whole dataset\n",
      "dataset.x: <class 'numpy.ndarray'> 1024000 (1000, 32, 32)\n",
      "dataset.y: <class 'numpy.ndarray'> 3000 (1000, 3)\n",
      "dataset.x: <class 'numpy.ndarray'> 1024000 (1000, 32, 32)\n",
      "dataset.y: <class 'numpy.ndarray'> 3000 (1000, 3)\n",
      "dataset.y(working_column) sample [['MLBT' '0.4' '2.5']\n",
      " ['MLBT' '0.4' '2.5']\n",
      " ['MLBT' '0.2' '2.5']\n",
      " ['MMAT' '0.4' '1']\n",
      " ['MMAT' '0.4' '1']\n",
      " ['MMAT' '0.3' '1']\n",
      " ['MMAT' '0.4' '1']\n",
      " ['MMAT' '0.3' '1']\n",
      " ['MLBT' '0.4' '2.5']\n",
      " ['MLBT' '0.4' '2.0']]\n",
      "Pre-processing\n",
      "Scaling the datset_x each image between 0 and 1\n",
      "dataset_x_points shape: (1000, 1024, 3)\n",
      "deleting the original dataset_x after preprocess ...\n",
      "Extract the working column#1 for classification\n",
      "Preprocess dataset_y\n",
      "Encoding to sparse categorical variable\n",
      "dataset_y_encoded:\n",
      " [2 2 0 2 2 1 2 1 2 2]\n",
      "dataset_y_encoded shape: (1000,)\n",
      "deleting the original dataset_x after preprocess ...\n"
     ]
    }
   ],
   "source": [
    "from jet_ml_dataset_builder.jet_ml_dataset_builder_utilities import get_dataset\n",
    "dataset_size=1000\n",
    "dataset_x, dataset_y=get_dataset(dataset_size,label_str_dict, dataset_directory_path)\n",
    "from jet_ml_models.pointnet import preprocess_dataset\n",
    "(dataset_x, dataset_y)=preprocess_dataset(dataset_x, dataset_y,is_one_hot_encoded=False,working_column=1,scale_x=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting dataset_x,dataset_y\n",
      "deleting the original dataset_x,dataset_y after splitting ...\n",
      "x_train: <class 'numpy.ndarray'> 2764800 (900, 1024, 3)\n",
      "y_train: <class 'numpy.ndarray'> 900 (900,)\n",
      "x_test: <class 'numpy.ndarray'> 307200 (100, 1024, 3)\n",
      "y_test: <class 'numpy.ndarray'> 100 (100,)\n",
      "y_test[:10]:\n",
      " [2 0 1 2 1 2 1 2 0 2]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from jet_ml_models.pointnet import prepare_datasets\n",
    "from jet_ml_models.pointnet import augment\n",
    "# Prepare datasets for training\n",
    "train_dataset, validation_dataset,test_dataset = prepare_datasets(dataset_x, dataset_y, random_state=42,test_size=0.1, validation_size=None, augment=augment, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29\n",
      "4\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "print(len(train_dataset))\n",
    "print(len(validation_dataset))\n",
    "print(len(test_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "simulation_directory_path: D:\\Projects\\110_JetscapeMl\\hm.jetscapeml.data\\simulation_results\\\n",
      "simulation_path: D:\\Projects\\110_JetscapeMl\\hm.jetscapeml.data\\simulation_results\\jetml_pointnet_classification_alpha_s_0.2_0.3_0.4\n",
      "current_simulation_path: D:\\Projects\\110_JetscapeMl\\hm.jetscapeml.data\\simulation_results\\jetml_pointnet_classification_alpha_s_0.2_0.3_0.4_size_1000_epochs_100_fold_1\n",
      "best_model_file_path: D:\\Projects\\110_JetscapeMl\\hm.jetscapeml.data\\simulation_results\\jetml_pointnet_classification_alpha_s_0.2_0.3_0.4_size_1000_epochs_100_fold_1_best_model.keras\n"
     ]
    }
   ],
   "source": [
    "from jet_ml_dataset_builder.jet_ml_dataset_builder_utilities import generate_simulation_path\n",
    "# monitor = 'val_accuracy'  # 'val_accuracy' or 'val_loss'\n",
    "monitor=\"val_sparse_categorical_accuracy\"\n",
    "\n",
    "\n",
    "\n",
    "classifying_parameter=\"alpha_s\"\n",
    "fold = 1\n",
    "n_epochs = 100\n",
    "\n",
    "current_simulation_path = generate_simulation_path(simulation_directory_path, classifying_parameter,label_str_dict, dataset_size, n_epochs, fold)\n",
    "print(\"current_simulation_path:\",current_simulation_path)\n",
    "\n",
    "# Use ModelCheckpoint callback to save the best model\n",
    "best_model_file_path = f'{current_simulation_path}_best_model.keras'\n",
    "print(\"best_model_file_path:\",best_model_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from jet_ml_models.pointnet import build_pointnet_classifier_model\n",
    "NUM_POINTS = 1024\n",
    "#because alpha_s can get 3 values\n",
    "NUM_CLASSES = 3\n",
    "activation=\"softmax\"\n",
    "# activation=\"sigmoid\"\n",
    "pointnet=build_pointnet_classifier_model(NUM_POINTS=NUM_POINTS,NUM_CLASSES=NUM_CLASSES, activation=activation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install tensorflow scikeras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from jet_ml_models.pointnet import compile_pointnet_classifier_model_with_hyperparam\n",
    "\n",
    "# learning_rate=0.001\n",
    "loss='sparse_categorical_crossentropy'\n",
    "# loss='categorical_crossentropy',\n",
    "metrics='sparse_categorical_accuracy'\n",
    "# metrics=['accuracy'],\n",
    "pointnet=compile_pointnet_classifier_model_with_hyperparam(pointnet, loss=loss,metrics=metrics)\n",
    "# from jet_ml_models.pointnet import print_model_summary\n",
    "# print_model_summary(pointnet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\saving\\saving_lib.py:415: UserWarning: Skipping variable loading for optimizer 'adam', because it has 150 variables whereas the saved optimizer has 2 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.342987 using {'batch_size': 32, 'epochs': 2}\n",
      "0.342987 (0.009719) with: {'batch_size': 32, 'epochs': 2}\n",
      "0.339031 (0.023787) with: {'batch_size': 32, 'epochs': 5}\n"
     ]
    }
   ],
   "source": [
    "from scikeras.wrappers import KerasClassifier\n",
    "model = KerasClassifier(model=pointnet, verbose=0)\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "# batch_size = [10, 20, 40, 60, 80, 100]\n",
    "# epochs = [10, 50, 100]\n",
    "batch_size = [32]\n",
    "epochs = [2, 5]\n",
    "param_grid = dict(batch_size=batch_size, epochs=epochs)\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1, cv=3)\n",
    "grid_result = grid.fit(dataset_x, dataset_y)\n",
    "# summarize results\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "undefined.undefined.undefined"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
