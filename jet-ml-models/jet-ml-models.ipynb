{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(1,'/wsu/home/gy/gy40/gy4065/hm.jetscapeml.source')\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Loading/Installing Package => Begin\\n\\n')\n",
    "\n",
    "import jet_ml_dataset_builder.jet_ml_dataset_builder_utilities as util\n",
    "\n",
    "print('\\n########################################################################')\n",
    "print('Checking the running platforms\\n')\n",
    "\n",
    "from jet_ml_dataset_builder.jet_ml_dataset_builder_utilities import set_directory_paths\n",
    "# Call the function and retrieve the dataset_directory_path and simulation_directory_path\n",
    "dataset_directory_path, simulation_directory_path = set_directory_paths()\n",
    "\n",
    "# Access the dataset_directory_path and simulation_directory_path\n",
    "print(\"Dataset Directory Path:\", dataset_directory_path)\n",
    "print(\"Simulation Directory Path:\", simulation_directory_path)\n",
    "print('########################################################################\\n')\n",
    "\n",
    "\n",
    "print('\\nLoading/Installing Package => End\\n\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from jet_ml_dataset_builder.jet_ml_dataset_builder_utilities import  parse_parameters\n",
    "\n",
    "# Call the function and retrieve the tokenized parameters\n",
    "tokenized_arguments, tokenized_values = parse_parameters()\n",
    "\n",
    "# Access the tokenized arguments and values\n",
    "print(\"Tokenized Arguments:\")\n",
    "for argument in tokenized_arguments:\n",
    "    print(argument)\n",
    "\n",
    "print(\"\\nTokenized Values:\")\n",
    "for argument, value in tokenized_values.items():\n",
    "    print(f\"{argument}: {value}\")\n",
    "\n",
    "y_class_label_items=['MMAT','MLBT']\n",
    "alpha_s_items=[0.2 ,0.3 ,0.4]\n",
    "q0_items=[1.5 ,2.0 ,2.5]\n",
    "\n",
    "print(\"y_class_label_items:\",y_class_label_items)\n",
    "print(\"alpha_s_items:\",alpha_s_items)\n",
    "print(\"q0_items:\",q0_items)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading the dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Building required params for the loading the dataset file\")\n",
    "\n",
    "class_labels_str = '_'.join(y_class_label_items)\n",
    "alpha_s_items_str='_'.join(map(str, alpha_s_items))\n",
    "q0_items_str='_'.join(map(str, q0_items))\n",
    "total_size=9*1200000\n",
    "# for shuffled_y_processed\n",
    "# dataset_file_name = f\"jet_ml_benchmark_config_01_to_09_alpha_{alpha_s_items_str}_q0_{q0_items_str}_{class_labels_str}_size_{total_size}_split_train_datasets/train_split_0.pkl\"\n",
    "# for shuffled\n",
    "dataset_file_name = f\"jet_ml_benchmark_config_01_to_09_alpha_{alpha_s_items_str}_q0_{q0_items_str}_{class_labels_str}_size_{1000}_shuffled.pkl\"\n",
    "# dataset_file_name = f\"jet_ml_benchmark_config_01_to_09_alpha_{alpha_s_items_str}_q0_{q0_items_str}_{class_labels_str}_size_{10000}_shuffled.pkl\"\n",
    "# dataset_file_name = f\"jet_ml_benchmark_config_01_to_09_alpha_{alpha_s_items_str}_q0_{q0_items_str}_{class_labels_str}_size_{100000}_shuffled.pkl\"\n",
    "# dataset_file_name = f\"jet_ml_benchmark_config_01_to_09_alpha_{alpha_s_items_str}_q0_{q0_items_str}_{class_labels_str}_size_{1000000}_shuffled.pkl\"\n",
    "# dataset_file_name = f\"jet_ml_benchmark_config_01_to_09_alpha_{alpha_s_items_str}_q0_{q0_items_str}_{class_labels_str}_size_{total_size}_shuffled.pkl\"\n",
    "\n",
    "dataset_file_name=simulation_directory_path+dataset_file_name\n",
    "print(\"dataset_file_name:\",dataset_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from jet_ml_dataset_builder.jet_ml_dataset_builder_utilities import load_dataset\n",
    "# dataset=load_dataset(dataset_file_name,has_test=False)\n",
    "# # ((x_train, y_train),(x_test,y_test))=dataset\n",
    "# # dataset_x=[x_train,x_test]\n",
    "# # dataset_y=[x_test,y_test]\n",
    "# (dataset_x, dataset_y) = dataset\n",
    "# print(\"dataset.x:\",type(dataset_x), dataset_x.size, dataset_x.shape)\n",
    "# print(\"dataset.y:\",type(dataset_y), dataset_y.size,dataset_y.shape)\n",
    "# # print(\"dataset y_train values:\\n\", dataset_x[1:10])\n",
    "# print(\"dataset y_test values:\\n\", dataset_y[1:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The first column of `dataset_y` is extracted (`dataset_y_binary`) for binary classification.\n",
    "- The dataset is split into training and testing sets using `train_test_split`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Assuming x and y are defined\n",
    "# # x should be a 2D array (e.g., (1000, 32*32))\n",
    "# # y should be a 2D array with three columns (e.g., (1000, 3))\n",
    "\n",
    "# from sklearn.model_selection import train_test_split\n",
    "\n",
    "# test_size = 0.1  # Adjust the test_size as needed\n",
    "# # Extract the first column for binary classification\n",
    "# dataset_y_binary = dataset_y[:, 0]\n",
    "\n",
    "# # Split the dataset into training and testing sets\n",
    "# x_train, x_test, y_train, y_test = train_test_split(dataset_x, dataset_y_binary, test_size=test_size, random_state=42)\n",
    "\n",
    "# # Display the shapes of the training and test datasets\n",
    "# print(\"Training set shapes - x:\", x_train.shape, \" y:\", y_train.shape)\n",
    "# print(\"Test set shapes - x:\", x_test.shape, \" y:\", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Assuming x and y are defined\n",
    "# # x should be a 2D array (e.g., (1000, 32*32))\n",
    "# # y should be a 2D array with three columns (e.g., (1000, 3))\n",
    "\n",
    "# # Flatten the 32x32 images to 1D arrays for LogisticRegression, DecisionTreeClassifier, LinearSVM, KNN, RandomForests\n",
    "# x_train_flatten = x_train.reshape(x_train.shape[0], -1)\n",
    "# x_test_flatten = x_test.reshape(x_test.shape[0], -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The logistic regression model is trained specifically for binary classification on the first column.\n",
    "- Predictions and evaluation are performed based on the binary labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.linear_model import LogisticRegression\n",
    "# from sklearn.metrics import accuracy_score\n",
    "\n",
    "# # Initialize the Logistic Regression model\n",
    "# model_binary = LogisticRegression(max_iter=1000, random_state=42)\n",
    "\n",
    "# # Train the model for binary classification\n",
    "# model_binary.fit(x_train_flatten, y_train)\n",
    "\n",
    "# # Make predictions on the test set\n",
    "# y_pred_binary = model_binary.predict(x_test_flatten)\n",
    "\n",
    "# # Evaluate the accuracy for binary classification\n",
    "# accuracy_binary = accuracy_score(y_test, y_pred_binary)\n",
    "# print(f\"Accuracy (Binary Classification with Logistic Regression): {accuracy_binary}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code uses DecisionTreeClassifier instead of LogisticRegression. The structure is similar: extract the first column for binary classification, split the dataset, flatten the images, initialize the model, train the model, make predictions, and evaluate the accuracy. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.tree import DecisionTreeClassifier\n",
    "# from sklearn.metrics import accuracy_score\n",
    "\n",
    "# # Initialize the Decision Tree Classifier model\n",
    "# model_decision_tree = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "# # Train the model for binary classification\n",
    "# model_decision_tree.fit(x_train_flatten, y_train)\n",
    "\n",
    "# # Make predictions on the test set\n",
    "# y_pred_binary = model_decision_tree.predict(x_test_flatten)\n",
    "\n",
    "# # Evaluate the accuracy for binary classification\n",
    "# accuracy_binary = accuracy_score(y_test, y_pred_binary)\n",
    "# print(f\"Accuracy (Binary Classification with Decision Tree): {accuracy_binary}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code uses LinearSVC instead of LogisticRegression or DecisionTreeClassifier. The structure remains similar: extract the first column for binary classification, split the dataset, flatten the images, initialize the model, train the model, make predictions, and evaluate the accuracy. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.svm import LinearSVC\n",
    "# from sklearn.metrics import accuracy_score\n",
    "\n",
    "# # Initialize the Linear Support Vector Classification model\n",
    "# model_linear_svc = LinearSVC(random_state=42)\n",
    "\n",
    "# # Train the model for binary classification\n",
    "# model_linear_svc.fit(x_train_flatten, y_train)\n",
    "\n",
    "# # Make predictions on the test set\n",
    "# y_pred_binary = model_linear_svc.predict(x_test_flatten)\n",
    "\n",
    "# # Evaluate the accuracy for binary classification\n",
    "# accuracy_binary = accuracy_score(y_test, y_pred_binary)\n",
    "# print(f\"Accuracy (Binary Classification with LinearSVC): {accuracy_binary}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adjust the k_neighbors parameter based on your requirements. The structure is similar to the previous examples: extract the first column for binary classification, split the dataset, flatten the images, initialize the model, train the model, make predictions, and evaluate the accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.neighbors import KNeighborsClassifier\n",
    "# from sklearn.metrics import accuracy_score\n",
    "\n",
    "# # Initialize the KNN classifier model\n",
    "# k_neighbors = 5  # You can adjust this parameter\n",
    "# model_knn = KNeighborsClassifier(n_neighbors=k_neighbors)\n",
    "\n",
    "# # Train the model for binary classification\n",
    "# model_knn.fit(x_train_flatten, y_train)\n",
    "\n",
    "# # Make predictions on the test set\n",
    "# y_pred_binary = model_knn.predict(x_test_flatten)\n",
    "\n",
    "# # Evaluate the accuracy for binary classification\n",
    "# accuracy_binary = accuracy_score(y_test, y_pred_binary)\n",
    "# print(f\"Accuracy (Binary Classification with KNN): {accuracy_binary}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code uses RandomForestClassifier from scikit-learn. The structure is similar to the previous examples: extract the first column for binary classification, split the dataset, flatten the images, initialize the model, train the model, make predictions, and evaluate the accuracy. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "# from sklearn.metrics import accuracy_score\n",
    "\n",
    "# # Initialize the Random Forest Classifier model\n",
    "# model_random_forest = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# # Train the model for binary classification\n",
    "# model_random_forest.fit(x_train_flatten, y_train)\n",
    "\n",
    "# # Make predictions on the test set\n",
    "# y_pred_binary = model_random_forest.predict(x_test_flatten)\n",
    "\n",
    "# # Evaluate the accuracy for binary classification\n",
    "# accuracy_binary = accuracy_score(y_test, y_pred_binary)\n",
    "# print(f\"Accuracy (Binary Classification with RandomForest): {accuracy_binary}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import pandas as pd\n",
    "# import matplotlib.pyplot as plt\n",
    "# from sklearn.linear_model import LogisticRegression\n",
    "# from sklearn.tree import DecisionTreeClassifier\n",
    "# from sklearn.svm import LinearSVC\n",
    "# from sklearn.neighbors import KNeighborsClassifier\n",
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "# from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "# from sklearn.model_selection import train_test_split\n",
    "\n",
    "# from jet_ml_dataset_builder.jet_ml_dataset_builder_utilities import load_dataset\n",
    "# # Function to load datasets of different sizes\n",
    "# def get_dataset(size):\n",
    "#     # x = np.random.random((size, 32, 32))\n",
    "#     # y = np.random.randint(0, 2, size=(size, 3))  # Assuming three columns for y\n",
    "#     dataset_file_name = f\"jet_ml_benchmark_config_01_to_09_alpha_{alpha_s_items_str}_q0_{q0_items_str}_{class_labels_str}_size_{size}_shuffled.pkl\"\n",
    "    \n",
    "#     dataset_file_name=simulation_directory_path+dataset_file_name\n",
    "#     print(\"dataset_file_name:\",dataset_file_name)\n",
    "    \n",
    "#     dataset=load_dataset(dataset_file_name,has_test=False)\n",
    "#     (dataset_x, dataset_y) = dataset\n",
    "#     # Extract the first column for binary classification\n",
    "#     dataset_y = dataset_y[:, 0]\n",
    "#     print(\"dataset.x:\",type(dataset_x), dataset_x.size, dataset_x.shape)\n",
    "#     print(\"dataset.y:\",type(dataset_y), dataset_y.size,dataset_y.shape)\n",
    "#     return dataset_x, dataset_y\n",
    "\n",
    "# # Function to train and evaluate classifiers\n",
    "# def train_and_evaluate_classifier(model, x_train, y_train, x_test, y_test):\n",
    "#     # Assuming x and y are defined\n",
    "#     # x should be a 2D array (e.g., (1000, 32*32))\n",
    "#     # y should be a 2D array with three columns (e.g., (1000, 3))\n",
    "\n",
    "#     # Flatten the 32x32 images to 1D arrays for LogisticRegression, DecisionTreeClassifier, LinearSVM, KNN, RandomForests\n",
    "#     x_train_flatten = x_train.reshape(x_train.shape[0], -1)\n",
    "#     x_test_flatten = x_test.reshape(x_test.shape[0], -1)\n",
    "#     model.fit(x_train_flatten, y_train)\n",
    "#     y_pred = model.predict(x_test_flatten)\n",
    "#     accuracy = accuracy_score(y_test, y_pred)\n",
    "#     cm = confusion_matrix(y_test, y_pred)\n",
    "#     return accuracy, cm\n",
    "\n",
    "\n",
    "# # # Sizes of datasets\n",
    "# # dataset_sizes = [1000, 10000]\n",
    "# dataset_sizes = [1000, 10000, 100000, 1000000]\n",
    "\n",
    "\n",
    "# # Classifiers\n",
    "# classifiers = {\n",
    "#     'Logistic Regression': LogisticRegression(max_iter=1000, random_state=42),\n",
    "#     'Decision Tree': DecisionTreeClassifier(random_state=42),\n",
    "#     'LinearSVC': LinearSVC(random_state=42),\n",
    "#     'KNN': KNeighborsClassifier(),\n",
    "#     'Random Forest': RandomForestClassifier(random_state=42)\n",
    "# }\n",
    "\n",
    "# # Results storage\n",
    "# results = []\n",
    "\n",
    "# # Loop through different dataset sizes\n",
    "# for size in dataset_sizes:\n",
    "#     # Generate dataset\n",
    "#     x, y = get_dataset(size)\n",
    "    \n",
    "#     # Split dataset\n",
    "#     x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)\n",
    "    \n",
    "#     # Loop through classifiers\n",
    "#     for clf_name, clf in classifiers.items():\n",
    "#         # Train and evaluate classifier\n",
    "#         accuracy, cm = train_and_evaluate_classifier(clf, x_train, y_train, x_test, y_test)\n",
    "#         results.append({'Dataset Size': size, 'Classifier': clf_name, 'Accuracy': accuracy, 'Confusion Matrix': cm})\n",
    "\n",
    "# # Create a DataFrame from results\n",
    "# df_results = pd.DataFrame(results)\n",
    "\n",
    "# # Save the DataFrame to a text file\n",
    "# df_results.to_csv('binary_classification_results.txt', index=False, sep='\\t')\n",
    "\n",
    "\n",
    "# # Plotting with different markers for each classifier\n",
    "# plt.figure(figsize=(12, 8))\n",
    "# markers = ['o', 's', '^', 'D', 'v']  # You can customize the markers here\n",
    "\n",
    "# for clf_name, group, marker in zip(classifiers.keys(), df_results.groupby('Classifier'), markers):\n",
    "#     plt.plot(group[1]['Dataset Size'], group[1]['Accuracy'], label=clf_name, marker=marker)\n",
    "\n",
    "# # # Plotting\n",
    "# # plt.figure(figsize=(12, 8))\n",
    "# # for clf_name, group in df_results.groupby('Classifier'):\n",
    "# #     plt.plot(group['Dataset Size'], group['Accuracy'], label=clf_name, marker='o')\n",
    "\n",
    "# plt.title('Binary Classification Accuracy for Different Dataset Sizes')\n",
    "# plt.xlabel('Dataset Size')\n",
    "# plt.xscale('log')\n",
    "# plt.ylabel('Accuracy')\n",
    "# plt.legend()\n",
    "\n",
    "# # Save the plot with high resolution (300 dpi)\n",
    "# plt.savefig('binary_classification_accuracy_plot.png', dpi=300)\n",
    "# plt.show()\n",
    "\n",
    "# # Display results in a table\n",
    "# print(df_results.pivot_table(index='Dataset Size', columns='Classifier', values='Accuracy'))\n",
    "\n",
    "# # Define the module labels\n",
    "# module_labels = ['MMATTER', 'MLBT']\n",
    "\n",
    "# # Save confusion matrices\n",
    "# for index, row in df_results.iterrows():\n",
    "#     clf_name = row['Classifier']\n",
    "#     dataset_size = row['Dataset Size']\n",
    "#     cm = row['Confusion Matrix']\n",
    "#     plt.figure()\n",
    "#     plt.imshow(cm, interpolation='nearest', cmap='Oranges') #plt.cm.Blue\n",
    "\n",
    "#     # Annotate each cell with the value\n",
    "#     for i in range(len(module_labels)):\n",
    "#         for j in range(len(module_labels)):\n",
    "#             plt.text(j, i, str(cm[i, j]), ha='center', va='center', color='black')\n",
    "\n",
    "#     plt.title(f'Confusion Matrix - {clf_name} - {dataset_size} samples')\n",
    "#     plt.colorbar()\n",
    "#     # Set tick labels\n",
    "#     plt.xticks(np.arange(len(module_labels)), module_labels)\n",
    "#     plt.yticks(np.arange(len(module_labels)), module_labels)\n",
    "\n",
    "#     plt.xlabel('Predicted Label')\n",
    "#     plt.ylabel('True Label')\n",
    "#     # Remove tick marks\n",
    "#     plt.tick_params(axis='both', which='both', bottom=False, top=False, left=False, right=False)\n",
    "#     plt.savefig(f'confusion_matrix_{clf_name}_{dataset_size}.png', dpi=300)\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "implementing k-fold for the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading dataset by size and getting just the first column\n",
    "\n",
    "from jet_ml_dataset_builder.jet_ml_dataset_builder_utilities import load_dataset\n",
    "# Function to load datasets of different sizes\n",
    "def get_dataset(size):\n",
    "    dataset_file_name = f\"jet_ml_benchmark_config_01_to_09_alpha_{alpha_s_items_str}_q0_{q0_items_str}_{class_labels_str}_size_{size}_shuffled.pkl\"\n",
    "    \n",
    "    dataset_file_name=simulation_directory_path+dataset_file_name\n",
    "    print(\"dataset_file_name:\",dataset_file_name)\n",
    "    \n",
    "    dataset=load_dataset(dataset_file_name,has_test=False)\n",
    "    (dataset_x, dataset_y) = dataset\n",
    "    # Extract the first column for binary classification\n",
    "    dataset_y = dataset_y[:, 0]\n",
    "    print(\"dataset.x:\",type(dataset_x), dataset_x.size, dataset_x.shape)\n",
    "    print(\"dataset.y:\",type(dataset_y), dataset_y.size,dataset_y.shape)\n",
    "    return dataset_x, dataset_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining dataset sizes and classifiers\n",
    "\n",
    "# Sizes of datasets\n",
    "# dataset_sizes = [1000]\n",
    "# dataset_sizes = [1000, 10000]\n",
    "dataset_sizes = [1000, 10000, 100000, 1000000]\n",
    "\n",
    "\n",
    "# Classifiers\n",
    "classifiers = {\n",
    "    'Logistic Regression': LogisticRegression(max_iter=1000, random_state=42),\n",
    "    'Decision Tree': DecisionTreeClassifier(random_state=42),\n",
    "    'LinearSVC': LinearSVC(random_state=42),\n",
    "    'KNN': KNeighborsClassifier(),\n",
    "    'Random Forest': RandomForestClassifier(random_state=42)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to train and evaluate classifiers \n",
    "def train_and_evaluate_classifier(model, x_train, y_train, x_test, y_test):\n",
    "    # Assuming x and y are defined\n",
    "    # x should be a 2D array (e.g., (1000, 32*32))\n",
    "    # y should be a 2D array with three columns (e.g., (1000, 3))\n",
    "\n",
    "    # Flatten the 32x32 images to 1D arrays for LogisticRegression, DecisionTreeClassifier, LinearSVM, KNN, RandomForests\n",
    "    x_train_flatten = x_train.reshape(x_train.shape[0], -1)\n",
    "    x_test_flatten = x_test.reshape(x_test.shape[0], -1)\n",
    "    model.fit(x_train_flatten, y_train)\n",
    "    y_pred = model.predict(x_test_flatten)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    return accuracy, cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to train and evaluate classifiers using k-fold cross-validation and giving confusion matrix and accuracy as results\n",
    "def train_and_evaluate_classifier_kfold(model, x, y, k_fold=5):\n",
    "    x_flatten = x.reshape(x.shape[0], -1)\n",
    "    kf = KFold(n_splits=k_fold, shuffle=True, random_state=42)\n",
    "    \n",
    "    scores = []\n",
    "    confusion_matrices = []\n",
    "\n",
    "    for train_index, test_index in kf.split(x_flatten):\n",
    "        x_train, x_test = x_flatten[train_index], x_flatten[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "        model.fit(x_train, y_train)\n",
    "        y_pred = model.predict(x_test)\n",
    "\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "        scores.append(accuracy)\n",
    "        confusion_matrices.append(cm)\n",
    "\n",
    "    return scores, confusion_matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Results storage\n",
    "# results = []\n",
    "\n",
    "# # Loop through different dataset sizes\n",
    "# for size in dataset_sizes:\n",
    "#     # Generate dataset\n",
    "#     x, y = get_dataset(size)\n",
    "    \n",
    "#     # Split dataset\n",
    "#     x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)\n",
    "    \n",
    "#     # Loop through classifiers\n",
    "#     for clf_name, clf in classifiers.items():\n",
    "#         # Train and evaluate classifier\n",
    "#         accuracy, cm = train_and_evaluate_classifier(clf, x_train, y_train, x_test, y_test)\n",
    "#         results.append({\n",
    "#             'Dataset Size': size,\n",
    "#             'Classifier': clf_name, \n",
    "#             'Accuracy': accuracy, \n",
    "#             'Confusion Matrix': cm})\n",
    "# # Create a DataFrame from results\n",
    "# df_results = pd.DataFrame(results)\n",
    "# # Save the DataFrame to a text file\n",
    "# df_results.to_csv('binary_classification_results.txt', index=False, sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Results storage\n",
    "results_kfold = []\n",
    "results_kfold_errorbar=[]\n",
    "# Loop through different dataset sizes\n",
    "for size in dataset_sizes:\n",
    "    # Generate dataset\n",
    "    x, y = get_dataset(size)\n",
    "    \n",
    "    # Loop through classifiers\n",
    "    for clf_name, clf in classifiers.items():\n",
    "        # Evaluate classifier using k-fold cross-validation\n",
    "        fold_scores, fold_conf_matrices = train_and_evaluate_classifier_kfold(clf, x, y)\n",
    "        \n",
    "        # Store results for each fold\n",
    "        for fold_num, (score, cm) in enumerate(zip(fold_scores, fold_conf_matrices), start=1):\n",
    "            results_kfold.append({\n",
    "                'Dataset Size': size,\n",
    "                'Classifier': clf_name,\n",
    "                'Fold Number': fold_num,\n",
    "                'Accuracy': score,\n",
    "                'Confusion Matrix': cm\n",
    "            })\n",
    "        # Calculate mean and standard deviation of accuracy scores\n",
    "        mean_accuracy = np.mean(fold_scores)\n",
    "        std_accuracy = np.std(fold_scores)\n",
    "        \n",
    "        # Store results\n",
    "        results_kfold_errorbar.append({\n",
    "            'Dataset_Size': size,\n",
    "            'Classifier': clf_name,\n",
    "            'Mean_Accuracy': mean_accuracy,\n",
    "            'Std_Accuracy': std_accuracy\n",
    "        })\n",
    "# Create a DataFrame from k-fold results\n",
    "df_results_kfold = pd.DataFrame(results_kfold)\n",
    "# Save the DataFrame to a text file\n",
    "df_results_kfold.to_csv('binary_classification_results_kfold.txt', index=False, sep='\\t')\n",
    "# Display results in a table\n",
    "print(df_results_kfold)\n",
    "\n",
    "# Create a DataFrame from k-fold results\n",
    "df_results_kfold_errorbar = pd.DataFrame(results_kfold_errorbar)\n",
    "# Save the DataFrame to a text file\n",
    "df_results_kfold_errorbar.to_csv('binary_classification_results_kfold_errorbar.txt', index=False, sep='\\t')\n",
    "# Display results in a table\n",
    "print(df_results_kfold_errorbar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the module labels\n",
    "module_labels = ['MMATTER', 'MLBT']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Save confusion matrices\n",
    "# for index, row in df_results.iterrows():\n",
    "#     clf_name = row['Classifier']\n",
    "#     dataset_size = row['Dataset Size']\n",
    "#     cm = row['Confusion Matrix']\n",
    "#     plt.figure()\n",
    "#     plt.imshow(cm, interpolation='nearest', cmap='Oranges') #plt.cm.Blue\n",
    "\n",
    "#     # Annotate each cell with the value\n",
    "#     for i in range(len(module_labels)):\n",
    "#         for j in range(len(module_labels)):\n",
    "#             plt.text(j, i, str(cm[i, j]), ha='center', va='center', color='black')\n",
    "\n",
    "#     plt.title(f'Confusion Matrix - {clf_name} - {dataset_size} samples')\n",
    "#     plt.colorbar()\n",
    "#     # Set tick labels\n",
    "#     plt.xticks(np.arange(len(module_labels)), module_labels)\n",
    "#     plt.yticks(np.arange(len(module_labels)), module_labels)\n",
    "\n",
    "#     plt.xlabel('Predicted Label')\n",
    "#     plt.ylabel('True Label')\n",
    "#     # Remove tick marks\n",
    "#     plt.tick_params(axis='both', which='both', bottom=False, top=False, left=False, right=False)\n",
    "#     plt.savefig(f'confusion_matrix_{clf_name}_{dataset_size}.png', dpi=300)\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save confusion matrices for each fold\n",
    "for index, row in df_results_kfold.iterrows():\n",
    "    clf_name = row['Classifier']\n",
    "    dataset_size = row['Dataset Size']\n",
    "    fold_num = row['Fold Number']\n",
    "    cm = row['Confusion Matrix']\n",
    "\n",
    "    plt.figure()\n",
    "    plt.imshow(cm, interpolation='nearest', cmap='Oranges') # plt.cm.Blues\n",
    "\n",
    "    # Annotate each cell with the value\n",
    "    for i in range(len(module_labels)):\n",
    "        for j in range(len(module_labels)):\n",
    "            plt.text(j, i, str(cm[i, j]), ha='center', va='center', color='black')\n",
    "\n",
    "    plt.title(f'Confusion Matrix - {clf_name} - {dataset_size} samples - Fold {fold_num}')\n",
    "    plt.colorbar()\n",
    "    # Set tick labels\n",
    "    plt.xticks(np.arange(len(module_labels)), module_labels)\n",
    "    plt.yticks(np.arange(len(module_labels)), module_labels)\n",
    "\n",
    "    plt.xlabel('Predicted Label')\n",
    "    plt.ylabel('True Label')\n",
    "    # Remove tick marks\n",
    "    plt.tick_params(axis='both', which='both', bottom=False, top=False, left=False, right=False)\n",
    "    plt.savefig(f'confusion_matrix_{clf_name}_{dataset_size}_fold_{fold_num}.png', dpi=300)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Plotting with different markers for each classifier\n",
    "# plt.figure(figsize=(12, 8))\n",
    "# markers = ['o', 's', '^', 'D', 'v']  # You can customize the markers here\n",
    "\n",
    "# for clf_name, group, marker in zip(classifiers.keys(), df_results.groupby('Classifier'), markers):\n",
    "#     plt.plot(group[1]['Dataset Size'], group[1]['Accuracy'], label=clf_name, marker=marker)\n",
    "\n",
    "\n",
    "# plt.title('Binary Classification Accuracy for Different Dataset Sizes')\n",
    "# plt.xlabel('Dataset Size')\n",
    "# plt.xscale('log')\n",
    "# plt.ylabel('Accuracy')\n",
    "# plt.legend()\n",
    "\n",
    "# # Save the plot with high resolution (300 dpi)\n",
    "# plt.savefig('binary_classification_accuracy_plot.png', dpi=300)\n",
    "# plt.show()\n",
    "\n",
    "# # Display results in a table\n",
    "# print(df_results.pivot_table(index='Dataset Size', columns='Classifier', values='Accuracy'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "# Load the DataFrame from the saved file\n",
    "#df_results = pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/binary_classification_results_kfold_errorbar.txt\", sep='\\t')\n",
    "df_results= df_results_kfold_errorbar\n",
    "print(df_results)\n",
    "# Set a seaborn style (optional)\n",
    "sns.set(style=\"whitegrid\")\n",
    "\n",
    "\n",
    "# Define a dictionary to map classifiers to markers\n",
    "marker_dict = {\n",
    "    'Logistic Regression': 'o',\n",
    "    'Decision Tree': 's',\n",
    "    'LinearSVC': '^',\n",
    "    'KNN': 'v',\n",
    "    'Random Forest': 'D'\n",
    "}\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "for clf_name, group in df_results.groupby('Classifier'):\n",
    "    plt.errorbar(\n",
    "        group['Dataset_Size'],\n",
    "        group['Mean_Accuracy'],\n",
    "        yerr=group['Std_Accuracy'],\n",
    "        label=clf_name,\n",
    "        marker=marker_dict.get(clf_name, 'o'),  # Use 'o' as default marker if not found in the dictionary\n",
    "        capsize=5\n",
    "    )\n",
    "\n",
    "plt.xscale('log')  # Set x-axis to logarithmic scale\n",
    "plt.xlabel('Dataset Size (log scale)')\n",
    "plt.ylabel('Mean Accuracy')\n",
    "plt.title('Binary Classification Accuracy with Error Bars for Different Dataset Sizes')\n",
    "plt.legend()\n",
    "# plt.grid(True)\n",
    "# Save the plot with high resolution (300 dpi)\n",
    "plt.savefig('binary_classification_accuracy_errorbar_plot.png', dpi=300)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
