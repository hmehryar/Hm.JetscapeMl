{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(1,'/wsu/home/gy/gy40/gy4065/hm.jetscapeml.source')\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Loading/Installing Package => Begin\\n\\n')\n",
    "\n",
    "import jet_ml_dataset_builder.jet_ml_dataset_builder_utilities as util\n",
    "\n",
    "print('\\n########################################################################')\n",
    "print('Checking the running platforms\\n')\n",
    "\n",
    "from jet_ml_dataset_builder.jet_ml_dataset_builder_utilities import set_directory_paths\n",
    "# Call the function and retrieve the dataset_directory_path and simulation_directory_path\n",
    "dataset_directory_path, simulation_directory_path = set_directory_paths()\n",
    "\n",
    "# Access the dataset_directory_path and simulation_directory_path\n",
    "print(\"Dataset Directory Path:\", dataset_directory_path)\n",
    "print(\"Simulation Directory Path:\", simulation_directory_path)\n",
    "print('########################################################################\\n')\n",
    "\n",
    "\n",
    "print('\\nLoading/Installing Package => End\\n\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from jet_ml_dataset_builder.jet_ml_dataset_builder_utilities import  parse_parameters\n",
    "\n",
    "# Call the function and retrieve the tokenized parameters\n",
    "tokenized_arguments, tokenized_values = parse_parameters()\n",
    "\n",
    "# Access the tokenized arguments and values\n",
    "print(\"Tokenized Arguments:\")\n",
    "for argument in tokenized_arguments:\n",
    "    print(argument)\n",
    "\n",
    "print(\"\\nTokenized Values:\")\n",
    "for argument, value in tokenized_values.items():\n",
    "    print(f\"{argument}: {value}\")\n",
    "\n",
    "y_class_label_items=['MMAT','MLBT']\n",
    "alpha_s_items=[0.2 ,0.3 ,0.4]\n",
    "q0_items=[1.5 ,2.0 ,2.5]\n",
    "\n",
    "print(\"y_class_label_items:\",y_class_label_items)\n",
    "print(\"alpha_s_items:\",alpha_s_items)\n",
    "print(\"q0_items:\",q0_items)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading the dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Building required params for the loading the dataset file\")\n",
    "\n",
    "class_labels_str = '_'.join(y_class_label_items)\n",
    "alpha_s_items_str='_'.join(map(str, alpha_s_items))\n",
    "q0_items_str='_'.join(map(str, q0_items))\n",
    "total_size=9*1200000\n",
    "# for shuffled_y_processed\n",
    "# dataset_file_name = f\"jet_ml_benchmark_config_01_to_09_alpha_{alpha_s_items_str}_q0_{q0_items_str}_{class_labels_str}_size_{total_size}_split_train_datasets/train_split_0.pkl\"\n",
    "# for shuffled\n",
    "dataset_file_name = f\"jet_ml_benchmark_config_01_to_09_alpha_{alpha_s_items_str}_q0_{q0_items_str}_{class_labels_str}_size_{total_size}_shuffled.pkl\"\n",
    "dataset_file_name=simulation_directory_path+dataset_file_name\n",
    "print(\"dataset_file_name:\",dataset_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from jet_ml_dataset_builder.jet_ml_dataset_builder_utilities import load_dataset\n",
    "# dataset=load_dataset (dataset_file_name,has_test=False)\n",
    "# (dataset_x, dataset_y)=dataset\n",
    "# print(\"dataset y_train values:\\n\", dataset_x[1:10])\n",
    "# print(\"dataset y_test values:\\n\", dataset_y[1:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from jet_ml_dataset_builder.jet_ml_dataset_builder_utilities import load_dataset\n",
    "dataset=load_dataset (dataset_file_name)\n",
    "((dataset_x, dataset_y),(dataset_x_test,dataset_y_test))=dataset\n",
    "print(\"After loading the dataset\")\n",
    "print(\"dataset.x_train:\",type(dataset_x), dataset_x.size, dataset_x.shape)\n",
    "print(\"dataset.y_train:\",type(dataset_y), dataset_y.size,dataset_y.shape)\n",
    "\n",
    "print(\"dataset.x_test:\",type(dataset_x_test), dataset_x_test.size, dataset_x_test.shape)\n",
    "print(\"dataset.y_test:\",type(dataset_y_test), dataset_y_test.size, dataset_y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def split_dataset(dataset_x, dataset_y, dataset_size):\n",
    "#     \"\"\"\n",
    "#     Split a dataset into proportioned x and y.\n",
    "\n",
    "#     Parameters:\n",
    "#     - dataset: Dictionary or object containing 'x' and 'y' numpy arrays.\n",
    "#     - dataset_size: Number of samples for the final dataset.\n",
    "\n",
    "\n",
    "#     Returns:\n",
    "#     - x, y: Numpy arrays for the dataset.\n",
    "#     \"\"\"\n",
    "#     # Create the training dataset\n",
    "#     x = dataset_x[:dataset_size]\n",
    "#     y = dataset_y[:dataset_size]\n",
    "\n",
    "#     return (x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_dataset(dataset_x, dataset_y, train_size, test_size = None):\n",
    "    \"\"\"\n",
    "    Split a dataset into training and test sets.\n",
    "\n",
    "    Parameters:\n",
    "    - dataset: Dictionary or object containing 'x' and 'y' numpy arrays.\n",
    "    - train_size: Number of samples for the training set.\n",
    "    - test_size: Number of samples for the test set.\n",
    "\n",
    "    Returns:\n",
    "    - x_train, y_train, x_test, y_test: Numpy arrays for the training and test sets.\n",
    "    \"\"\"\n",
    "    \n",
    "    x_train = dataset_x[:train_size]\n",
    "    y_train = dataset_y[:train_size]\n",
    "\n",
    "    if test_size is None:\n",
    "       return (x_train, y_train)\n",
    "    # Create the test dataset\n",
    "    x_test = dataset_x[train_size:train_size + test_size]\n",
    "    y_test = dataset_y[train_size:train_size + test_size]\n",
    "\n",
    "    return ((x_train, y_train), (x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Assuming your original dataset is named dataset\n",
    "# train_size = 900\n",
    "# test_size = 100\n",
    "# from jet_ml_dataset_builder.jet_ml_dataset_builder_utilities import save_dataset\n",
    "# dataset_file_name = f\"jet_ml_benchmark_config_01_to_09_alpha_{alpha_s_items_str}_q0_{q0_items_str}_{class_labels_str}_size_{1000}_shuffled.pkl\"\n",
    "# dataset_file_name=simulation_directory_path+dataset_file_name\n",
    "# print(\"dataset_file_name:\",dataset_file_name)\n",
    "# save_dataset(dataset_file_name,(dataset_x, dataset_y))\n",
    "\n",
    "# dataset_file_name=\"\"\n",
    "# dataset_file_name = f\"jet_ml_benchmark_config_01_to_09_alpha_{alpha_s_items_str}_q0_{q0_items_str}_{class_labels_str}_size_{1000}_shuffled_splitted.pkl\"\n",
    "# ((x_train, y_train), (x_test, y_test)) = split_dataset(dataset_x, dataset_y, train_size, test_size)\n",
    "\n",
    "# # Display the shapes of the training and test datasets\n",
    "# print(\"Training set shapes - x:\", x_train.shape, \" y:\", y_train.shape)\n",
    "# print(\"Test set shapes - x:\", x_test.shape, \" y:\", y_test.shape)\n",
    "# dataset_file_name=simulation_directory_path+dataset_file_name\n",
    "# print(\"dataset_file_name:\",dataset_file_name)\n",
    "# save_dataset(dataset_file_name,((x_train, y_train), (x_test, y_test)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from jet_ml_dataset_builder.jet_ml_dataset_builder_utilities import save_dataset\n",
    "def create_and_save_split_dataset(dataset_x,dataset_y,train_size,test_size,simulation_directory_path):\n",
    "    dataset_size=train_size+test_size\n",
    "    \n",
    "    (x, y)=split_dataset(dataset_x, dataset_y, dataset_size)\n",
    "\n",
    "    dataset_file_name = f\"jet_ml_benchmark_config_01_to_09_alpha_{alpha_s_items_str}_q0_{q0_items_str}_{class_labels_str}_size_{dataset_size}_shuffled.pkl\"\n",
    "    dataset_file_name=simulation_directory_path+dataset_file_name\n",
    "    print(\"dataset_file_name:\",dataset_file_name)\n",
    "    # Display the shapes of the training and test datasets\n",
    "    print(\"Dataset shapes - x:\", x.shape, \" y:\", y.shape)\n",
    "    save_dataset(dataset_file_name,(x, y))\n",
    "\n",
    "    ((x_train, y_train), (x_test, y_test)) = split_dataset(dataset_x, dataset_y, train_size, test_size)\n",
    "\n",
    "    dataset_file_name = f\"jet_ml_benchmark_config_01_to_09_alpha_{alpha_s_items_str}_q0_{q0_items_str}_{class_labels_str}_size_{dataset_size}_shuffled_splitted.pkl\"\n",
    "    dataset_file_name=simulation_directory_path+dataset_file_name\n",
    "    print(\"dataset_file_name:\",dataset_file_name)\n",
    "    # Display the shapes of the training and test datasets\n",
    "    print(\"Training set shapes - x:\", x_train.shape, \" y:\", y_train.shape)\n",
    "    print(\"Test set shapes - x:\", x_test.shape, \" y:\", y_test.shape) \n",
    "    save_dataset(dataset_file_name,((x_train, y_train), (x_test, y_test)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming your original dataset is named dataset\n",
    "train_size = 900\n",
    "test_size = 100\n",
    "create_and_save_split_dataset(dataset_x,dataset_y,train_size,test_size,simulation_directory_path)\n",
    "\n",
    "train_size = 9000\n",
    "test_size = 1000\n",
    "create_and_save_split_dataset(dataset_x,dataset_y,train_size,test_size,simulation_directory_path)\n",
    "\n",
    "train_size = 90000\n",
    "test_size = 10000\n",
    "create_and_save_split_dataset(dataset_x,dataset_y,train_size,test_size,simulation_directory_path)\n",
    "\n",
    "train_size = 900000\n",
    "test_size = 100000\n",
    "create_and_save_split_dataset(dataset_x,dataset_y,train_size,test_size,simulation_directory_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_size = 9000\n",
    "# test_size = 1000\n",
    "\n",
    "# ((x_train, y_train), (x_test, y_test)) = split_dataset(dataset_x, dataset_y, train_size, test_size)\n",
    "\n",
    "# # Display the shapes of the training and test datasets\n",
    "# print(\"Training set shapes - x:\", x_train.shape, \" y:\", y_train.shape)\n",
    "# print(\"Test set shapes - x:\", x_test.shape, \" y:\", y_test.shape)\n",
    "\n",
    "# from jet_ml_dataset_builder.jet_ml_dataset_builder_utilities import save_dataset\n",
    "# dataset_file_name = f\"jet_ml_benchmark_config_01_to_09_alpha_{alpha_s_items_str}_q0_{q0_items_str}_{class_labels_str}_size_{10000}_shuffled.pkl\"\n",
    "# dataset_file_name=simulation_directory_path+dataset_file_name\n",
    "# print(\"dataset_file_name:\",dataset_file_name)\n",
    "# save_dataset(dataset_file_name,((x_train, y_train), (x_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_size = 90000\n",
    "# test_size = 10000\n",
    "\n",
    "# ((x_train, y_train), (x_test, y_test)) = split_dataset(dataset_x, dataset_y, train_size, test_size)\n",
    "\n",
    "# # Display the shapes of the training and test datasets\n",
    "# print(\"Training set shapes - x:\", x_train.shape, \" y:\", y_train.shape)\n",
    "# print(\"Test set shapes - x:\", x_test.shape, \" y:\", y_test.shape)\n",
    "\n",
    "# from jet_ml_dataset_builder.jet_ml_dataset_builder_utilities import save_dataset\n",
    "# dataset_file_name = f\"jet_ml_benchmark_config_01_to_09_alpha_{alpha_s_items_str}_q0_{q0_items_str}_{class_labels_str}_size_{100000}_shuffled.pkl\"\n",
    "# dataset_file_name=simulation_directory_path+dataset_file_name\n",
    "# print(\"dataset_file_name:\",dataset_file_name)\n",
    "# save_dataset(dataset_file_name,((x_train, y_train), (x_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_size = 900000\n",
    "# test_size = 100000\n",
    "\n",
    "# ((x_train, y_train), (x_test, y_test)) = split_dataset(dataset_x, dataset_y, train_size, test_size)\n",
    "\n",
    "# # Display the shapes of the training and test datasets\n",
    "# print(\"Training set shapes - x:\", x_train.shape, \" y:\", y_train.shape)\n",
    "# print(\"Test set shapes - x:\", x_test.shape, \" y:\", y_test.shape)\n",
    "\n",
    "# from jet_ml_dataset_builder.jet_ml_dataset_builder_utilities import save_dataset\n",
    "# dataset_file_name = f\"jet_ml_benchmark_config_01_to_09_alpha_{alpha_s_items_str}_q0_{q0_items_str}_{class_labels_str}_size_{1000000}_shuffled.pkl\"\n",
    "# dataset_file_name=simulation_directory_path+dataset_file_name\n",
    "# print(\"dataset_file_name:\",dataset_file_name)\n",
    "# save_dataset(dataset_file_name,((x_train, y_train), (x_test, y_test)))"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
