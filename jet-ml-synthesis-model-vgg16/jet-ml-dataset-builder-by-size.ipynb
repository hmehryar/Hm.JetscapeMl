{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(1,'/wsu/home/gy/gy40/gy4065/hm.jetscapeml.source')\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Loading/Installing Package => Begin\\n\\n')\n",
    "\n",
    "import jet_ml_dataset_builder.jet_ml_dataset_builder_utilities as util\n",
    "\n",
    "print('\\n########################################################################')\n",
    "print('Checking the running platforms\\n')\n",
    "\n",
    "from jet_ml_dataset_builder.jet_ml_dataset_builder_utilities import set_directory_paths\n",
    "# Call the function and retrieve the dataset_directory_path and simulation_directory_path\n",
    "dataset_directory_path, simulation_directory_path = set_directory_paths()\n",
    "\n",
    "# Access the dataset_directory_path and simulation_directory_path\n",
    "print(\"Dataset Directory Path:\", dataset_directory_path)\n",
    "print(\"Simulation Directory Path:\", simulation_directory_path)\n",
    "print('########################################################################\\n')\n",
    "\n",
    "\n",
    "print('\\nLoading/Installing Package => End\\n\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from jet_ml_dataset_builder.jet_ml_dataset_builder_utilities import  parse_parameters\n",
    "\n",
    "# Call the function and retrieve the tokenized parameters\n",
    "tokenized_arguments, tokenized_values = parse_parameters()\n",
    "\n",
    "# Access the tokenized arguments and values\n",
    "print(\"Tokenized Arguments:\")\n",
    "for argument in tokenized_arguments:\n",
    "    print(argument)\n",
    "\n",
    "print(\"\\nTokenized Values:\")\n",
    "for argument, value in tokenized_values.items():\n",
    "    print(f\"{argument}: {value}\")\n",
    "\n",
    "y_class_label_items=['MMAT','MLBT']\n",
    "alpha_s_items=[0.2 ,0.3 ,0.4]\n",
    "q0_items=[1.5 ,2.0 ,2.5]\n",
    "\n",
    "print(\"y_class_label_items:\",y_class_label_items)\n",
    "print(\"alpha_s_items:\",alpha_s_items)\n",
    "print(\"q0_items:\",q0_items)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading the dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Building required params for the loading the dataset file\")\n",
    "\n",
    "class_labels_str = '_'.join(y_class_label_items)\n",
    "alpha_s_items_str='_'.join(map(str, alpha_s_items))\n",
    "q0_items_str='_'.join(map(str, q0_items))\n",
    "total_size=9*1200000\n",
    "# for shuffled_y_processed\n",
    "# dataset_file_name = f\"jet_ml_benchmark_config_01_to_09_alpha_{alpha_s_items_str}_q0_{q0_items_str}_{class_labels_str}_size_{total_size}_split_train_datasets/train_split_0.pkl\"\n",
    "# for shuffled\n",
    "dataset_file_name = f\"jet_ml_benchmark_config_01_to_09_alpha_{alpha_s_items_str}_q0_{q0_items_str}_{class_labels_str}_size_{total_size}_shuffled.pkl\"\n",
    "dataset_file_name=simulation_directory_path+dataset_file_name\n",
    "print(\"dataset_file_name:\",dataset_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from jet_ml_dataset_builder.jet_ml_dataset_builder_utilities import load_dataset\n",
    "# dataset=load_dataset (dataset_file_name,has_test=False)\n",
    "# (dataset_x, dataset_y)=dataset\n",
    "# print(\"dataset y_train values:\\n\", dataset_x[1:10])\n",
    "# print(\"dataset y_test values:\\n\", dataset_y[1:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from jet_ml_dataset_builder.jet_ml_dataset_builder_utilities import load_dataset\n",
    "dataset=load_dataset (dataset_file_name)\n",
    "((dataset_x, dataset_y),(x_test,y_test))=dataset\n",
    "print(\"dataset y_train values:\\n\", dataset_x[1:10])\n",
    "print(\"dataset y_test values:\\n\", dataset_y[1:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "making 1000 dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_dataset(dataset_x, dataset_y, train_size, test_size):\n",
    "    \"\"\"\n",
    "    Split a dataset into training and test sets.\n",
    "\n",
    "    Parameters:\n",
    "    - dataset: Dictionary or object containing 'x' and 'y' numpy arrays.\n",
    "    - train_size: Number of samples for the training set.\n",
    "    - test_size: Number of samples for the test set.\n",
    "\n",
    "    Returns:\n",
    "    - x_train, y_train, x_test, y_test: Numpy arrays for the training and test sets.\n",
    "    \"\"\"\n",
    "    # Create the training dataset\n",
    "    # Create the training dataset\n",
    "    x_train = dataset_x[:train_size]\n",
    "    y_train = dataset_y[:train_size]\n",
    "\n",
    "    # Create the test dataset\n",
    "    x_test = dataset_x[train_size:train_size + test_size]\n",
    "    y_test = dataset_y[train_size:train_size + test_size]\n",
    "\n",
    "    return x_train, y_train, x_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Assuming your original dataset is named dataset\n",
    "# train_size = 900\n",
    "# test_size = 100\n",
    "\n",
    "# x_train, y_train, x_test, y_test = split_dataset(dataset_x, dataset_y, train_size, test_size)\n",
    "\n",
    "# # Display the shapes of the training and test datasets\n",
    "# print(\"Training set shapes - x:\", x_train.shape, \" y:\", y_train.shape)\n",
    "# print(\"Test set shapes - x:\", x_test.shape, \" y:\", y_test.shape)\n",
    "\n",
    "# from jet_ml_dataset_builder.jet_ml_dataset_builder_utilities import save_dataset\n",
    "# dataset_file_name = f\"jet_ml_benchmark_config_01_to_09_alpha_{alpha_s_items_str}_q0_{q0_items_str}_{class_labels_str}_size_{1000}_shuffled.pkl\"\n",
    "# dataset_file_name=simulation_directory_path+dataset_file_name\n",
    "# print(\"dataset_file_name:\",dataset_file_name)\n",
    "# save_dataset(dataset_file_name,(x_train, y_train, x_test, y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_size = 9000\n",
    "# test_size = 1000\n",
    "\n",
    "# x_train, y_train, x_test, y_test = split_dataset(dataset_x, dataset_y, train_size, test_size)\n",
    "\n",
    "# # Display the shapes of the training and test datasets\n",
    "# print(\"Training set shapes - x:\", x_train.shape, \" y:\", y_train.shape)\n",
    "# print(\"Test set shapes - x:\", x_test.shape, \" y:\", y_test.shape)\n",
    "\n",
    "# from jet_ml_dataset_builder.jet_ml_dataset_builder_utilities import save_dataset\n",
    "# dataset_file_name = f\"jet_ml_benchmark_config_01_to_09_alpha_{alpha_s_items_str}_q0_{q0_items_str}_{class_labels_str}_size_{10000}_shuffled.pkl\"\n",
    "# dataset_file_name=simulation_directory_path+dataset_file_name\n",
    "# print(\"dataset_file_name:\",dataset_file_name)\n",
    "# save_dataset(dataset_file_name,(x_train, y_train, x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = 90000\n",
    "test_size = 10000\n",
    "\n",
    "x_train, y_train, x_test, y_test = split_dataset(dataset_x, dataset_y, train_size, test_size)\n",
    "\n",
    "# Display the shapes of the training and test datasets\n",
    "print(\"Training set shapes - x:\", x_train.shape, \" y:\", y_train.shape)\n",
    "print(\"Test set shapes - x:\", x_test.shape, \" y:\", y_test.shape)\n",
    "\n",
    "from jet_ml_dataset_builder.jet_ml_dataset_builder_utilities import save_dataset\n",
    "dataset_file_name = f\"jet_ml_benchmark_config_01_to_09_alpha_{alpha_s_items_str}_q0_{q0_items_str}_{class_labels_str}_size_{100000}_shuffled.pkl\"\n",
    "dataset_file_name=simulation_directory_path+dataset_file_name\n",
    "print(\"dataset_file_name:\",dataset_file_name)\n",
    "save_dataset(dataset_file_name,(x_train, y_train, x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = 900000\n",
    "test_size = 100000\n",
    "\n",
    "x_train, y_train, x_test, y_test = split_dataset(dataset_x, dataset_y, train_size, test_size)\n",
    "\n",
    "# Display the shapes of the training and test datasets\n",
    "print(\"Training set shapes - x:\", x_train.shape, \" y:\", y_train.shape)\n",
    "print(\"Test set shapes - x:\", x_test.shape, \" y:\", y_test.shape)\n",
    "\n",
    "from jet_ml_dataset_builder.jet_ml_dataset_builder_utilities import save_dataset\n",
    "dataset_file_name = f\"jet_ml_benchmark_config_01_to_09_alpha_{alpha_s_items_str}_q0_{q0_items_str}_{class_labels_str}_size_{1000000}_shuffled.pkl\"\n",
    "dataset_file_name=simulation_directory_path+dataset_file_name\n",
    "print(\"dataset_file_name:\",dataset_file_name)\n",
    "save_dataset(dataset_file_name,(x_train, y_train, x_test, y_test))"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
