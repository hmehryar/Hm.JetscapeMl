{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_namespace():\n",
    "    import sys\n",
    "    sys.path.insert(1,f'/wsu/home/gy/gy40/gy4065/hm_jetscapeml_source')#WSU Grid\n",
    "    sys.path.insert(1,'/content/drive/My Drive/Projects/110_JetscapeMl/hm_jetscapeml_source')#Colab GDrive v1\n",
    "    sys.path.insert(1,'/content/drive/MyDrive/Projects/110_JetscapeMl/hm_jetscapeml_source')#Colab GDrive v2\n",
    "    sys.path.insert(1,f'/mnt/g/My Drive/Projects/110_JetscapeMl/hm_jetscapeml_source')#wsl gdrive\n",
    "    sys.path.insert(1,'G:\\\\My Drive\\\\Projects\\\\110_JetscapeMl\\\\hm_jetscapeml_source') #Windows GDrive\n",
    "    sys.path.insert(1,'/home/arsalan/Projects/110_JetscapeML/hm_jetscapeml_source/') #office tower\n",
    "    \n",
    "load_namespace()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-17 23:28:17.878320: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-09-17 23:28:17.938669: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-09-17 23:28:17.958434: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-09-17 23:28:18.017149: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-09-17 23:28:19.893889: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory /mnt/g/My Drive/Projects/110_JetscapeMl/hm_jetscapeml_source/models/alpha_s_res_net_5_fold_2_epoch_1k_dataset_size already exists.\n",
      "Directory /mnt/g/My Drive/Projects/110_JetscapeMl/hm_jetscapeml_source/reports/alpha_s_res_net_5_fold_2_epoch_1k_dataset_size already exists.\n",
      "Directory /mnt/g/My Drive/Projects/110_JetscapeMl/hm_jetscapeml_source/reports/figures/alpha_s_res_net_5_fold_2_epoch_1k_dataset_size already exists.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1726630102.106482    5206 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Project Root: /mnt/g/My Drive/Projects/110_JetscapeMl/hm_jetscapeml_source\\nData Directory: /mnt/g/My Drive/Projects/110_JetscapeMl/hm_jetscapeml_source/data\\nModels Directory: /mnt/g/My Drive/Projects/110_JetscapeMl/hm_jetscapeml_source/models\\nReports Directory: /mnt/g/My Drive/Projects/110_JetscapeMl/hm_jetscapeml_source/reports\\nFigures Directory: /mnt/g/My Drive/Projects/110_JetscapeMl/hm_jetscapeml_source/reports/figures\\nSimulation Models Directory: /mnt/g/My Drive/Projects/110_JetscapeMl/hm_jetscapeml_source/models/alpha_s_res_net_5_fold_2_epoch_1k_dataset_size\\nSimulation Reports Directory: /mnt/g/My Drive/Projects/110_JetscapeMl/hm_jetscapeml_source/reports/alpha_s_res_net_5_fold_2_epoch_1k_dataset_size\\nSimulation Figures Directory: /mnt/g/My Drive/Projects/110_JetscapeMl/hm_jetscapeml_source/reports/figures/alpha_s_res_net_5_fold_2_epoch_1k_dataset_size\\nEnvironment Details:\\n  TensorFlow Version: 2.17.0\\n  Keras Version: 3.5.0\\n  Python Version: 3.12.5 | packaged by conda-forge | (main, Aug  8 2024, 18:36:51) [GCC 12.4.0]\\n  Pandas Version: 2.2.2\\n  Scikit-Learn Version: 1.5.1\\n  GPU is available'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1726630102.345378    5206 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1726630102.346209    5206 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n"
     ]
    }
   ],
   "source": [
    "# Loading/Preparing Environment for simulation\n",
    "from jet_ml.config import Config\n",
    "folds=5\n",
    "epochs=2\n",
    "dataset_size=1000 #10800000 #1000000\n",
    "model_name=\"res_net\"\n",
    "simulation_name=f\"alpha_s_{model_name}_{folds}_fold_{epochs}_epoch_{int(dataset_size/1000)}k_dataset_size\"\n",
    "\n",
    "config=Config(simulation_name=simulation_name)\n",
    "config.__str__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPUs Available:  [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Disable GPU by setting visible devices to only CPU\n",
    "tf.config.set_visible_devices([], 'GPU')\n",
    "\n",
    "# Optionally, check if GPUs are available (should show an empty list)\n",
    "print(\"GPUs Available: \", tf.config.list_physical_devices('GPU'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Preprocessor\n",
      "Loading the whole dataset\n",
      "Extract the working column#1 for classification\n",
      "dataset.x: <class 'numpy.ndarray'> 1024000 (1000, 32, 32)\n",
      "dataset.y: <class 'numpy.ndarray'> 1000 (1000,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'y_classes: '"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Index(['0.2', '0.3', '0.4'], dtype='object')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'y: '"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [1, 0, 0],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'y_raw: '"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array(['0.4', '0.4', '0.2', '0.4', '0.4'], dtype='<U32')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display\n",
    "# with tf.device(\"CPU\"):\n",
    "import jet_ml.classifiers.alpha_s.preprocess_dataset as pred\n",
    "(x,y_raw,y_df)=pred.preprocess_dataset_for_alpha_s(dataset_size)\n",
    "y_classes=y_df.columns\n",
    "y=y_df.values\n",
    "display(\"y_classes: \",y_classes)\n",
    "display(\"y: \",y[:5])\n",
    "display(\"y_raw: \",y_raw[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_normalized(x):\n",
    "    import numpy as np\n",
    "    return np.max(x) <= 1\n",
    "\n",
    "def convert_to_rgb(x):\n",
    "    import numpy as np\n",
    "    import tensorflow as tf\n",
    "    # Convert grayscale to RGB (if needed)\n",
    "    x_rgb = np.concatenate([x] * 3, axis=-1)  # Convert to RGB\n",
    "    return x_rgb\n",
    "\n",
    "def resize_images(x,width=32,height=32,device=\"/CPU:0\"):\n",
    "    import numpy as np\n",
    "    import tensorflow as tf\n",
    "    # Resize images to the target size\n",
    "    TARGET_WIDTH = width\n",
    "    TARGET_HEIGHT = height\n",
    "    # with tf.device('/CPU:0'):\n",
    "    x_resized = np.array([tf.image.resize(image, [TARGET_HEIGHT, TARGET_WIDTH]) for image in x])\n",
    "    return x_resized\n",
    "def resize_y(y):\n",
    "    import numpy as np\n",
    "    # Optionally, you might want to add an extra dimension if needed\n",
    "    y_resized = np.expand_dims(y, axis=2)  # Shape will be (1, 3, 1000)\n",
    "    return y_resized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1726630140.093076    5206 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1726630140.093818    5206 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1726630140.094415    5206 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1726630140.484795    5206 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1726630140.485345    5206 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-09-17 23:29:00.485361: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2112] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "I0000 00:00:1726630140.485829    5206 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-09-17 23:29:00.485920: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 2242 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1650 Ti with Max-Q Design, pci bus id: 0000:01:00.0, compute capability: 7.5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'x.shape (1000, 32, 32, 1)'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'y.shape (1000, 3)'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Data is normalized: True'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'x_rgb.shape (1000, 32, 32, 3)'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'x_resized.shape (1000, 256, 256, 3)'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'y_resized.shape (1000, 3, 1)'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#implementing the preprocess_dataset_for_resnet function\n",
    "def preprocess_dataset_for_resnet(x,y,width=32,height=32):\n",
    "    display(\"x.shape {0}\".format(x.shape))\n",
    "    display(\"y.shape {0}\".format(y.shape))\n",
    "    \n",
    "    display(\"Data is normalized: {0}\".format(is_normalized(x)))\n",
    "    \n",
    "    x_rgb=convert_to_rgb(x)\n",
    "    display(\"x_rgb.shape {0}\".format(x_rgb.shape))\n",
    "    \n",
    "    x_resized=resize_images(x_rgb,width,height)\n",
    "    display(\"x_resized.shape {0}\".format(x_resized.shape))\n",
    "    \n",
    "    y_resized=resize_y(y)\n",
    "    display(\"y_resized.shape {0}\".format(y_resized.shape))\n",
    "    return x_resized,y_resized\n",
    "\n",
    "WIDTH = 256\n",
    "HEIGHT = 256\n",
    "import tensorflow as tf\n",
    "with tf.device(\"/CPU:0\"):\n",
    "    x_resized,y_resized= preprocess_dataset_for_resnet(x,y,WIDTH,HEIGHT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "#checking data is normalize\n",
    "print(\"checking data is normalize\")\n",
    "x_max=np.max(x)\n",
    "display(x_max)\n",
    "display(x.shape)\n",
    "display(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "WIDTH = 256\n",
    "HEIGHT = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "# Convert grayscale to RGB (if needed)\n",
    "x_rgb = np.concatenate([x] * 3, axis=-1)  # Convert to RGB\n",
    "\n",
    "# Resize images to the target size\n",
    "TARGET_WIDTH = 256\n",
    "TARGET_HEIGHT = 256\n",
    "with tf.device(\"GPU\"):\n",
    "    x_resized = np.array([tf.image.resize(image, [HEIGHT, WIDTH]) for image in x_rgb])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transpose and then rearrange the dimensions\n",
    "y_transposed = np.transpose(y)  # Shape will be (3, 1000)\n",
    "\n",
    "# y_transposed is now (3, 1000)\n",
    "print(\"Transposed shape:\", y_transposed.shape)\n",
    "\n",
    "# Optionally, you might want to add an extra dimension if needed\n",
    "y_resized = np.expand_dims(y, axis=2)  # Shape will be (1, 3, 1000)\n",
    "\n",
    "# Check the final shape\n",
    "print(\"Final shape:\", y_resized.shape)  # Should be (1, 3, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training size: 900\n",
      "Validate size: 100\n"
     ]
    }
   ],
   "source": [
    "TRAIN_PCT = 0.9\n",
    "TRAIN_CUT = int(len(x) * TRAIN_PCT)\n",
    "\n",
    "x_df_train_cut = x_resized[0:TRAIN_CUT]\n",
    "x_df_validate_cut = x_resized[TRAIN_CUT:]\n",
    "\n",
    "y_df_train_cut = y_resized[0:TRAIN_CUT]\n",
    "y_df_validate_cut = y_resized[TRAIN_CUT:]\n",
    "\n",
    "\n",
    "print(f\"Training size: {len(x_df_train_cut)}\")\n",
    "print(f\"Validate size: {len(x_df_validate_cut)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "# Define ImageDataGenerator\n",
    "training_datagen = ImageDataGenerator(\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "\n",
    "# Keeping the training batch size small \n",
    "# USUALLY increases performance\n",
    "train_batch_size = 32\n",
    "\n",
    "# Create the data generator\n",
    "train_generator = training_datagen.flow(\n",
    "    x_df_train_cut,\n",
    "    y_df_train_cut,\n",
    "    batch_size=train_batch_size,\n",
    "    shuffle=True,\n",
    "    seed=42  # For reproducibility\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "validation_datagen = ImageDataGenerator()\n",
    "\n",
    "# Make the validation batch size as large as you \n",
    "# have memory for\n",
    "validation_batch_size = 16\n",
    "\n",
    "val_generator = validation_datagen.flow(\n",
    "        x_df_validate_cut,\n",
    "        y_df_validate_cut,\n",
    "        batch_size=validation_batch_size,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(input_tensor,num_classes,activation='softmax'):\n",
    "    from tensorflow.keras.applications.resnet50 import ResNet50\n",
    "    base_model = ResNet50(\n",
    "    include_top=False, weights=None, input_tensor=input_tensor,\n",
    "    input_shape=None)\n",
    "\n",
    "    from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
    "    from tensorflow.keras.models import Model\n",
    "    x=base_model.output\n",
    "    x=GlobalAveragePooling2D()(x)\n",
    "    model=Model(inputs=base_model.input,outputs=Dense(num_classes,activation=activation)(x),name='ResNet50')\n",
    "    return model\n",
    "\n",
    "with tf.device('/CPU:0'):#/GPU:0\n",
    "    from tensorflow.keras.layers import Input\n",
    "    input_tensor = Input(shape=(HEIGHT, WIDTH, 3))\n",
    "    model=build_model(input_tensor,num_classes=3,activation='softmax')\n",
    "    # model.summary()\n",
    "    import tensorflow as tf\n",
    "\n",
    "    from jet_ml.models.helpers import compile_model\n",
    "    model=compile_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.device('/CPU:0'):\n",
    "    from tensorflow.keras.applications.resnet50 import ResNet50\n",
    "    from tensorflow.keras.layers import Input\n",
    "    import tensorflow as tf\n",
    "    # Enable logging of device placement\n",
    "    tf.debugging.set_log_device_placement(True)\n",
    "\n",
    "    input_tensor = Input(shape=(HEIGHT, WIDTH, 3))\n",
    "    base_model = ResNet50(\n",
    "        include_top=False, weights=None, input_tensor=input_tensor,\n",
    "        input_shape=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with tf.device('/CPU:0'):\n",
    "    from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
    "    from tensorflow.keras.models import Model\n",
    "    x=base_model.output\n",
    "    x=GlobalAveragePooling2D()(x)\n",
    "    model=Model(inputs=base_model.input,outputs=Dense(y_classes.size,activation='softmax')(x),name='ResNet50')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.device('/CPU:0'):\n",
    "    from tensorflow.keras.callbacks import EarlyStopping\n",
    "    # Important, calculate a valid step size for the validation dataset\n",
    "    STEP_SIZE_VALID=val_generator.n//val_generator.batch_size\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/arsi/miniconda3/envs/tensorflow/lib/python3.12/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:122: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1726630324.888083    5271 service.cc:146] XLA service 0x7fac900b8d60 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1726630324.888240    5271 service.cc:154]   StreamExecutor device (0): Host, Default Version\n",
      "2024-09-17 23:32:06.049386: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "I0000 00:00:1726630361.828552    5271 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "2024-09-17 23:32:41.864047: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 2072288504 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m 1/28\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m43:27\u001b[0m 97s/step - accuracy: 0.1042 - loss: 1.2110"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-17 23:33:14.386645: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 2072288504 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m 2/28\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m12:43\u001b[0m 29s/step - accuracy: 0.1823 - loss: 1.9067"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-17 23:33:43.719285: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 2072288504 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m 4/28\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m12:24\u001b[0m 31s/step - accuracy: 0.2391 - loss: 2.4627"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-17 23:34:47.445488: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 2072288504 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m 5/28\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m11:59\u001b[0m 31s/step - accuracy: 0.2675 - loss: 2.4990"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-17 23:35:19.510583: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 2072288504 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m 9/28\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m9:48\u001b[0m 31s/step - accuracy: 0.2900 - loss: 2.4163 "
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 43\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtf\u001b[39;00m\n\u001b[1;32m     42\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/CPU:0\u001b[39m\u001b[38;5;124m'\u001b[39m):\u001b[38;5;66;03m#/GPU:0\u001b[39;00m\n\u001b[0;32m---> 43\u001b[0m     \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtrain_generator\u001b[49m\u001b[43m,\u001b[49m\u001b[43mval_generator\u001b[49m\u001b[43m,\u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43mmonitor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmonitor\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[12], line 25\u001b[0m, in \u001b[0;36mtrain_model\u001b[0;34m(model, train_generator, val_generator, epochs, monitor, fold, verbose)\u001b[0m\n\u001b[1;32m     21\u001b[0m STEP_SIZE_VALID\u001b[38;5;241m=\u001b[39mval_generator\u001b[38;5;241m.\u001b[39mn\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39mval_generator\u001b[38;5;241m.\u001b[39mbatch_size\n\u001b[1;32m     22\u001b[0m display(STEP_SIZE_VALID)\n\u001b[0;32m---> 25\u001b[0m history\u001b[38;5;241m=\u001b[39m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_generator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     26\u001b[0m \u001b[43m                \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msteps_per_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mSTEP_PER_EPOCH\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     27\u001b[0m \u001b[43m                \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_generator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     28\u001b[0m \u001b[43m                \u001b[49m\u001b[43mvalidation_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mSTEP_SIZE_VALID\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     29\u001b[0m \u001b[43m                \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     30\u001b[0m \u001b[43m                \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mjet_ml\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mhelpers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m extract_stopped_epoch\n\u001b[1;32m     33\u001b[0m stoppped_epoch\u001b[38;5;241m=\u001b[39mextract_stopped_epoch(callbacks\u001b[38;5;241m=\u001b[39mcallbacks)\n",
      "File \u001b[0;32m~/miniconda3/envs/tensorflow/lib/python3.12/site-packages/keras/src/utils/traceback_utils.py:117\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/miniconda3/envs/tensorflow/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py:320\u001b[0m, in \u001b[0;36mTensorFlowTrainer.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[1;32m    318\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step, iterator \u001b[38;5;129;01min\u001b[39;00m epoch_iterator\u001b[38;5;241m.\u001b[39menumerate_epoch():\n\u001b[1;32m    319\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m--> 320\u001b[0m     logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    321\u001b[0m     logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pythonify_logs(logs)\n\u001b[1;32m    322\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_end(step, logs)\n",
      "File \u001b[0;32m~/miniconda3/envs/tensorflow/lib/python3.12/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/miniconda3/envs/tensorflow/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:833\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    830\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    832\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 833\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    835\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    836\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/miniconda3/envs/tensorflow/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:878\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    875\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    876\u001b[0m \u001b[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[1;32m    877\u001b[0m \u001b[38;5;66;03m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[0;32m--> 878\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mtracing_compilation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    879\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_variable_creation_config\u001b[49m\n\u001b[1;32m    880\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    881\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_created_variables:\n\u001b[1;32m    882\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreating variables on a non-first call to a function\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    883\u001b[0m                    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m decorated with tf.function.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/tensorflow/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m bound_args \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    138\u001b[0m flat_inputs \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39munpack_inputs(bound_args)\n\u001b[0;32m--> 139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[1;32m    140\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflat_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\n\u001b[1;32m    141\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/tensorflow/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py:1322\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1318\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1319\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1320\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1321\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1322\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_preflattened\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1323\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1324\u001b[0m     args,\n\u001b[1;32m   1325\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1326\u001b[0m     executing_eagerly)\n\u001b[1;32m   1327\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[0;32m~/miniconda3/envs/tensorflow/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:216\u001b[0m, in \u001b[0;36mAtomicFunction.call_preflattened\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core\u001b[38;5;241m.\u001b[39mTensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m    215\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 216\u001b[0m   flat_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    217\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mpack_output(flat_outputs)\n",
      "File \u001b[0;32m~/miniconda3/envs/tensorflow/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:251\u001b[0m, in \u001b[0;36mAtomicFunction.call_flat\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[1;32m    250\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[0;32m--> 251\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bound_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    252\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    256\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    257\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\n\u001b[1;32m    258\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    259\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[1;32m    260\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mfunction_call_options\u001b[38;5;241m.\u001b[39mas_attrs(),\n\u001b[1;32m    261\u001b[0m     )\n",
      "File \u001b[0;32m~/miniconda3/envs/tensorflow/lib/python3.12/site-packages/tensorflow/python/eager/context.py:1552\u001b[0m, in \u001b[0;36mContext.call_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1550\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[1;32m   1551\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1552\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1553\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1554\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1555\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1556\u001b[0m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1557\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1558\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1560\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m   1561\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1562\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1566\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[1;32m   1567\u001b[0m   )\n",
      "File \u001b[0;32m~/miniconda3/envs/tensorflow/lib/python3.12/site-packages/tensorflow/python/eager/execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import keras\n",
    "def train_model(model,train_generator, val_generator, epochs,\n",
    "                monitor=None,\n",
    "                fold=None,\n",
    "                verbose=1):\n",
    "    keras.backend.clear_session()\n",
    "    from jet_ml.models.helpers import get_best_model_filename\n",
    "    best_model_filename=get_best_model_filename(model.name,fold=fold)\n",
    "    \n",
    "    from jet_ml.models.helpers import get_callbacks\n",
    "    callbacks = get_callbacks(monitor=monitor,\n",
    "                              model_checkpoint_best_model_filename=best_model_filename)\n",
    "\n",
    "    import time\n",
    "    start_time=time.time()\n",
    "\n",
    "    STEP_PER_EPOCH=train_generator.n//train_generator.batch_size \n",
    "    display(STEP_PER_EPOCH)\n",
    "\n",
    "    # Important, calculate a valid step size for the validation dataset\n",
    "    STEP_SIZE_VALID=val_generator.n//val_generator.batch_size\n",
    "    display(STEP_SIZE_VALID)\n",
    "    \n",
    "\n",
    "    history=model.fit(train_generator, \n",
    "                    epochs=epochs, steps_per_epoch=STEP_PER_EPOCH, \n",
    "                    validation_data=val_generator,\n",
    "                    validation_steps=STEP_SIZE_VALID,\n",
    "                    callbacks=callbacks,\n",
    "                    verbose = verbose)\n",
    "\n",
    "    from jet_ml.models.helpers import extract_stopped_epoch\n",
    "    stoppped_epoch=extract_stopped_epoch(callbacks=callbacks)\n",
    "    elapsed_time=time.time()-start_time\n",
    "    import jet_ml.helpers as helpers\n",
    "    print(\"Elpased time: {}\".format(helpers.hms_string(elapsed_time)))\n",
    "    return model, history, elapsed_time,stoppped_epoch\n",
    "\n",
    "epochs=2\n",
    "monitor='val_loss' #'val_accuracy' or 'val_loss'\n",
    "import tensorflow as tf\n",
    "with tf.device('/CPU:0'):#/GPU:0\n",
    "    train_model(model,train_generator,val_generator,epochs=epochs,monitor=monitor)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/arsi/miniconda3/envs/tensorflow/lib/python3.12/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:122: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1726629164.195966    4976 service.cc:146] XLA service 0x7f4da40ba7c0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1726629164.196104    4976 service.cc:154]   StreamExecutor device (0): Host, Default Version\n",
      "2024-09-17 23:12:45.077663: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "I0000 00:00:1726629199.226423    4976 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "2024-09-17 23:13:19.245836: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 2072288504 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m 1/31\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m43:05\u001b[0m 86s/step - accuracy: 0.0000e+00 - loss: 1.2702"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-17 23:13:44.963982: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 2072288504 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m 2/31\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m12:22\u001b[0m 26s/step - accuracy: 0.1016 - loss: 1.7463    "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-17 23:14:10.571268: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 2072288504 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m 3/31\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m11:40\u001b[0m 25s/step - accuracy: 0.1406 - loss: 2.2852"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-17 23:14:34.969078: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 2072288504 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m 4/31\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m11:10\u001b[0m 25s/step - accuracy: 0.1882 - loss: 2.5853"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-17 23:14:59.439131: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 2072288504 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m29/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m48s\u001b[0m 24s/step - accuracy: 0.2918 - loss: 2.2267 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-17 23:25:03.837001: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n",
      "/home/arsi/miniconda3/envs/tensorflow/lib/python3.12/contextlib.py:158: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
      "  self.gen.throw(value)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m775s\u001b[0m 23s/step - accuracy: 0.2942 - loss: 2.1918 - val_accuracy: 0.0000e+00 - val_loss: 1.0758\n",
      "Epoch 2/5\n",
      "\u001b[1m 4/31\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m12:42\u001b[0m 28s/step - accuracy: 0.6345 - loss: 1.3835"
     ]
    }
   ],
   "source": [
    "with tf.device('/CPU:0'):\n",
    "        monitor = EarlyStopping(monitor='val_loss', min_delta=1e-3, \n",
    "        patience=50, verbose=1, mode='auto',\n",
    "        restore_best_weights=True)\n",
    "        history=model.fit(train_generator, epochs=5, steps_per_epoch=len(x_resized) // train_batch_size, \n",
    "          validation_data=val_generator,callbacks=[monitor],\n",
    "          verbose = 1,validation_steps=STEP_SIZE_VALID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fold, shuffle, x, y_raw\n",
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn import metrics\n",
    "k_fold=StratifiedKFold(folds,shuffle=False)\n",
    "\n",
    "out_of_sample_y=[]\n",
    "out_of_sample_pred=[]\n",
    "fold=0\n",
    "folds_accuracy=[]\n",
    "epochs_needed = []\n",
    "times_taken=[]\n",
    "#Must specify y StratifiedKFold for classification\n",
    "for train,test in k_fold.split(x,y_raw):\n",
    "    fold+=1\n",
    "    print(f\"Fold #{fold}\")\n",
    "\n",
    "    x_train=x[train]\n",
    "    y_train=y[train]\n",
    "    x_test=x[test]\n",
    "    y_test=y[test]\n",
    "\n",
    "    from jet_ml.models import vgg16_net\n",
    "    input_shape=x[0].shape\n",
    "    output_shape=y.shape[1]\n",
    "    activation='softmax'\n",
    "    # HIDE OUTPUT\n",
    "    from tensorflow.keras.applications import MobileNet\n",
    "    model = MobileNet(weights='imagenet',include_top=True)\n",
    "    model.summary()\n",
    "    model=vgg16_net.build_model(input_shape,output_shape,activation)\n",
    "    model=vgg16_net.compile_model(model)\n",
    "\n",
    "\n",
    "    batch_size=128\n",
    "    # batch_size=256 #original patch size applies for eloss classification\n",
    "    monitor='val_loss' #'val_accuracy' or 'val_loss'\n",
    "    \n",
    "    model, history,elapsed_time,stopped_epoch=vgg16_net.train_model(model,\n",
    "                                        x_train,y_train, x_test,y_test, \n",
    "                                        epochs, batch_size, monitor,\n",
    "                                        fold=fold)\n",
    "\n",
    "    from jet_ml.evaluation import get_accuracy\n",
    "    pred, score=get_accuracy(model,x_test=x_test,y_test=y_test)\n",
    "    \n",
    "    folds_accuracy.append(score)\n",
    "    times_taken.append(elapsed_time)    \n",
    "    epochs_needed.append(epochs)\n",
    "\n",
    "    out_of_sample_y.append(y_test)\n",
    "    out_of_sample_pred.append(pred)\n",
    "    print(f\"Fold score (accuracy): {score}\")\n",
    "\n",
    "    from jet_ml.evaluation import save_training_history\n",
    "    save_training_history(history=history,fold=fold)\n",
    "\n",
    "    from jet_ml.evaluation import plot_training_history\n",
    "    plot_training_history(history=history,fold=fold)\n",
    "\n",
    "from jet_ml.evaluation import save_training_stats\n",
    "save_training_stats(accuracies=folds_accuracy,\n",
    "                    epochs_needed=epochs_needed,\n",
    "                    times_taken=times_taken)\n",
    "\n",
    "# # Build the oos prediction list and calculate the error.\n",
    "out_of_sample_y=np.concatenate(out_of_sample_y)\n",
    "out_of_sample_pred=np.concatenate(out_of_sample_pred)\n",
    "\n",
    "out_of_sample_y_compare=np.argmax(out_of_sample_y,axis=1)# For accuracy and confusion matrix calculation"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.12.5 (tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
