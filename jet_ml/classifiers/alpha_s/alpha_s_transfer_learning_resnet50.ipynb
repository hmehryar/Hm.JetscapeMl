{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_namespace():\n",
    "    import sys\n",
    "    sys.path.insert(1,f'/wsu/home/gy/gy40/gy4065/hm_jetscapeml_source')#WSU Grid\n",
    "    sys.path.insert(1,'/content/drive/My Drive/Projects/110_JetscapeMl/hm_jetscapeml_source')#Colab GDrive v1\n",
    "    sys.path.insert(1,'/content/drive/MyDrive/Projects/110_JetscapeMl/hm_jetscapeml_source')#Colab GDrive v2\n",
    "    sys.path.insert(1,f'/mnt/g/My Drive/Projects/110_JetscapeMl/hm_jetscapeml_source')#wsl gdrive\n",
    "    sys.path.insert(1,'G:\\\\My Drive\\\\Projects\\\\110_JetscapeMl\\\\hm_jetscapeml_source') #Windows GDrive\n",
    "    sys.path.insert(1,'/home/arsalan/Projects/110_JetscapeML/hm_jetscapeml_source/') #office tower\n",
    "    \n",
    "load_namespace()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-17 23:07:15.685595: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-09-17 23:07:15.709135: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-09-17 23:07:15.716980: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-09-17 23:07:15.737738: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-09-17 23:07:17.617969: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory /mnt/g/My Drive/Projects/110_JetscapeMl/hm_jetscapeml_source/models/alpha_s_res_net_5_fold_2_epoch_1k_dataset_size already exists.\n",
      "Directory /mnt/g/My Drive/Projects/110_JetscapeMl/hm_jetscapeml_source/reports/alpha_s_res_net_5_fold_2_epoch_1k_dataset_size already exists.\n",
      "Directory /mnt/g/My Drive/Projects/110_JetscapeMl/hm_jetscapeml_source/reports/figures/alpha_s_res_net_5_fold_2_epoch_1k_dataset_size already exists.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1726628840.007128    4908 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1726628840.063622    4908 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1726628840.064311    4908 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Project Root: /mnt/g/My Drive/Projects/110_JetscapeMl/hm_jetscapeml_source\\nData Directory: /mnt/g/My Drive/Projects/110_JetscapeMl/hm_jetscapeml_source/data\\nModels Directory: /mnt/g/My Drive/Projects/110_JetscapeMl/hm_jetscapeml_source/models\\nReports Directory: /mnt/g/My Drive/Projects/110_JetscapeMl/hm_jetscapeml_source/reports\\nFigures Directory: /mnt/g/My Drive/Projects/110_JetscapeMl/hm_jetscapeml_source/reports/figures\\nSimulation Models Directory: /mnt/g/My Drive/Projects/110_JetscapeMl/hm_jetscapeml_source/models/alpha_s_res_net_5_fold_2_epoch_1k_dataset_size\\nSimulation Reports Directory: /mnt/g/My Drive/Projects/110_JetscapeMl/hm_jetscapeml_source/reports/alpha_s_res_net_5_fold_2_epoch_1k_dataset_size\\nSimulation Figures Directory: /mnt/g/My Drive/Projects/110_JetscapeMl/hm_jetscapeml_source/reports/figures/alpha_s_res_net_5_fold_2_epoch_1k_dataset_size\\nEnvironment Details:\\n  TensorFlow Version: 2.17.0\\n  Keras Version: 3.5.0\\n  Python Version: 3.12.5 | packaged by conda-forge | (main, Aug  8 2024, 18:36:51) [GCC 12.4.0]\\n  Pandas Version: 2.2.2\\n  Scikit-Learn Version: 1.5.1\\n  GPU is available'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loading/Preparing Environment for simulation\n",
    "from jet_ml.config import Config\n",
    "folds=5\n",
    "epochs=2\n",
    "dataset_size=1000 #10800000 #1000000\n",
    "model_name=\"res_net\"\n",
    "simulation_name=f\"alpha_s_{model_name}_{folds}_fold_{epochs}_epoch_{int(dataset_size/1000)}k_dataset_size\"\n",
    "\n",
    "config=Config(simulation_name=simulation_name)\n",
    "config.__str__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPUs Available:  [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Disable GPU by setting visible devices to only CPU\n",
    "tf.config.set_visible_devices([], 'GPU')\n",
    "\n",
    "# Optionally, check if GPUs are available (should show an empty list)\n",
    "print(\"GPUs Available: \", tf.config.list_physical_devices('GPU'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display\n",
    "# with tf.device(\"CPU\"):\n",
    "import jet_ml.classifiers.alpha_s.preprocess_dataset as pred\n",
    "(x,y_raw,y_df)=pred.preprocess_dataset_for_alpha_s(dataset_size)\n",
    "y_classes=y_df.columns\n",
    "y=y_df.values\n",
    "display(\"y_classes: \",y_classes)\n",
    "display(\"y: \",y[:5])\n",
    "display(\"y_raw: \",y_raw[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_normalized(x):\n",
    "    import numpy as np\n",
    "    return np.max(x) <= 1\n",
    "\n",
    "def convert_to_rgb(x):\n",
    "    import numpy as np\n",
    "    import tensorflow as tf\n",
    "    # Convert grayscale to RGB (if needed)\n",
    "    x_rgb = np.concatenate([x] * 3, axis=-1)  # Convert to RGB\n",
    "    return x_rgb\n",
    "\n",
    "def resize_images(x,width=32,height=32,device=\"/CPU:0\"):\n",
    "    import numpy as np\n",
    "    import tensorflow as tf\n",
    "    # Resize images to the target size\n",
    "    TARGET_WIDTH = width\n",
    "    TARGET_HEIGHT = height\n",
    "    # with tf.device('/CPU:0'):\n",
    "    x_resized = np.array([tf.image.resize(image, [TARGET_HEIGHT, TARGET_WIDTH]) for image in x])\n",
    "    return x_resized\n",
    "def resize_y(y):\n",
    "    import numpy as np\n",
    "    # Optionally, you might want to add an extra dimension if needed\n",
    "    y_resized = np.expand_dims(y, axis=2)  # Shape will be (1, 3, 1000)\n",
    "    return y_resized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#implementing the preprocess_dataset_for_resnet function\n",
    "def preprocess_dataset_for_resnet(x,y,width=32,height=32):\n",
    "    display(\"x.shape {0}\".format(x.shape))\n",
    "    display(\"y.shape {0}\".format(y.shape))\n",
    "    \n",
    "    display(\"Data is normalized: {0}\".format(is_normalized(x)))\n",
    "    \n",
    "    x_rgb=convert_to_rgb(x)\n",
    "    display(\"x_rgb.shape {0}\".format(x_rgb.shape))\n",
    "    \n",
    "    x_resized=resize_images(x_rgb,width,height)\n",
    "    display(\"x_resized.shape {0}\".format(x_resized.shape))\n",
    "    \n",
    "    y_resized=resize_y(y)\n",
    "    display(\"y_resized.shape {0}\".format(y_resized.shape))\n",
    "    return x_resized,y_resized\n",
    "\n",
    "WIDTH = 256\n",
    "HEIGHT = 256\n",
    "x_resized,y_resized= preprocess_dataset_for_resnet(x,y,WIDTH,HEIGHT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "#checking data is normalize\n",
    "print(\"checking data is normalize\")\n",
    "x_max=np.max(x)\n",
    "display(x_max)\n",
    "display(x.shape)\n",
    "display(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "WIDTH = 256\n",
    "HEIGHT = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "# Convert grayscale to RGB (if needed)\n",
    "x_rgb = np.concatenate([x] * 3, axis=-1)  # Convert to RGB\n",
    "\n",
    "# Resize images to the target size\n",
    "TARGET_WIDTH = 256\n",
    "TARGET_HEIGHT = 256\n",
    "with tf.device(\"GPU\"):\n",
    "    x_resized = np.array([tf.image.resize(image, [HEIGHT, WIDTH]) for image in x_rgb])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transpose and then rearrange the dimensions\n",
    "y_transposed = np.transpose(y)  # Shape will be (3, 1000)\n",
    "\n",
    "# y_transposed is now (3, 1000)\n",
    "print(\"Transposed shape:\", y_transposed.shape)\n",
    "\n",
    "# Optionally, you might want to add an extra dimension if needed\n",
    "y_resized = np.expand_dims(y, axis=2)  # Shape will be (1, 3, 1000)\n",
    "\n",
    "# Check the final shape\n",
    "print(\"Final shape:\", y_resized.shape)  # Should be (1, 3, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_PCT = 0.9\n",
    "TRAIN_CUT = int(len(x) * TRAIN_PCT)\n",
    "\n",
    "x_df_train_cut = x_resized[0:TRAIN_CUT]\n",
    "x_df_validate_cut = x_resized[TRAIN_CUT:]\n",
    "\n",
    "y_df_train_cut = y_resized[0:TRAIN_CUT]\n",
    "y_df_validate_cut = y_resized[TRAIN_CUT:]\n",
    "\n",
    "\n",
    "print(f\"Training size: {len(x_df_train_cut)}\")\n",
    "print(f\"Validate size: {len(x_df_validate_cut)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "# Define ImageDataGenerator\n",
    "training_datagen = ImageDataGenerator(\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "\n",
    "# Keeping the training batch size small \n",
    "# USUALLY increases performance\n",
    "train_batch_size = 32\n",
    "\n",
    "# Create the data generator\n",
    "train_generator = training_datagen.flow(\n",
    "    x_df_train_cut,\n",
    "    y_df_train_cut,\n",
    "    batch_size=train_batch_size,\n",
    "    shuffle=True,\n",
    "    seed=42  # For reproducibility\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "validation_datagen = ImageDataGenerator()\n",
    "\n",
    "# Make the validation batch size as large as you \n",
    "# have memory for\n",
    "validation_batch_size = 16\n",
    "\n",
    "val_generator = validation_datagen.flow(\n",
    "        x_df_validate_cut,\n",
    "        y_df_validate_cut,\n",
    "        batch_size=validation_batch_size,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(input_tensor,num_classes,activation='softmax'):\n",
    "    from tensorflow.keras.applications.resnet50 import ResNet50\n",
    "    base_model = ResNet50(\n",
    "    include_top=False, weights=None, input_tensor=input_tensor,\n",
    "    input_shape=None)\n",
    "\n",
    "    from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
    "    from tensorflow.keras.models import Model\n",
    "    x=base_model.output\n",
    "    x=GlobalAveragePooling2D()(x)\n",
    "    model=Model(inputs=base_model.input,outputs=Dense(num_classes,activation=activation)(x),name='ResNet50')\n",
    "    return model\n",
    "with tf.device('/CPU:0'):#/GPU:0\n",
    "    from tensorflow.keras.layers import Input\n",
    "    input_tensor = Input(shape=(HEIGHT, WIDTH, 3))\n",
    "    model=build_model(input_tensor,num_classes=3,activation='softmax')\n",
    "    # model.summary()\n",
    "    import tensorflow as tf\n",
    "\n",
    "    from jet_ml.models.helpers import compile_model\n",
    "    model=compile_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications.resnet50 import ResNet50\n",
    "from tensorflow.keras.layers import Input\n",
    "import tensorflow as tf\n",
    "# Enable logging of device placement\n",
    "tf.debugging.set_log_device_placement(True)\n",
    "\n",
    "input_tensor = Input(shape=(HEIGHT, WIDTH, 3))\n",
    "base_model = ResNet50(\n",
    "    include_top=False, weights=None, input_tensor=input_tensor,\n",
    "    input_shape=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with tf.device('/CPU:0'):\n",
    "    from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
    "    from tensorflow.keras.models import Model\n",
    "    x=base_model.output\n",
    "    x=GlobalAveragePooling2D()(x)\n",
    "    model=Model(inputs=base_model.input,outputs=Dense(y_classes.size,activation='softmax')(x),name='ResNet50')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.device('/CPU:0'):\n",
    "    from tensorflow.keras.callbacks import EarlyStopping\n",
    "    # Important, calculate a valid step size for the validation dataset\n",
    "    STEP_SIZE_VALID=val_generator.n//val_generator.batch_size\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "def train_model(model,train_generator, val_generator, epochs,\n",
    "                monitor=None,\n",
    "                fold=None,\n",
    "                verbose=1):\n",
    "    keras.backend.clear_session()\n",
    "    from jet_ml.models.helpers import get_best_model_filename\n",
    "    best_model_filename=get_best_model_filename(model.name,fold=fold)\n",
    "    \n",
    "    from jet_ml.models.helpers import get_callbacks\n",
    "    callbacks = get_callbacks(monitor=monitor,\n",
    "                              model_checkpoint_best_model_filename=best_model_filename)\n",
    "\n",
    "    import time\n",
    "    start_time=time.time()\n",
    "\n",
    "    STEP_PER_EPOCH=train_generator.n//train_generator.batch_size \n",
    "    display(STEP_PER_EPOCH)\n",
    "\n",
    "    # Important, calculate a valid step size for the validation dataset\n",
    "    STEP_SIZE_VALID=val_generator.n//val_generator.batch_size\n",
    "    display(STEP_SIZE_VALID)\n",
    "    \n",
    "\n",
    "    history=model.fit(train_generator, \n",
    "                    epochs=epochs, steps_per_epoch=STEP_PER_EPOCH, \n",
    "                    validation_data=val_generator,\n",
    "                    validation_steps=STEP_SIZE_VALID,\n",
    "                    callbacks=callbacks,\n",
    "                    verbose = verbose)\n",
    "\n",
    "    from jet_ml.models.helpers import extract_stopped_epoch\n",
    "    stoppped_epoch=extract_stopped_epoch(callbacks=callbacks)\n",
    "    elapsed_time=time.time()-start_time\n",
    "    import jet_ml.helpers as helpers\n",
    "    print(\"Elpased time: {}\".format(helpers.hms_string(elapsed_time)))\n",
    "    return model, history, elapsed_time,stoppped_epoch\n",
    "\n",
    "epochs=2\n",
    "monitor='val_loss' #'val_accuracy' or 'val_loss'\n",
    "import tensorflow as tf\n",
    "with tf.device('/CPU:0'):#/GPU:0\n",
    "    train_model(model,train_generator,val_generator,epochs=epochs,monitor=monitor)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.device('/CPU:0'):\n",
    "        monitor = EarlyStopping(monitor='val_loss', min_delta=1e-3, \n",
    "        patience=50, verbose=1, mode='auto',\n",
    "        restore_best_weights=True)\n",
    "        history=model.fit(train_generator, epochs=5, steps_per_epoch=len(x_resized) // train_batch_size, \n",
    "          validation_data=val_generator,callbacks=[monitor],\n",
    "          verbose = 1,validation_steps=STEP_SIZE_VALID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fold, shuffle, x, y_raw\n",
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn import metrics\n",
    "k_fold=StratifiedKFold(folds,shuffle=False)\n",
    "\n",
    "out_of_sample_y=[]\n",
    "out_of_sample_pred=[]\n",
    "fold=0\n",
    "folds_accuracy=[]\n",
    "epochs_needed = []\n",
    "times_taken=[]\n",
    "#Must specify y StratifiedKFold for classification\n",
    "for train,test in k_fold.split(x,y_raw):\n",
    "    fold+=1\n",
    "    print(f\"Fold #{fold}\")\n",
    "\n",
    "    x_train=x[train]\n",
    "    y_train=y[train]\n",
    "    x_test=x[test]\n",
    "    y_test=y[test]\n",
    "\n",
    "    from jet_ml.models import vgg16_net\n",
    "    input_shape=x[0].shape\n",
    "    output_shape=y.shape[1]\n",
    "    activation='softmax'\n",
    "    # HIDE OUTPUT\n",
    "    from tensorflow.keras.applications import MobileNet\n",
    "    model = MobileNet(weights='imagenet',include_top=True)\n",
    "    model.summary()\n",
    "    model=vgg16_net.build_model(input_shape,output_shape,activation)\n",
    "    model=vgg16_net.compile_model(model)\n",
    "\n",
    "\n",
    "    batch_size=128\n",
    "    # batch_size=256 #original patch size applies for eloss classification\n",
    "    monitor='val_loss' #'val_accuracy' or 'val_loss'\n",
    "    \n",
    "    model, history,elapsed_time,stopped_epoch=vgg16_net.train_model(model,\n",
    "                                        x_train,y_train, x_test,y_test, \n",
    "                                        epochs, batch_size, monitor,\n",
    "                                        fold=fold)\n",
    "\n",
    "    from jet_ml.evaluation import get_accuracy\n",
    "    pred, score=get_accuracy(model,x_test=x_test,y_test=y_test)\n",
    "    \n",
    "    folds_accuracy.append(score)\n",
    "    times_taken.append(elapsed_time)    \n",
    "    epochs_needed.append(epochs)\n",
    "\n",
    "    out_of_sample_y.append(y_test)\n",
    "    out_of_sample_pred.append(pred)\n",
    "    print(f\"Fold score (accuracy): {score}\")\n",
    "\n",
    "    from jet_ml.evaluation import save_training_history\n",
    "    save_training_history(history=history,fold=fold)\n",
    "\n",
    "    from jet_ml.evaluation import plot_training_history\n",
    "    plot_training_history(history=history,fold=fold)\n",
    "\n",
    "from jet_ml.evaluation import save_training_stats\n",
    "save_training_stats(accuracies=folds_accuracy,\n",
    "                    epochs_needed=epochs_needed,\n",
    "                    times_taken=times_taken)\n",
    "\n",
    "# # Build the oos prediction list and calculate the error.\n",
    "out_of_sample_y=np.concatenate(out_of_sample_y)\n",
    "out_of_sample_pred=np.concatenate(out_of_sample_pred)\n",
    "\n",
    "out_of_sample_y_compare=np.argmax(out_of_sample_y,axis=1)# For accuracy and confusion matrix calculation"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.12.5 (tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
