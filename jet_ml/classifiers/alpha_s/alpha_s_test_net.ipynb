{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_namespace():\n",
    "    import sys\n",
    "    sys.path.insert(1,f'/wsu/home/gy/gy40/gy4065/hm.jetscapeml_source')\n",
    "    sys.path.insert(1,'/content/drive/My Drive/Projects/110_JetscapeMl/hm_jetscapeml_source')\n",
    "    sys.path.insert(1,'/content/drive/MyDrive/Projects/110_JetscapeMl/hm_jetscapeml_source')\n",
    "    sys.path.insert(1,f'/mnt/g/My Drive/Projects/110_JetscapeMl/hm_jetscapeml_source')\n",
    "    sys.path.insert(1,'G:\\\\My Drive\\\\Projects\\\\110_JetscapeMl\\\\hm_jetscapeml_source')\n",
    "load_namespace()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor Flow Version: 2.17.0\n",
      "Keras Version: 3.5.0\n",
      "\n",
      "Python 3.12.5 | packaged by conda-forge | (main, Aug  8 2024, 18:36:51) [GCC 12.4.0]\n",
      "Pandas 2.2.2\n",
      "Scikit-Learn 1.5.1\n",
      "GPU is available\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1724104215.595992    1858 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1724104215.962351    1858 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1724104215.963420    1858 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n"
     ]
    }
   ],
   "source": [
    "# What version of Python do you have?\n",
    "import sys\n",
    "\n",
    "import tensorflow.keras\n",
    "import pandas as pd\n",
    "import sklearn as sk\n",
    "import tensorflow as tf\n",
    "\n",
    "print(f\"Tensor Flow Version: {tf.__version__}\")\n",
    "print(f\"Keras Version: {tensorflow.keras.__version__}\")\n",
    "print()\n",
    "print(f\"Python {sys.version}\")\n",
    "print(f\"Pandas {pd.__version__}\")\n",
    "print(f\"Scikit-Learn {sk.__version__}\")\n",
    "gpu = len(tf.config.list_physical_devices('GPU'))>0\n",
    "print(\"GPU is\", \"available\" if gpu else \"NOT AVAILABLE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Preprocessor\n",
      "All Path are set\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-19 17:49:11.986147: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-08-19 17:49:12.046739: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-08-19 17:49:12.060981: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-08-19 17:49:12.226153: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-08-19 17:49:14.560727: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aggregatring all parameters values\n",
      "label_items:\n",
      " {'eloss_items': ['MMAT', 'MLBT'], 'alpha_s_items': [0.2, 0.3, 0.4], 'q0_items': [1.5, 2.0, 2.5]}\n",
      "Building required params for the loading the dataset file\n",
      "labels_str:\n",
      " {'eloss_items_str': 'MMAT_MLBT', 'alpha_s_items_str': '0.2_0.3_0.4', 'q0_items_str': '1.5_2.0_2.5'}\n",
      "Loading the whole dataset\n",
      "Extract the working column#1 for classification\n",
      "dataset.x: <class 'numpy.ndarray'> 1024000 (1000, 32, 32)\n",
      "dataset.y: <class 'numpy.ndarray'> 1000 (1000,)\n"
     ]
    }
   ],
   "source": [
    "import jet_ml.classifiers.alpha_s.preprocess_dataset as pred\n",
    "(x,y_raw,y_df)=pred.preprocess_dataset_for_alpha_s(1000)\n",
    "# pred.get_preprocess_dataset_info(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['0.2', '0.3', '0.4'], dtype='object')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [1, 0, 0],\n",
       "       ...,\n",
       "       [0, 1, 0],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_classes=y_df.columns\n",
    "y=y_df.values\n",
    "display(y_classes)\n",
    "display(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     1  2  3\n",
       "0    0  0  1\n",
       "1    0  0  1\n",
       "2    1  0  0\n",
       "3    0  0  1\n",
       "4    0  0  1\n",
       "..  .. .. ..\n",
       "995  0  0  1\n",
       "996  0  0  1\n",
       "997  0  1  0\n",
       "998  0  0  1\n",
       "999  0  0  1\n",
       "\n",
       "[1000 rows x 3 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df_y=pd.DataFrame(data=y,columns= [1,2,3])\n",
    "display(df_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/arsi/miniconda3/envs/tensorflow/lib/python3.12/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "I0000 00:00:1724104317.816423    1858 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1724104317.816834    1858 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1724104317.817057    1858 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1724104318.107231    1858 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1724104318.107614    1858 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-08-19 17:51:58.107633: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2112] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "I0000 00:00:1724104318.107957    1858 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-08-19 17:51:58.109249: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 2242 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1650 Ti with Max-Q Design, pci bus id: 0000:01:00.0, compute capability: 7.5\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"testnet\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"testnet\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">320</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12544</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,605,760</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">387</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │           \u001b[38;5;34m320\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │        \u001b[38;5;34m18,496\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d (\u001b[38;5;33mMaxPooling2D\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12544\u001b[0m)          │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │     \u001b[38;5;34m1,605,760\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m)              │           \u001b[38;5;34m387\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,624,963</span> (6.20 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,624,963\u001b[0m (6.20 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,624,963</span> (6.20 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,624,963\u001b[0m (6.20 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1724104321.715398    2214 service.cc:146] XLA service 0x7fa0e4004b60 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1724104321.715498    2214 service.cc:154]   StreamExecutor device (0): NVIDIA GeForce GTX 1650 Ti with Max-Q Design, Compute Capability 7.5\n",
      "2024-08-19 17:52:01.802011: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2024-08-19 17:52:02.079746: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:531] Loaded cuDNN version 8900\n",
      "I0000 00:00:1724104327.200648    2214 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: val_loss improved from inf to 1.09711, saving model to /mnt/g/My Drive/Projects/110_JetscapeMl/hm_jetscapeml_source/models/testnet/model.keras\n",
      "7/7 - 13s - 2s/step - accuracy: 0.3212 - loss: 1.1003 - val_accuracy: 0.3600 - val_loss: 1.0971\n",
      "Epoch 2/1000\n",
      "\n",
      "Epoch 2: val_loss improved from 1.09711 to 1.09468, saving model to /mnt/g/My Drive/Projects/110_JetscapeMl/hm_jetscapeml_source/models/testnet/model.keras\n",
      "7/7 - 1s - 80ms/step - accuracy: 0.3875 - loss: 1.0946 - val_accuracy: 0.3600 - val_loss: 1.0947\n",
      "Epoch 3/1000\n",
      "\n",
      "Epoch 3: val_loss improved from 1.09468 to 1.09124, saving model to /mnt/g/My Drive/Projects/110_JetscapeMl/hm_jetscapeml_source/models/testnet/model.keras\n",
      "7/7 - 1s - 81ms/step - accuracy: 0.3925 - loss: 1.0882 - val_accuracy: 0.3400 - val_loss: 1.0912\n",
      "Epoch 4/1000\n",
      "\n",
      "Epoch 4: val_loss improved from 1.09124 to 1.08540, saving model to /mnt/g/My Drive/Projects/110_JetscapeMl/hm_jetscapeml_source/models/testnet/model.keras\n",
      "7/7 - 0s - 65ms/step - accuracy: 0.4225 - loss: 1.0735 - val_accuracy: 0.3950 - val_loss: 1.0854\n",
      "Epoch 5/1000\n",
      "\n",
      "Epoch 5: val_loss did not improve from 1.08540\n",
      "7/7 - 0s - 19ms/step - accuracy: 0.4300 - loss: 1.0623 - val_accuracy: 0.4000 - val_loss: 1.0869\n",
      "Epoch 6/1000\n",
      "\n",
      "Epoch 6: val_loss did not improve from 1.08540\n",
      "7/7 - 0s - 19ms/step - accuracy: 0.4613 - loss: 1.0375 - val_accuracy: 0.3550 - val_loss: 1.0900\n",
      "Epoch 7/1000\n",
      "\n",
      "Epoch 7: val_loss did not improve from 1.08540\n",
      "7/7 - 0s - 19ms/step - accuracy: 0.4725 - loss: 1.0209 - val_accuracy: 0.3750 - val_loss: 1.1072\n",
      "Epoch 8/1000\n",
      "\n",
      "Epoch 8: val_loss did not improve from 1.08540\n",
      "7/7 - 0s - 20ms/step - accuracy: 0.4925 - loss: 1.0109 - val_accuracy: 0.3700 - val_loss: 1.1171\n",
      "Epoch 9/1000\n",
      "\n",
      "Epoch 9: val_loss did not improve from 1.08540\n",
      "7/7 - 0s - 20ms/step - accuracy: 0.5100 - loss: 0.9952 - val_accuracy: 0.3700 - val_loss: 1.1211\n",
      "Epoch 10/1000\n",
      "\n",
      "Epoch 10: val_loss did not improve from 1.08540\n",
      "7/7 - 0s - 21ms/step - accuracy: 0.5288 - loss: 0.9656 - val_accuracy: 0.4100 - val_loss: 1.1258\n",
      "Epoch 11/1000\n",
      "\n",
      "Epoch 11: val_loss did not improve from 1.08540\n",
      "7/7 - 0s - 24ms/step - accuracy: 0.5063 - loss: 0.9702 - val_accuracy: 0.4050 - val_loss: 1.1329\n",
      "Epoch 12/1000\n",
      "\n",
      "Epoch 12: val_loss did not improve from 1.08540\n",
      "7/7 - 0s - 22ms/step - accuracy: 0.5350 - loss: 0.9409 - val_accuracy: 0.3600 - val_loss: 1.1453\n",
      "Epoch 13/1000\n",
      "\n",
      "Epoch 13: val_loss did not improve from 1.08540\n",
      "7/7 - 0s - 29ms/step - accuracy: 0.5450 - loss: 0.9354 - val_accuracy: 0.3750 - val_loss: 1.1779\n",
      "Epoch 14/1000\n",
      "\n",
      "Epoch 14: val_loss did not improve from 1.08540\n",
      "7/7 - 0s - 28ms/step - accuracy: 0.5487 - loss: 0.9222 - val_accuracy: 0.3600 - val_loss: 1.1908\n",
      "Epoch 15/1000\n",
      "\n",
      "Epoch 15: val_loss did not improve from 1.08540\n",
      "7/7 - 0s - 25ms/step - accuracy: 0.5625 - loss: 0.8987 - val_accuracy: 0.3900 - val_loss: 1.2112\n",
      "Epoch 16/1000\n",
      "\n",
      "Epoch 16: val_loss did not improve from 1.08540\n",
      "7/7 - 0s - 26ms/step - accuracy: 0.5600 - loss: 0.8955 - val_accuracy: 0.3550 - val_loss: 1.2135\n",
      "Epoch 17/1000\n",
      "\n",
      "Epoch 17: val_loss did not improve from 1.08540\n",
      "7/7 - 0s - 24ms/step - accuracy: 0.5612 - loss: 0.8746 - val_accuracy: 0.3950 - val_loss: 1.2342\n",
      "Epoch 18/1000\n",
      "\n",
      "Epoch 18: val_loss did not improve from 1.08540\n",
      "7/7 - 0s - 24ms/step - accuracy: 0.5775 - loss: 0.8749 - val_accuracy: 0.3900 - val_loss: 1.2435\n",
      "Epoch 19/1000\n",
      "\n",
      "Epoch 19: val_loss did not improve from 1.08540\n",
      "7/7 - 0s - 24ms/step - accuracy: 0.5825 - loss: 0.8561 - val_accuracy: 0.3700 - val_loss: 1.2699\n",
      "Epoch 20/1000\n",
      "\n",
      "Epoch 20: val_loss did not improve from 1.08540\n",
      "7/7 - 0s - 23ms/step - accuracy: 0.5863 - loss: 0.8394 - val_accuracy: 0.4150 - val_loss: 1.2871\n",
      "Epoch 21/1000\n",
      "\n",
      "Epoch 21: val_loss did not improve from 1.08540\n",
      "7/7 - 0s - 22ms/step - accuracy: 0.5900 - loss: 0.8314 - val_accuracy: 0.3900 - val_loss: 1.2912\n",
      "Epoch 22/1000\n",
      "\n",
      "Epoch 22: val_loss did not improve from 1.08540\n",
      "7/7 - 0s - 23ms/step - accuracy: 0.6087 - loss: 0.8166 - val_accuracy: 0.4250 - val_loss: 1.2948\n",
      "Epoch 23/1000\n",
      "\n",
      "Epoch 23: val_loss did not improve from 1.08540\n",
      "7/7 - 0s - 23ms/step - accuracy: 0.6087 - loss: 0.8008 - val_accuracy: 0.3950 - val_loss: 1.3277\n",
      "Epoch 24/1000\n",
      "\n",
      "Epoch 24: val_loss did not improve from 1.08540\n",
      "7/7 - 0s - 22ms/step - accuracy: 0.6275 - loss: 0.7923 - val_accuracy: 0.3900 - val_loss: 1.3674\n",
      "Epoch 25/1000\n",
      "\n",
      "Epoch 25: val_loss did not improve from 1.08540\n",
      "7/7 - 0s - 21ms/step - accuracy: 0.6400 - loss: 0.7788 - val_accuracy: 0.4050 - val_loss: 1.4066\n",
      "Epoch 26/1000\n",
      "\n",
      "Epoch 26: val_loss did not improve from 1.08540\n",
      "7/7 - 0s - 20ms/step - accuracy: 0.6200 - loss: 0.7811 - val_accuracy: 0.3450 - val_loss: 1.4186\n",
      "Epoch 27/1000\n",
      "\n",
      "Epoch 27: val_loss did not improve from 1.08540\n",
      "7/7 - 0s - 21ms/step - accuracy: 0.6488 - loss: 0.7456 - val_accuracy: 0.4100 - val_loss: 1.4225\n",
      "Epoch 28/1000\n",
      "\n",
      "Epoch 28: val_loss did not improve from 1.08540\n",
      "7/7 - 0s - 21ms/step - accuracy: 0.6687 - loss: 0.7424 - val_accuracy: 0.3750 - val_loss: 1.4692\n",
      "Epoch 29/1000\n",
      "\n",
      "Epoch 29: val_loss did not improve from 1.08540\n",
      "7/7 - 0s - 21ms/step - accuracy: 0.6825 - loss: 0.7165 - val_accuracy: 0.3850 - val_loss: 1.4662\n",
      "Epoch 30/1000\n",
      "\n",
      "Epoch 30: val_loss did not improve from 1.08540\n",
      "7/7 - 0s - 21ms/step - accuracy: 0.6850 - loss: 0.7246 - val_accuracy: 0.3550 - val_loss: 1.4908\n",
      "Epoch 31/1000\n",
      "\n",
      "Epoch 31: val_loss did not improve from 1.08540\n",
      "7/7 - 0s - 22ms/step - accuracy: 0.6675 - loss: 0.7256 - val_accuracy: 0.3800 - val_loss: 1.5231\n",
      "Epoch 32/1000\n",
      "\n",
      "Epoch 32: val_loss did not improve from 1.08540\n",
      "7/7 - 0s - 23ms/step - accuracy: 0.6862 - loss: 0.6825 - val_accuracy: 0.3550 - val_loss: 1.5465\n",
      "Epoch 33/1000\n",
      "\n",
      "Epoch 33: val_loss did not improve from 1.08540\n",
      "7/7 - 0s - 23ms/step - accuracy: 0.6988 - loss: 0.6739 - val_accuracy: 0.3750 - val_loss: 1.5991\n",
      "Epoch 34/1000\n",
      "\n",
      "Epoch 34: val_loss did not improve from 1.08540\n",
      "7/7 - 0s - 23ms/step - accuracy: 0.7038 - loss: 0.6604 - val_accuracy: 0.3800 - val_loss: 1.6497\n",
      "Epoch 35/1000\n",
      "\n",
      "Epoch 35: val_loss did not improve from 1.08540\n",
      "7/7 - 0s - 24ms/step - accuracy: 0.7175 - loss: 0.6455 - val_accuracy: 0.3250 - val_loss: 1.6612\n",
      "Epoch 36/1000\n",
      "\n",
      "Epoch 36: val_loss did not improve from 1.08540\n",
      "7/7 - 0s - 26ms/step - accuracy: 0.7125 - loss: 0.6279 - val_accuracy: 0.3300 - val_loss: 1.7002\n",
      "Epoch 37/1000\n",
      "\n",
      "Epoch 37: val_loss did not improve from 1.08540\n",
      "7/7 - 0s - 30ms/step - accuracy: 0.7175 - loss: 0.6188 - val_accuracy: 0.3750 - val_loss: 1.7600\n",
      "Epoch 38/1000\n",
      "\n",
      "Epoch 38: val_loss did not improve from 1.08540\n",
      "7/7 - 0s - 28ms/step - accuracy: 0.7237 - loss: 0.6223 - val_accuracy: 0.3900 - val_loss: 1.7624\n",
      "Epoch 39/1000\n",
      "\n",
      "Epoch 39: val_loss did not improve from 1.08540\n",
      "7/7 - 0s - 26ms/step - accuracy: 0.7575 - loss: 0.5899 - val_accuracy: 0.3900 - val_loss: 1.8521\n",
      "Epoch 40/1000\n",
      "\n",
      "Epoch 40: val_loss did not improve from 1.08540\n",
      "7/7 - 0s - 25ms/step - accuracy: 0.7425 - loss: 0.5982 - val_accuracy: 0.4150 - val_loss: 1.9188\n",
      "Epoch 41/1000\n",
      "\n",
      "Epoch 41: val_loss did not improve from 1.08540\n",
      "7/7 - 0s - 24ms/step - accuracy: 0.7312 - loss: 0.5847 - val_accuracy: 0.3500 - val_loss: 1.8637\n",
      "Epoch 42/1000\n",
      "\n",
      "Epoch 42: val_loss did not improve from 1.08540\n",
      "7/7 - 0s - 23ms/step - accuracy: 0.7663 - loss: 0.5358 - val_accuracy: 0.3500 - val_loss: 1.8873\n",
      "Epoch 43/1000\n",
      "\n",
      "Epoch 43: val_loss did not improve from 1.08540\n",
      "7/7 - 0s - 22ms/step - accuracy: 0.7750 - loss: 0.5271 - val_accuracy: 0.3600 - val_loss: 1.9892\n",
      "Epoch 44/1000\n",
      "\n",
      "Epoch 44: val_loss did not improve from 1.08540\n",
      "7/7 - 0s - 22ms/step - accuracy: 0.7725 - loss: 0.5535 - val_accuracy: 0.3900 - val_loss: 1.9907\n",
      "Epoch 45/1000\n",
      "\n",
      "Epoch 45: val_loss did not improve from 1.08540\n",
      "7/7 - 0s - 22ms/step - accuracy: 0.7738 - loss: 0.5438 - val_accuracy: 0.3450 - val_loss: 2.0369\n",
      "Epoch 46/1000\n",
      "\n",
      "Epoch 46: val_loss did not improve from 1.08540\n",
      "7/7 - 0s - 22ms/step - accuracy: 0.8075 - loss: 0.4886 - val_accuracy: 0.4000 - val_loss: 2.0708\n",
      "Epoch 47/1000\n",
      "\n",
      "Epoch 47: val_loss did not improve from 1.08540\n",
      "7/7 - 0s - 22ms/step - accuracy: 0.7900 - loss: 0.4751 - val_accuracy: 0.3900 - val_loss: 2.1500\n",
      "Epoch 48/1000\n",
      "\n",
      "Epoch 48: val_loss did not improve from 1.08540\n",
      "7/7 - 0s - 22ms/step - accuracy: 0.8213 - loss: 0.4488 - val_accuracy: 0.3650 - val_loss: 2.2231\n",
      "Epoch 49/1000\n",
      "\n",
      "Epoch 49: val_loss did not improve from 1.08540\n",
      "7/7 - 0s - 20ms/step - accuracy: 0.8138 - loss: 0.4628 - val_accuracy: 0.3800 - val_loss: 2.2567\n",
      "Epoch 50/1000\n",
      "\n",
      "Epoch 50: val_loss did not improve from 1.08540\n",
      "7/7 - 0s - 20ms/step - accuracy: 0.8313 - loss: 0.4415 - val_accuracy: 0.3800 - val_loss: 2.3054\n",
      "Epoch 51/1000\n",
      "\n",
      "Epoch 51: val_loss did not improve from 1.08540\n",
      "7/7 - 0s - 21ms/step - accuracy: 0.8138 - loss: 0.4528 - val_accuracy: 0.4050 - val_loss: 2.3534\n",
      "Epoch 52/1000\n",
      "\n",
      "Epoch 52: val_loss did not improve from 1.08540\n",
      "7/7 - 0s - 22ms/step - accuracy: 0.8512 - loss: 0.4151 - val_accuracy: 0.3900 - val_loss: 2.5012\n",
      "Epoch 53/1000\n",
      "\n",
      "Epoch 53: val_loss did not improve from 1.08540\n",
      "7/7 - 0s - 22ms/step - accuracy: 0.8388 - loss: 0.4306 - val_accuracy: 0.3600 - val_loss: 2.4692\n",
      "Epoch 54/1000\n",
      "\n",
      "Epoch 54: val_loss did not improve from 1.08540\n",
      "7/7 - 0s - 23ms/step - accuracy: 0.8525 - loss: 0.3967 - val_accuracy: 0.3550 - val_loss: 2.5190\n",
      "Epoch 55/1000\n",
      "\n",
      "Epoch 55: val_loss did not improve from 1.08540\n",
      "7/7 - 0s - 22ms/step - accuracy: 0.8375 - loss: 0.3818 - val_accuracy: 0.3750 - val_loss: 2.5935\n",
      "Epoch 56/1000\n",
      "\n",
      "Epoch 56: val_loss did not improve from 1.08540\n",
      "7/7 - 0s - 23ms/step - accuracy: 0.8675 - loss: 0.3571 - val_accuracy: 0.3750 - val_loss: 2.6647\n",
      "Epoch 57/1000\n",
      "\n",
      "Epoch 57: val_loss did not improve from 1.08540\n",
      "7/7 - 0s - 22ms/step - accuracy: 0.8850 - loss: 0.3414 - val_accuracy: 0.3950 - val_loss: 2.7019\n",
      "Epoch 58/1000\n",
      "\n",
      "Epoch 58: val_loss did not improve from 1.08540\n",
      "7/7 - 0s - 23ms/step - accuracy: 0.8950 - loss: 0.3281 - val_accuracy: 0.3850 - val_loss: 2.7597\n",
      "Epoch 59/1000\n",
      "\n",
      "Epoch 59: val_loss did not improve from 1.08540\n",
      "7/7 - 0s - 23ms/step - accuracy: 0.8900 - loss: 0.3170 - val_accuracy: 0.3700 - val_loss: 2.8064\n",
      "Epoch 60/1000\n",
      "\n",
      "Epoch 60: val_loss did not improve from 1.08540\n",
      "7/7 - 0s - 26ms/step - accuracy: 0.8800 - loss: 0.3271 - val_accuracy: 0.3850 - val_loss: 2.8988\n",
      "Epoch 61/1000\n",
      "\n",
      "Epoch 61: val_loss did not improve from 1.08540\n",
      "7/7 - 0s - 28ms/step - accuracy: 0.8863 - loss: 0.3208 - val_accuracy: 0.3950 - val_loss: 2.9226\n",
      "Epoch 62/1000\n",
      "\n",
      "Epoch 62: val_loss did not improve from 1.08540\n",
      "7/7 - 0s - 27ms/step - accuracy: 0.8850 - loss: 0.3213 - val_accuracy: 0.3600 - val_loss: 3.0148\n",
      "Epoch 63/1000\n",
      "\n",
      "Epoch 63: val_loss did not improve from 1.08540\n",
      "7/7 - 0s - 28ms/step - accuracy: 0.9025 - loss: 0.3003 - val_accuracy: 0.3850 - val_loss: 2.9525\n",
      "Epoch 64/1000\n",
      "\n",
      "Epoch 64: val_loss did not improve from 1.08540\n",
      "7/7 - 0s - 25ms/step - accuracy: 0.9000 - loss: 0.2963 - val_accuracy: 0.3800 - val_loss: 2.9560\n",
      "Epoch 65/1000\n",
      "\n",
      "Epoch 65: val_loss did not improve from 1.08540\n",
      "7/7 - 0s - 22ms/step - accuracy: 0.9025 - loss: 0.2891 - val_accuracy: 0.3500 - val_loss: 3.0662\n",
      "Epoch 66/1000\n",
      "\n",
      "Epoch 66: val_loss did not improve from 1.08540\n",
      "7/7 - 0s - 23ms/step - accuracy: 0.9200 - loss: 0.2402 - val_accuracy: 0.3800 - val_loss: 3.1429\n",
      "Epoch 67/1000\n",
      "\n",
      "Epoch 67: val_loss did not improve from 1.08540\n",
      "7/7 - 0s - 23ms/step - accuracy: 0.9175 - loss: 0.2603 - val_accuracy: 0.3800 - val_loss: 3.3034\n",
      "Epoch 68/1000\n",
      "\n",
      "Epoch 68: val_loss did not improve from 1.08540\n",
      "7/7 - 0s - 23ms/step - accuracy: 0.9112 - loss: 0.2593 - val_accuracy: 0.3800 - val_loss: 3.2539\n",
      "Epoch 69/1000\n",
      "\n",
      "Epoch 69: val_loss did not improve from 1.08540\n",
      "7/7 - 0s - 22ms/step - accuracy: 0.9262 - loss: 0.2453 - val_accuracy: 0.3850 - val_loss: 3.3175\n",
      "Epoch 70/1000\n",
      "\n",
      "Epoch 70: val_loss did not improve from 1.08540\n",
      "7/7 - 0s - 21ms/step - accuracy: 0.9175 - loss: 0.2550 - val_accuracy: 0.3700 - val_loss: 3.4133\n",
      "Epoch 71/1000\n",
      "\n",
      "Epoch 71: val_loss did not improve from 1.08540\n",
      "7/7 - 0s - 22ms/step - accuracy: 0.9187 - loss: 0.2462 - val_accuracy: 0.3750 - val_loss: 3.5189\n",
      "Epoch 72/1000\n",
      "\n",
      "Epoch 72: val_loss did not improve from 1.08540\n",
      "7/7 - 0s - 21ms/step - accuracy: 0.9312 - loss: 0.2367 - val_accuracy: 0.3500 - val_loss: 3.4779\n",
      "Epoch 73/1000\n",
      "\n",
      "Epoch 73: val_loss did not improve from 1.08540\n",
      "7/7 - 0s - 21ms/step - accuracy: 0.9262 - loss: 0.2114 - val_accuracy: 0.3650 - val_loss: 3.5048\n",
      "Epoch 74/1000\n",
      "\n",
      "Epoch 74: val_loss did not improve from 1.08540\n",
      "7/7 - 0s - 20ms/step - accuracy: 0.9463 - loss: 0.1957 - val_accuracy: 0.3650 - val_loss: 3.6660\n",
      "Epoch 75/1000\n",
      "\n",
      "Epoch 75: val_loss did not improve from 1.08540\n",
      "7/7 - 0s - 22ms/step - accuracy: 0.9300 - loss: 0.2008 - val_accuracy: 0.3700 - val_loss: 3.5632\n",
      "Epoch 76/1000\n",
      "\n",
      "Epoch 76: val_loss did not improve from 1.08540\n",
      "7/7 - 0s - 20ms/step - accuracy: 0.9362 - loss: 0.1880 - val_accuracy: 0.3750 - val_loss: 3.6780\n",
      "Epoch 77/1000\n",
      "\n",
      "Epoch 77: val_loss did not improve from 1.08540\n",
      "7/7 - 0s - 21ms/step - accuracy: 0.9375 - loss: 0.1807 - val_accuracy: 0.3600 - val_loss: 3.8167\n",
      "Epoch 78/1000\n",
      "\n",
      "Epoch 78: val_loss did not improve from 1.08540\n",
      "7/7 - 0s - 20ms/step - accuracy: 0.9488 - loss: 0.1833 - val_accuracy: 0.3550 - val_loss: 3.8492\n",
      "Epoch 79/1000\n",
      "\n",
      "Epoch 79: val_loss did not improve from 1.08540\n",
      "7/7 - 0s - 21ms/step - accuracy: 0.9425 - loss: 0.1707 - val_accuracy: 0.3750 - val_loss: 3.7224\n",
      "Epoch 80/1000\n",
      "\n",
      "Epoch 80: val_loss did not improve from 1.08540\n",
      "7/7 - 0s - 23ms/step - accuracy: 0.9513 - loss: 0.1754 - val_accuracy: 0.3600 - val_loss: 4.0032\n",
      "Epoch 81/1000\n",
      "\n",
      "Epoch 81: val_loss did not improve from 1.08540\n",
      "7/7 - 0s - 22ms/step - accuracy: 0.9463 - loss: 0.1570 - val_accuracy: 0.3550 - val_loss: 3.9078\n",
      "Epoch 82/1000\n",
      "\n",
      "Epoch 82: val_loss did not improve from 1.08540\n",
      "7/7 - 0s - 22ms/step - accuracy: 0.9425 - loss: 0.1658 - val_accuracy: 0.3650 - val_loss: 3.9531\n",
      "Epoch 83/1000\n",
      "\n",
      "Epoch 83: val_loss did not improve from 1.08540\n",
      "7/7 - 0s - 23ms/step - accuracy: 0.9563 - loss: 0.1598 - val_accuracy: 0.3400 - val_loss: 3.9130\n",
      "Epoch 84/1000\n",
      "\n",
      "Epoch 84: val_loss did not improve from 1.08540\n",
      "7/7 - 0s - 22ms/step - accuracy: 0.9513 - loss: 0.1706 - val_accuracy: 0.3550 - val_loss: 4.1158\n",
      "Epoch 85/1000\n",
      "\n",
      "Epoch 85: val_loss did not improve from 1.08540\n",
      "7/7 - 0s - 23ms/step - accuracy: 0.9525 - loss: 0.1638 - val_accuracy: 0.3550 - val_loss: 4.1203\n",
      "Epoch 86/1000\n",
      "\n",
      "Epoch 86: val_loss did not improve from 1.08540\n",
      "7/7 - 0s - 24ms/step - accuracy: 0.9550 - loss: 0.1594 - val_accuracy: 0.3600 - val_loss: 4.2685\n",
      "Epoch 87/1000\n",
      "\n",
      "Epoch 87: val_loss did not improve from 1.08540\n",
      "7/7 - 0s - 23ms/step - accuracy: 0.9413 - loss: 0.1622 - val_accuracy: 0.3600 - val_loss: 4.1587\n",
      "Epoch 88/1000\n",
      "\n",
      "Epoch 88: val_loss did not improve from 1.08540\n",
      "7/7 - 0s - 23ms/step - accuracy: 0.9638 - loss: 0.1235 - val_accuracy: 0.3500 - val_loss: 4.1467\n",
      "Epoch 89/1000\n",
      "\n",
      "Epoch 89: val_loss did not improve from 1.08540\n",
      "7/7 - 0s - 22ms/step - accuracy: 0.9675 - loss: 0.1218 - val_accuracy: 0.3500 - val_loss: 4.3125\n",
      "Epoch 90/1000\n",
      "\n",
      "Epoch 90: val_loss did not improve from 1.08540\n",
      "7/7 - 0s - 21ms/step - accuracy: 0.9550 - loss: 0.1351 - val_accuracy: 0.3600 - val_loss: 4.2375\n",
      "Epoch 91/1000\n",
      "\n",
      "Epoch 91: val_loss did not improve from 1.08540\n",
      "7/7 - 0s - 22ms/step - accuracy: 0.9762 - loss: 0.1087 - val_accuracy: 0.3550 - val_loss: 4.3483\n",
      "Epoch 92/1000\n",
      "\n",
      "Epoch 92: val_loss did not improve from 1.08540\n",
      "7/7 - 0s - 22ms/step - accuracy: 0.9675 - loss: 0.1163 - val_accuracy: 0.3500 - val_loss: 4.3660\n",
      "Epoch 93/1000\n",
      "\n",
      "Epoch 93: val_loss did not improve from 1.08540\n",
      "7/7 - 0s - 22ms/step - accuracy: 0.9712 - loss: 0.1096 - val_accuracy: 0.3500 - val_loss: 4.4971\n",
      "Epoch 94/1000\n",
      "\n",
      "Epoch 94: val_loss did not improve from 1.08540\n",
      "7/7 - 0s - 22ms/step - accuracy: 0.9712 - loss: 0.1150 - val_accuracy: 0.3500 - val_loss: 4.5807\n",
      "Epoch 95/1000\n",
      "\n",
      "Epoch 95: val_loss did not improve from 1.08540\n",
      "7/7 - 0s - 21ms/step - accuracy: 0.9700 - loss: 0.1043 - val_accuracy: 0.3700 - val_loss: 4.4018\n",
      "Epoch 96/1000\n",
      "\n",
      "Epoch 96: val_loss did not improve from 1.08540\n",
      "7/7 - 0s - 21ms/step - accuracy: 0.9688 - loss: 0.1102 - val_accuracy: 0.3550 - val_loss: 4.4130\n",
      "Epoch 97/1000\n",
      "\n",
      "Epoch 97: val_loss did not improve from 1.08540\n",
      "7/7 - 0s - 21ms/step - accuracy: 0.9750 - loss: 0.1122 - val_accuracy: 0.3450 - val_loss: 4.4849\n",
      "Epoch 98/1000\n",
      "\n",
      "Epoch 98: val_loss did not improve from 1.08540\n",
      "7/7 - 0s - 20ms/step - accuracy: 0.9787 - loss: 0.1158 - val_accuracy: 0.3500 - val_loss: 4.5655\n",
      "Epoch 99/1000\n",
      "\n",
      "Epoch 99: val_loss did not improve from 1.08540\n",
      "7/7 - 0s - 20ms/step - accuracy: 0.9725 - loss: 0.1031 - val_accuracy: 0.3600 - val_loss: 4.6692\n",
      "Epoch 100/1000\n",
      "\n",
      "Epoch 100: val_loss did not improve from 1.08540\n",
      "7/7 - 0s - 19ms/step - accuracy: 0.9688 - loss: 0.0928 - val_accuracy: 0.3550 - val_loss: 4.8906\n",
      "Epoch 101/1000\n",
      "\n",
      "Epoch 101: val_loss did not improve from 1.08540\n",
      "7/7 - 0s - 22ms/step - accuracy: 0.9825 - loss: 0.0769 - val_accuracy: 0.3500 - val_loss: 4.8407\n",
      "Epoch 102/1000\n",
      "\n",
      "Epoch 102: val_loss did not improve from 1.08540\n",
      "7/7 - 0s - 20ms/step - accuracy: 0.9775 - loss: 0.0970 - val_accuracy: 0.3600 - val_loss: 4.8289\n",
      "Epoch 103/1000\n",
      "\n",
      "Epoch 103: val_loss did not improve from 1.08540\n",
      "7/7 - 0s - 20ms/step - accuracy: 0.9762 - loss: 0.0840 - val_accuracy: 0.3750 - val_loss: 4.8544\n",
      "Epoch 104/1000\n",
      "\n",
      "Epoch 104: val_loss did not improve from 1.08540\n",
      "7/7 - 0s - 21ms/step - accuracy: 0.9750 - loss: 0.0847 - val_accuracy: 0.3750 - val_loss: 4.8269\n",
      "Epoch 104: early stopping\n",
      "Restoring model weights from the end of the best epoch: 4.\n",
      "Elpased time: 0:00:31\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 115ms/step\n",
      "Fold score (accuracy): 0.395\n",
      "Fold #2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/arsi/miniconda3/envs/tensorflow/lib/python3.12/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"testnet\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"testnet\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">320</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12544</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,605,760</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">387</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │           \u001b[38;5;34m320\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │        \u001b[38;5;34m18,496\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d (\u001b[38;5;33mMaxPooling2D\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12544\u001b[0m)          │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │     \u001b[38;5;34m1,605,760\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m)              │           \u001b[38;5;34m387\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,624,963</span> (6.20 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,624,963\u001b[0m (6.20 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,624,963</span> (6.20 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,624,963\u001b[0m (6.20 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "\n",
      "Epoch 1: val_loss improved from inf to 1.09782, saving model to /mnt/g/My Drive/Projects/110_JetscapeMl/hm_jetscapeml_source/models/testnet/model.keras\n",
      "7/7 - 6s - 921ms/step - accuracy: 0.3212 - loss: 1.0991 - val_accuracy: 0.3350 - val_loss: 1.0978\n",
      "Epoch 2/1000\n",
      "\n",
      "Epoch 2: val_loss improved from 1.09782 to 1.09638, saving model to /mnt/g/My Drive/Projects/110_JetscapeMl/hm_jetscapeml_source/models/testnet/model.keras\n",
      "7/7 - 1s - 125ms/step - accuracy: 0.3438 - loss: 1.0978 - val_accuracy: 0.3100 - val_loss: 1.0964\n",
      "Epoch 3/1000\n",
      "\n",
      "Epoch 3: val_loss improved from 1.09638 to 1.09320, saving model to /mnt/g/My Drive/Projects/110_JetscapeMl/hm_jetscapeml_source/models/testnet/model.keras\n",
      "7/7 - 1s - 115ms/step - accuracy: 0.4125 - loss: 1.0830 - val_accuracy: 0.3650 - val_loss: 1.0932\n",
      "Epoch 4/1000\n",
      "\n",
      "Epoch 4: val_loss did not improve from 1.09320\n",
      "7/7 - 0s - 28ms/step - accuracy: 0.4212 - loss: 1.0663 - val_accuracy: 0.3550 - val_loss: 1.0974\n",
      "Epoch 5/1000\n",
      "\n",
      "Epoch 5: val_loss did not improve from 1.09320\n",
      "7/7 - 0s - 28ms/step - accuracy: 0.4563 - loss: 1.0468 - val_accuracy: 0.3900 - val_loss: 1.1110\n",
      "Epoch 6/1000\n",
      "\n",
      "Epoch 6: val_loss did not improve from 1.09320\n",
      "7/7 - 0s - 32ms/step - accuracy: 0.4638 - loss: 1.0315 - val_accuracy: 0.3950 - val_loss: 1.1191\n",
      "Epoch 7/1000\n",
      "\n",
      "Epoch 7: val_loss did not improve from 1.09320\n",
      "7/7 - 0s - 32ms/step - accuracy: 0.4475 - loss: 1.0226 - val_accuracy: 0.3500 - val_loss: 1.1328\n",
      "Epoch 8/1000\n",
      "\n",
      "Epoch 8: val_loss did not improve from 1.09320\n",
      "7/7 - 0s - 28ms/step - accuracy: 0.4900 - loss: 1.0043 - val_accuracy: 0.4200 - val_loss: 1.1389\n",
      "Epoch 9/1000\n",
      "\n",
      "Epoch 9: val_loss did not improve from 1.09320\n",
      "7/7 - 0s - 30ms/step - accuracy: 0.4775 - loss: 1.0037 - val_accuracy: 0.4200 - val_loss: 1.1449\n",
      "Epoch 10/1000\n",
      "\n",
      "Epoch 10: val_loss did not improve from 1.09320\n",
      "7/7 - 0s - 27ms/step - accuracy: 0.4863 - loss: 0.9896 - val_accuracy: 0.4250 - val_loss: 1.1494\n",
      "Epoch 11/1000\n",
      "\n",
      "Epoch 11: val_loss did not improve from 1.09320\n",
      "7/7 - 0s - 27ms/step - accuracy: 0.5125 - loss: 0.9779 - val_accuracy: 0.4050 - val_loss: 1.1597\n",
      "Epoch 12/1000\n",
      "\n",
      "Epoch 12: val_loss did not improve from 1.09320\n",
      "7/7 - 0s - 29ms/step - accuracy: 0.5288 - loss: 0.9620 - val_accuracy: 0.4100 - val_loss: 1.1768\n",
      "Epoch 13/1000\n",
      "\n",
      "Epoch 13: val_loss did not improve from 1.09320\n",
      "7/7 - 0s - 29ms/step - accuracy: 0.5025 - loss: 0.9663 - val_accuracy: 0.4150 - val_loss: 1.1762\n",
      "Epoch 14/1000\n",
      "\n",
      "Epoch 14: val_loss did not improve from 1.09320\n",
      "7/7 - 0s - 28ms/step - accuracy: 0.5263 - loss: 0.9262 - val_accuracy: 0.4400 - val_loss: 1.1811\n",
      "Epoch 15/1000\n",
      "\n",
      "Epoch 15: val_loss did not improve from 1.09320\n",
      "7/7 - 0s - 26ms/step - accuracy: 0.5213 - loss: 0.9216 - val_accuracy: 0.4400 - val_loss: 1.2103\n",
      "Epoch 16/1000\n",
      "\n",
      "Epoch 16: val_loss did not improve from 1.09320\n",
      "7/7 - 0s - 25ms/step - accuracy: 0.5487 - loss: 0.9131 - val_accuracy: 0.4050 - val_loss: 1.2334\n",
      "Epoch 17/1000\n",
      "\n",
      "Epoch 17: val_loss did not improve from 1.09320\n",
      "7/7 - 0s - 24ms/step - accuracy: 0.5350 - loss: 0.9118 - val_accuracy: 0.4100 - val_loss: 1.2240\n",
      "Epoch 18/1000\n",
      "\n",
      "Epoch 18: val_loss did not improve from 1.09320\n",
      "7/7 - 0s - 27ms/step - accuracy: 0.5312 - loss: 0.9124 - val_accuracy: 0.4250 - val_loss: 1.2309\n",
      "Epoch 19/1000\n",
      "\n",
      "Epoch 19: val_loss did not improve from 1.09320\n",
      "7/7 - 0s - 24ms/step - accuracy: 0.5612 - loss: 0.8933 - val_accuracy: 0.4100 - val_loss: 1.2593\n",
      "Epoch 20/1000\n",
      "\n",
      "Epoch 20: val_loss did not improve from 1.09320\n",
      "7/7 - 0s - 24ms/step - accuracy: 0.5625 - loss: 0.8799 - val_accuracy: 0.3800 - val_loss: 1.2778\n",
      "Epoch 21/1000\n",
      "\n",
      "Epoch 21: val_loss did not improve from 1.09320\n",
      "7/7 - 0s - 25ms/step - accuracy: 0.5725 - loss: 0.8612 - val_accuracy: 0.4150 - val_loss: 1.2733\n",
      "Epoch 22/1000\n",
      "\n",
      "Epoch 22: val_loss did not improve from 1.09320\n",
      "7/7 - 0s - 26ms/step - accuracy: 0.5725 - loss: 0.8653 - val_accuracy: 0.4150 - val_loss: 1.2664\n",
      "Epoch 23/1000\n",
      "\n",
      "Epoch 23: val_loss did not improve from 1.09320\n",
      "7/7 - 0s - 25ms/step - accuracy: 0.5800 - loss: 0.8367 - val_accuracy: 0.4350 - val_loss: 1.2955\n",
      "Epoch 24/1000\n",
      "\n",
      "Epoch 24: val_loss did not improve from 1.09320\n",
      "7/7 - 0s - 26ms/step - accuracy: 0.6000 - loss: 0.8253 - val_accuracy: 0.4300 - val_loss: 1.3187\n",
      "Epoch 25/1000\n",
      "\n",
      "Epoch 25: val_loss did not improve from 1.09320\n",
      "7/7 - 0s - 24ms/step - accuracy: 0.5788 - loss: 0.8319 - val_accuracy: 0.4150 - val_loss: 1.3347\n",
      "Epoch 26/1000\n",
      "\n",
      "Epoch 26: val_loss did not improve from 1.09320\n",
      "7/7 - 0s - 25ms/step - accuracy: 0.5913 - loss: 0.8314 - val_accuracy: 0.4150 - val_loss: 1.3542\n",
      "Epoch 27/1000\n",
      "\n",
      "Epoch 27: val_loss did not improve from 1.09320\n",
      "7/7 - 0s - 23ms/step - accuracy: 0.6037 - loss: 0.8038 - val_accuracy: 0.4050 - val_loss: 1.3668\n",
      "Epoch 28/1000\n",
      "\n",
      "Epoch 28: val_loss did not improve from 1.09320\n",
      "7/7 - 0s - 21ms/step - accuracy: 0.6300 - loss: 0.7801 - val_accuracy: 0.4000 - val_loss: 1.4093\n",
      "Epoch 29/1000\n",
      "\n",
      "Epoch 29: val_loss did not improve from 1.09320\n",
      "7/7 - 0s - 22ms/step - accuracy: 0.6250 - loss: 0.7715 - val_accuracy: 0.4150 - val_loss: 1.4285\n",
      "Epoch 30/1000\n",
      "\n",
      "Epoch 30: val_loss did not improve from 1.09320\n",
      "7/7 - 0s - 22ms/step - accuracy: 0.6313 - loss: 0.7654 - val_accuracy: 0.4100 - val_loss: 1.4447\n",
      "Epoch 31/1000\n",
      "\n",
      "Epoch 31: val_loss did not improve from 1.09320\n",
      "7/7 - 0s - 26ms/step - accuracy: 0.6463 - loss: 0.7493 - val_accuracy: 0.4150 - val_loss: 1.4807\n",
      "Epoch 32/1000\n",
      "\n",
      "Epoch 32: val_loss did not improve from 1.09320\n",
      "7/7 - 0s - 24ms/step - accuracy: 0.6513 - loss: 0.7418 - val_accuracy: 0.4200 - val_loss: 1.4609\n",
      "Epoch 33/1000\n",
      "\n",
      "Epoch 33: val_loss did not improve from 1.09320\n",
      "7/7 - 0s - 22ms/step - accuracy: 0.6225 - loss: 0.7716 - val_accuracy: 0.4450 - val_loss: 1.4844\n",
      "Epoch 34/1000\n",
      "\n",
      "Epoch 34: val_loss did not improve from 1.09320\n",
      "7/7 - 0s - 24ms/step - accuracy: 0.6538 - loss: 0.7294 - val_accuracy: 0.4350 - val_loss: 1.4961\n",
      "Epoch 35/1000\n",
      "\n",
      "Epoch 35: val_loss did not improve from 1.09320\n",
      "7/7 - 0s - 22ms/step - accuracy: 0.6750 - loss: 0.6992 - val_accuracy: 0.4550 - val_loss: 1.5231\n",
      "Epoch 36/1000\n",
      "\n",
      "Epoch 36: val_loss did not improve from 1.09320\n",
      "7/7 - 0s - 22ms/step - accuracy: 0.6950 - loss: 0.6988 - val_accuracy: 0.4250 - val_loss: 1.5441\n",
      "Epoch 37/1000\n",
      "\n",
      "Epoch 37: val_loss did not improve from 1.09320\n",
      "7/7 - 0s - 22ms/step - accuracy: 0.6850 - loss: 0.6890 - val_accuracy: 0.4200 - val_loss: 1.5754\n",
      "Epoch 38/1000\n",
      "\n",
      "Epoch 38: val_loss did not improve from 1.09320\n",
      "7/7 - 0s - 21ms/step - accuracy: 0.6888 - loss: 0.6600 - val_accuracy: 0.4250 - val_loss: 1.6186\n",
      "Epoch 39/1000\n",
      "\n",
      "Epoch 39: val_loss did not improve from 1.09320\n",
      "7/7 - 0s - 22ms/step - accuracy: 0.7212 - loss: 0.6336 - val_accuracy: 0.4450 - val_loss: 1.6282\n",
      "Epoch 40/1000\n",
      "\n",
      "Epoch 40: val_loss did not improve from 1.09320\n",
      "7/7 - 0s - 26ms/step - accuracy: 0.7250 - loss: 0.6233 - val_accuracy: 0.4500 - val_loss: 1.6765\n",
      "Epoch 41/1000\n",
      "\n",
      "Epoch 41: val_loss did not improve from 1.09320\n",
      "7/7 - 0s - 23ms/step - accuracy: 0.7312 - loss: 0.6364 - val_accuracy: 0.4100 - val_loss: 1.7414\n",
      "Epoch 42/1000\n",
      "\n",
      "Epoch 42: val_loss did not improve from 1.09320\n",
      "7/7 - 0s - 22ms/step - accuracy: 0.7362 - loss: 0.5950 - val_accuracy: 0.4350 - val_loss: 1.7094\n",
      "Epoch 43/1000\n",
      "\n",
      "Epoch 43: val_loss did not improve from 1.09320\n",
      "7/7 - 0s - 22ms/step - accuracy: 0.7287 - loss: 0.5911 - val_accuracy: 0.4550 - val_loss: 1.7217\n",
      "Epoch 44/1000\n",
      "\n",
      "Epoch 44: val_loss did not improve from 1.09320\n",
      "7/7 - 0s - 25ms/step - accuracy: 0.7500 - loss: 0.5842 - val_accuracy: 0.4500 - val_loss: 1.7635\n",
      "Epoch 45/1000\n",
      "\n",
      "Epoch 45: val_loss did not improve from 1.09320\n",
      "7/7 - 0s - 26ms/step - accuracy: 0.7437 - loss: 0.5716 - val_accuracy: 0.4600 - val_loss: 1.8520\n",
      "Epoch 46/1000\n",
      "\n",
      "Epoch 46: val_loss did not improve from 1.09320\n",
      "7/7 - 0s - 23ms/step - accuracy: 0.7412 - loss: 0.5592 - val_accuracy: 0.4550 - val_loss: 1.8635\n",
      "Epoch 47/1000\n",
      "\n",
      "Epoch 47: val_loss did not improve from 1.09320\n",
      "7/7 - 0s - 22ms/step - accuracy: 0.7862 - loss: 0.5063 - val_accuracy: 0.4450 - val_loss: 1.9136\n",
      "Epoch 48/1000\n",
      "\n",
      "Epoch 48: val_loss did not improve from 1.09320\n",
      "7/7 - 0s - 24ms/step - accuracy: 0.7713 - loss: 0.5219 - val_accuracy: 0.4400 - val_loss: 1.9187\n",
      "Epoch 49/1000\n",
      "\n",
      "Epoch 49: val_loss did not improve from 1.09320\n",
      "7/7 - 0s - 26ms/step - accuracy: 0.7912 - loss: 0.5077 - val_accuracy: 0.4550 - val_loss: 1.9022\n",
      "Epoch 50/1000\n",
      "\n",
      "Epoch 50: val_loss did not improve from 1.09320\n",
      "7/7 - 0s - 26ms/step - accuracy: 0.8150 - loss: 0.4994 - val_accuracy: 0.4400 - val_loss: 1.9662\n",
      "Epoch 51/1000\n",
      "\n",
      "Epoch 51: val_loss did not improve from 1.09320\n",
      "7/7 - 0s - 24ms/step - accuracy: 0.8037 - loss: 0.4861 - val_accuracy: 0.4450 - val_loss: 1.9878\n",
      "Epoch 52/1000\n",
      "\n",
      "Epoch 52: val_loss did not improve from 1.09320\n",
      "7/7 - 0s - 23ms/step - accuracy: 0.8125 - loss: 0.4521 - val_accuracy: 0.4200 - val_loss: 2.0671\n",
      "Epoch 53/1000\n",
      "\n",
      "Epoch 53: val_loss did not improve from 1.09320\n",
      "7/7 - 0s - 19ms/step - accuracy: 0.8125 - loss: 0.4401 - val_accuracy: 0.4300 - val_loss: 2.1180\n",
      "Epoch 54/1000\n",
      "\n",
      "Epoch 54: val_loss did not improve from 1.09320\n",
      "7/7 - 0s - 18ms/step - accuracy: 0.8375 - loss: 0.4080 - val_accuracy: 0.4150 - val_loss: 2.2158\n",
      "Epoch 55/1000\n",
      "\n",
      "Epoch 55: val_loss did not improve from 1.09320\n",
      "7/7 - 0s - 18ms/step - accuracy: 0.8325 - loss: 0.4016 - val_accuracy: 0.4350 - val_loss: 2.3736\n",
      "Epoch 56/1000\n",
      "\n",
      "Epoch 56: val_loss did not improve from 1.09320\n",
      "7/7 - 0s - 18ms/step - accuracy: 0.8400 - loss: 0.4180 - val_accuracy: 0.4400 - val_loss: 2.1857\n",
      "Epoch 57/1000\n",
      "\n",
      "Epoch 57: val_loss did not improve from 1.09320\n",
      "7/7 - 0s - 17ms/step - accuracy: 0.8163 - loss: 0.4423 - val_accuracy: 0.4400 - val_loss: 2.2234\n",
      "Epoch 58/1000\n",
      "\n",
      "Epoch 58: val_loss did not improve from 1.09320\n",
      "7/7 - 0s - 17ms/step - accuracy: 0.8600 - loss: 0.4143 - val_accuracy: 0.4250 - val_loss: 2.3524\n",
      "Epoch 59/1000\n",
      "\n",
      "Epoch 59: val_loss did not improve from 1.09320\n",
      "7/7 - 0s - 17ms/step - accuracy: 0.8325 - loss: 0.4142 - val_accuracy: 0.4300 - val_loss: 2.3789\n",
      "Epoch 60/1000\n",
      "\n",
      "Epoch 60: val_loss did not improve from 1.09320\n",
      "7/7 - 0s - 17ms/step - accuracy: 0.8763 - loss: 0.3723 - val_accuracy: 0.4500 - val_loss: 2.4319\n",
      "Epoch 61/1000\n",
      "\n",
      "Epoch 61: val_loss did not improve from 1.09320\n",
      "7/7 - 0s - 17ms/step - accuracy: 0.8562 - loss: 0.3820 - val_accuracy: 0.4550 - val_loss: 2.4875\n",
      "Epoch 62/1000\n",
      "\n",
      "Epoch 62: val_loss did not improve from 1.09320\n",
      "7/7 - 0s - 17ms/step - accuracy: 0.8675 - loss: 0.3570 - val_accuracy: 0.4450 - val_loss: 2.5368\n",
      "Epoch 63/1000\n",
      "\n",
      "Epoch 63: val_loss did not improve from 1.09320\n",
      "7/7 - 0s - 17ms/step - accuracy: 0.8788 - loss: 0.3242 - val_accuracy: 0.4250 - val_loss: 2.5802\n",
      "Epoch 64/1000\n",
      "\n",
      "Epoch 64: val_loss did not improve from 1.09320\n",
      "7/7 - 0s - 18ms/step - accuracy: 0.8750 - loss: 0.3237 - val_accuracy: 0.4250 - val_loss: 2.6046\n",
      "Epoch 65/1000\n",
      "\n",
      "Epoch 65: val_loss did not improve from 1.09320\n",
      "7/7 - 0s - 18ms/step - accuracy: 0.8938 - loss: 0.3245 - val_accuracy: 0.4300 - val_loss: 2.6733\n",
      "Epoch 66/1000\n",
      "\n",
      "Epoch 66: val_loss did not improve from 1.09320\n",
      "7/7 - 0s - 18ms/step - accuracy: 0.9025 - loss: 0.3032 - val_accuracy: 0.4200 - val_loss: 2.7466\n",
      "Epoch 67/1000\n",
      "\n",
      "Epoch 67: val_loss did not improve from 1.09320\n",
      "7/7 - 0s - 18ms/step - accuracy: 0.9013 - loss: 0.2914 - val_accuracy: 0.4250 - val_loss: 2.8256\n",
      "Epoch 68/1000\n",
      "\n",
      "Epoch 68: val_loss did not improve from 1.09320\n",
      "7/7 - 0s - 21ms/step - accuracy: 0.8850 - loss: 0.3076 - val_accuracy: 0.4400 - val_loss: 2.7688\n",
      "Epoch 69/1000\n",
      "\n",
      "Epoch 69: val_loss did not improve from 1.09320\n",
      "7/7 - 0s - 20ms/step - accuracy: 0.9200 - loss: 0.2672 - val_accuracy: 0.4400 - val_loss: 2.8408\n",
      "Epoch 70/1000\n",
      "\n",
      "Epoch 70: val_loss did not improve from 1.09320\n",
      "7/7 - 0s - 19ms/step - accuracy: 0.9200 - loss: 0.2645 - val_accuracy: 0.4500 - val_loss: 2.8954\n",
      "Epoch 71/1000\n",
      "\n",
      "Epoch 71: val_loss did not improve from 1.09320\n",
      "7/7 - 0s - 18ms/step - accuracy: 0.9150 - loss: 0.2512 - val_accuracy: 0.4450 - val_loss: 2.9077\n",
      "Epoch 72/1000\n",
      "\n",
      "Epoch 72: val_loss did not improve from 1.09320\n",
      "7/7 - 0s - 18ms/step - accuracy: 0.9187 - loss: 0.2429 - val_accuracy: 0.4250 - val_loss: 3.0077\n",
      "Epoch 73/1000\n",
      "\n",
      "Epoch 73: val_loss did not improve from 1.09320\n",
      "7/7 - 0s - 18ms/step - accuracy: 0.9287 - loss: 0.2284 - val_accuracy: 0.4150 - val_loss: 3.0914\n",
      "Epoch 74/1000\n",
      "\n",
      "Epoch 74: val_loss did not improve from 1.09320\n",
      "7/7 - 0s - 17ms/step - accuracy: 0.9087 - loss: 0.2453 - val_accuracy: 0.4100 - val_loss: 2.9858\n",
      "Epoch 75/1000\n",
      "\n",
      "Epoch 75: val_loss did not improve from 1.09320\n",
      "7/7 - 0s - 18ms/step - accuracy: 0.9275 - loss: 0.2202 - val_accuracy: 0.4450 - val_loss: 3.0059\n",
      "Epoch 76/1000\n",
      "\n",
      "Epoch 76: val_loss did not improve from 1.09320\n",
      "7/7 - 0s - 18ms/step - accuracy: 0.9375 - loss: 0.2162 - val_accuracy: 0.4500 - val_loss: 3.0961\n",
      "Epoch 77/1000\n",
      "\n",
      "Epoch 77: val_loss did not improve from 1.09320\n",
      "7/7 - 0s - 19ms/step - accuracy: 0.9388 - loss: 0.2177 - val_accuracy: 0.4300 - val_loss: 3.2204\n",
      "Epoch 78/1000\n",
      "\n",
      "Epoch 78: val_loss did not improve from 1.09320\n",
      "7/7 - 0s - 18ms/step - accuracy: 0.9300 - loss: 0.2234 - val_accuracy: 0.4350 - val_loss: 3.1629\n",
      "Epoch 79/1000\n",
      "\n",
      "Epoch 79: val_loss did not improve from 1.09320\n",
      "7/7 - 0s - 19ms/step - accuracy: 0.9337 - loss: 0.2117 - val_accuracy: 0.4600 - val_loss: 3.2889\n",
      "Epoch 80/1000\n",
      "\n",
      "Epoch 80: val_loss did not improve from 1.09320\n",
      "7/7 - 0s - 22ms/step - accuracy: 0.9438 - loss: 0.1992 - val_accuracy: 0.4450 - val_loss: 3.2671\n",
      "Epoch 81/1000\n",
      "\n",
      "Epoch 81: val_loss did not improve from 1.09320\n",
      "7/7 - 0s - 19ms/step - accuracy: 0.9463 - loss: 0.1720 - val_accuracy: 0.4400 - val_loss: 3.3494\n",
      "Epoch 82/1000\n",
      "\n",
      "Epoch 82: val_loss did not improve from 1.09320\n",
      "7/7 - 0s - 18ms/step - accuracy: 0.9262 - loss: 0.2240 - val_accuracy: 0.4150 - val_loss: 3.2756\n",
      "Epoch 83/1000\n",
      "\n",
      "Epoch 83: val_loss did not improve from 1.09320\n",
      "7/7 - 0s - 18ms/step - accuracy: 0.9475 - loss: 0.1768 - val_accuracy: 0.4350 - val_loss: 3.4039\n",
      "Epoch 84/1000\n",
      "\n",
      "Epoch 84: val_loss did not improve from 1.09320\n",
      "7/7 - 0s - 17ms/step - accuracy: 0.9425 - loss: 0.1853 - val_accuracy: 0.4100 - val_loss: 3.4381\n",
      "Epoch 85/1000\n",
      "\n",
      "Epoch 85: val_loss did not improve from 1.09320\n",
      "7/7 - 0s - 17ms/step - accuracy: 0.9375 - loss: 0.1915 - val_accuracy: 0.4100 - val_loss: 3.5691\n",
      "Epoch 86/1000\n",
      "\n",
      "Epoch 86: val_loss did not improve from 1.09320\n",
      "7/7 - 0s - 18ms/step - accuracy: 0.9438 - loss: 0.1882 - val_accuracy: 0.4150 - val_loss: 3.6139\n",
      "Epoch 87/1000\n",
      "\n",
      "Epoch 87: val_loss did not improve from 1.09320\n",
      "7/7 - 0s - 17ms/step - accuracy: 0.9400 - loss: 0.1679 - val_accuracy: 0.4400 - val_loss: 3.6535\n",
      "Epoch 88/1000\n",
      "\n",
      "Epoch 88: val_loss did not improve from 1.09320\n",
      "7/7 - 0s - 17ms/step - accuracy: 0.9425 - loss: 0.1776 - val_accuracy: 0.4200 - val_loss: 3.6129\n",
      "Epoch 89/1000\n",
      "\n",
      "Epoch 89: val_loss did not improve from 1.09320\n",
      "7/7 - 0s - 17ms/step - accuracy: 0.9513 - loss: 0.1591 - val_accuracy: 0.4250 - val_loss: 3.7626\n",
      "Epoch 90/1000\n",
      "\n",
      "Epoch 90: val_loss did not improve from 1.09320\n",
      "7/7 - 0s - 18ms/step - accuracy: 0.9613 - loss: 0.1457 - val_accuracy: 0.4200 - val_loss: 3.6920\n",
      "Epoch 91/1000\n",
      "\n",
      "Epoch 91: val_loss did not improve from 1.09320\n",
      "7/7 - 0s - 17ms/step - accuracy: 0.9663 - loss: 0.1316 - val_accuracy: 0.4250 - val_loss: 3.7916\n",
      "Epoch 92/1000\n",
      "\n",
      "Epoch 92: val_loss did not improve from 1.09320\n",
      "7/7 - 0s - 17ms/step - accuracy: 0.9588 - loss: 0.1366 - val_accuracy: 0.4400 - val_loss: 3.7623\n",
      "Epoch 93/1000\n",
      "\n",
      "Epoch 93: val_loss did not improve from 1.09320\n",
      "7/7 - 0s - 17ms/step - accuracy: 0.9613 - loss: 0.1280 - val_accuracy: 0.4350 - val_loss: 3.7479\n",
      "Epoch 94/1000\n",
      "\n",
      "Epoch 94: val_loss did not improve from 1.09320\n",
      "7/7 - 0s - 17ms/step - accuracy: 0.9750 - loss: 0.1212 - val_accuracy: 0.4400 - val_loss: 3.7917\n",
      "Epoch 95/1000\n",
      "\n",
      "Epoch 95: val_loss did not improve from 1.09320\n",
      "7/7 - 0s - 17ms/step - accuracy: 0.9550 - loss: 0.1413 - val_accuracy: 0.4500 - val_loss: 3.9678\n",
      "Epoch 96/1000\n",
      "\n",
      "Epoch 96: val_loss did not improve from 1.09320\n",
      "7/7 - 0s - 18ms/step - accuracy: 0.9650 - loss: 0.1208 - val_accuracy: 0.4200 - val_loss: 3.9477\n",
      "Epoch 97/1000\n",
      "\n",
      "Epoch 97: val_loss did not improve from 1.09320\n",
      "7/7 - 0s - 20ms/step - accuracy: 0.9663 - loss: 0.1156 - val_accuracy: 0.4050 - val_loss: 3.8888\n",
      "Epoch 98/1000\n",
      "\n",
      "Epoch 98: val_loss did not improve from 1.09320\n",
      "7/7 - 0s - 20ms/step - accuracy: 0.9688 - loss: 0.1144 - val_accuracy: 0.4200 - val_loss: 3.9490\n",
      "Epoch 99/1000\n",
      "\n",
      "Epoch 99: val_loss did not improve from 1.09320\n",
      "7/7 - 0s - 20ms/step - accuracy: 0.9712 - loss: 0.1052 - val_accuracy: 0.4350 - val_loss: 3.9837\n",
      "Epoch 100/1000\n",
      "\n",
      "Epoch 100: val_loss did not improve from 1.09320\n",
      "7/7 - 0s - 20ms/step - accuracy: 0.9725 - loss: 0.1028 - val_accuracy: 0.4100 - val_loss: 4.0667\n",
      "Epoch 101/1000\n",
      "\n",
      "Epoch 101: val_loss did not improve from 1.09320\n",
      "7/7 - 0s - 19ms/step - accuracy: 0.9712 - loss: 0.1074 - val_accuracy: 0.4300 - val_loss: 4.1520\n",
      "Epoch 102/1000\n",
      "\n",
      "Epoch 102: val_loss did not improve from 1.09320\n",
      "7/7 - 0s - 18ms/step - accuracy: 0.9750 - loss: 0.1070 - val_accuracy: 0.4050 - val_loss: 4.1353\n",
      "Epoch 103/1000\n",
      "\n",
      "Epoch 103: val_loss did not improve from 1.09320\n",
      "7/7 - 0s - 17ms/step - accuracy: 0.9725 - loss: 0.0900 - val_accuracy: 0.4300 - val_loss: 4.2719\n",
      "Epoch 103: early stopping\n",
      "Restoring model weights from the end of the best epoch: 3.\n",
      "Elpased time: 0:00:24\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "Fold score (accuracy): 0.365\n",
      "Fold #3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/arsi/miniconda3/envs/tensorflow/lib/python3.12/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"testnet\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"testnet\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">320</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12544</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,605,760</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">387</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │           \u001b[38;5;34m320\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │        \u001b[38;5;34m18,496\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d (\u001b[38;5;33mMaxPooling2D\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12544\u001b[0m)          │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │     \u001b[38;5;34m1,605,760\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m)              │           \u001b[38;5;34m387\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,624,963</span> (6.20 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,624,963\u001b[0m (6.20 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,624,963</span> (6.20 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,624,963\u001b[0m (6.20 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "\n",
      "Epoch 1: val_loss improved from inf to 1.09609, saving model to /mnt/g/My Drive/Projects/110_JetscapeMl/hm_jetscapeml_source/models/testnet/model.keras\n",
      "7/7 - 5s - 752ms/step - accuracy: 0.3288 - loss: 1.0990 - val_accuracy: 0.3850 - val_loss: 1.0961\n",
      "Epoch 2/1000\n",
      "\n",
      "Epoch 2: val_loss improved from 1.09609 to 1.09369, saving model to /mnt/g/My Drive/Projects/110_JetscapeMl/hm_jetscapeml_source/models/testnet/model.keras\n",
      "7/7 - 1s - 97ms/step - accuracy: 0.3775 - loss: 1.0944 - val_accuracy: 0.3700 - val_loss: 1.0937\n",
      "Epoch 3/1000\n",
      "\n",
      "Epoch 3: val_loss improved from 1.09369 to 1.08997, saving model to /mnt/g/My Drive/Projects/110_JetscapeMl/hm_jetscapeml_source/models/testnet/model.keras\n",
      "7/7 - 1s - 86ms/step - accuracy: 0.4137 - loss: 1.0880 - val_accuracy: 0.4000 - val_loss: 1.0900\n",
      "Epoch 4/1000\n",
      "\n",
      "Epoch 4: val_loss improved from 1.08997 to 1.08632, saving model to /mnt/g/My Drive/Projects/110_JetscapeMl/hm_jetscapeml_source/models/testnet/model.keras\n",
      "7/7 - 1s - 106ms/step - accuracy: 0.4162 - loss: 1.0751 - val_accuracy: 0.3700 - val_loss: 1.0863\n",
      "Epoch 5/1000\n",
      "\n",
      "Epoch 5: val_loss improved from 1.08632 to 1.08465, saving model to /mnt/g/My Drive/Projects/110_JetscapeMl/hm_jetscapeml_source/models/testnet/model.keras\n",
      "7/7 - 1s - 101ms/step - accuracy: 0.4313 - loss: 1.0621 - val_accuracy: 0.4100 - val_loss: 1.0847\n",
      "Epoch 6/1000\n",
      "\n",
      "Epoch 6: val_loss did not improve from 1.08465\n",
      "7/7 - 0s - 32ms/step - accuracy: 0.4613 - loss: 1.0392 - val_accuracy: 0.4150 - val_loss: 1.0883\n",
      "Epoch 7/1000\n",
      "\n",
      "Epoch 7: val_loss did not improve from 1.08465\n",
      "7/7 - 0s - 28ms/step - accuracy: 0.4613 - loss: 1.0301 - val_accuracy: 0.3900 - val_loss: 1.0968\n",
      "Epoch 8/1000\n",
      "\n",
      "Epoch 8: val_loss did not improve from 1.08465\n",
      "7/7 - 0s - 26ms/step - accuracy: 0.5063 - loss: 1.0062 - val_accuracy: 0.3650 - val_loss: 1.1107\n",
      "Epoch 9/1000\n",
      "\n",
      "Epoch 9: val_loss did not improve from 1.08465\n",
      "7/7 - 0s - 25ms/step - accuracy: 0.5125 - loss: 0.9891 - val_accuracy: 0.4050 - val_loss: 1.1228\n",
      "Epoch 10/1000\n",
      "\n",
      "Epoch 10: val_loss did not improve from 1.08465\n",
      "7/7 - 0s - 23ms/step - accuracy: 0.5225 - loss: 0.9761 - val_accuracy: 0.3800 - val_loss: 1.1360\n",
      "Epoch 11/1000\n",
      "\n",
      "Epoch 11: val_loss did not improve from 1.08465\n",
      "7/7 - 0s - 20ms/step - accuracy: 0.5113 - loss: 0.9635 - val_accuracy: 0.3900 - val_loss: 1.1540\n",
      "Epoch 12/1000\n",
      "\n",
      "Epoch 12: val_loss did not improve from 1.08465\n",
      "7/7 - 0s - 19ms/step - accuracy: 0.5175 - loss: 0.9513 - val_accuracy: 0.3650 - val_loss: 1.1853\n",
      "Epoch 13/1000\n",
      "\n",
      "Epoch 13: val_loss did not improve from 1.08465\n",
      "7/7 - 0s - 20ms/step - accuracy: 0.5337 - loss: 0.9352 - val_accuracy: 0.3750 - val_loss: 1.1856\n",
      "Epoch 14/1000\n",
      "\n",
      "Epoch 14: val_loss did not improve from 1.08465\n",
      "7/7 - 0s - 21ms/step - accuracy: 0.5487 - loss: 0.9100 - val_accuracy: 0.3800 - val_loss: 1.2212\n",
      "Epoch 15/1000\n",
      "\n",
      "Epoch 15: val_loss did not improve from 1.08465\n",
      "7/7 - 0s - 20ms/step - accuracy: 0.5475 - loss: 0.8975 - val_accuracy: 0.3500 - val_loss: 1.2610\n",
      "Epoch 16/1000\n",
      "\n",
      "Epoch 16: val_loss did not improve from 1.08465\n",
      "7/7 - 0s - 19ms/step - accuracy: 0.5763 - loss: 0.8706 - val_accuracy: 0.3750 - val_loss: 1.2935\n",
      "Epoch 17/1000\n",
      "\n",
      "Epoch 17: val_loss did not improve from 1.08465\n",
      "7/7 - 0s - 20ms/step - accuracy: 0.5487 - loss: 0.8816 - val_accuracy: 0.3550 - val_loss: 1.3003\n",
      "Epoch 18/1000\n",
      "\n",
      "Epoch 18: val_loss did not improve from 1.08465\n",
      "7/7 - 0s - 20ms/step - accuracy: 0.5825 - loss: 0.8624 - val_accuracy: 0.3350 - val_loss: 1.3148\n",
      "Epoch 19/1000\n",
      "\n",
      "Epoch 19: val_loss did not improve from 1.08465\n",
      "7/7 - 0s - 21ms/step - accuracy: 0.5863 - loss: 0.8385 - val_accuracy: 0.3700 - val_loss: 1.3100\n",
      "Epoch 20/1000\n",
      "\n",
      "Epoch 20: val_loss did not improve from 1.08465\n",
      "7/7 - 0s - 21ms/step - accuracy: 0.6162 - loss: 0.8243 - val_accuracy: 0.3750 - val_loss: 1.3238\n",
      "Epoch 21/1000\n",
      "\n",
      "Epoch 21: val_loss did not improve from 1.08465\n",
      "7/7 - 0s - 20ms/step - accuracy: 0.6200 - loss: 0.8081 - val_accuracy: 0.3650 - val_loss: 1.3760\n",
      "Epoch 22/1000\n",
      "\n",
      "Epoch 22: val_loss did not improve from 1.08465\n",
      "7/7 - 0s - 20ms/step - accuracy: 0.6300 - loss: 0.7873 - val_accuracy: 0.3800 - val_loss: 1.4143\n",
      "Epoch 23/1000\n",
      "\n",
      "Epoch 23: val_loss did not improve from 1.08465\n",
      "7/7 - 0s - 19ms/step - accuracy: 0.6562 - loss: 0.7720 - val_accuracy: 0.3750 - val_loss: 1.4661\n",
      "Epoch 24/1000\n",
      "\n",
      "Epoch 24: val_loss did not improve from 1.08465\n",
      "7/7 - 0s - 19ms/step - accuracy: 0.6562 - loss: 0.7694 - val_accuracy: 0.3650 - val_loss: 1.5080\n",
      "Epoch 25/1000\n",
      "\n",
      "Epoch 25: val_loss did not improve from 1.08465\n",
      "7/7 - 0s - 20ms/step - accuracy: 0.6463 - loss: 0.7475 - val_accuracy: 0.3750 - val_loss: 1.5334\n",
      "Epoch 26/1000\n",
      "\n",
      "Epoch 26: val_loss did not improve from 1.08465\n",
      "7/7 - 0s - 19ms/step - accuracy: 0.6888 - loss: 0.7374 - val_accuracy: 0.3750 - val_loss: 1.5405\n",
      "Epoch 27/1000\n",
      "\n",
      "Epoch 27: val_loss did not improve from 1.08465\n",
      "7/7 - 0s - 18ms/step - accuracy: 0.6662 - loss: 0.7247 - val_accuracy: 0.3600 - val_loss: 1.5665\n",
      "Epoch 28/1000\n",
      "\n",
      "Epoch 28: val_loss did not improve from 1.08465\n",
      "7/7 - 0s - 17ms/step - accuracy: 0.6762 - loss: 0.7115 - val_accuracy: 0.3600 - val_loss: 1.6270\n",
      "Epoch 29/1000\n",
      "\n",
      "Epoch 29: val_loss did not improve from 1.08465\n",
      "7/7 - 0s - 18ms/step - accuracy: 0.7025 - loss: 0.6803 - val_accuracy: 0.3400 - val_loss: 1.7612\n",
      "Epoch 30/1000\n",
      "\n",
      "Epoch 30: val_loss did not improve from 1.08465\n",
      "7/7 - 0s - 20ms/step - accuracy: 0.7025 - loss: 0.6919 - val_accuracy: 0.3400 - val_loss: 1.6903\n",
      "Epoch 31/1000\n",
      "\n",
      "Epoch 31: val_loss did not improve from 1.08465\n",
      "7/7 - 0s - 17ms/step - accuracy: 0.7000 - loss: 0.6675 - val_accuracy: 0.3550 - val_loss: 1.6917\n",
      "Epoch 32/1000\n",
      "\n",
      "Epoch 32: val_loss did not improve from 1.08465\n",
      "7/7 - 0s - 18ms/step - accuracy: 0.7262 - loss: 0.6449 - val_accuracy: 0.3750 - val_loss: 1.7743\n",
      "Epoch 33/1000\n",
      "\n",
      "Epoch 33: val_loss did not improve from 1.08465\n",
      "7/7 - 0s - 19ms/step - accuracy: 0.7250 - loss: 0.6373 - val_accuracy: 0.3700 - val_loss: 1.8234\n",
      "Epoch 34/1000\n",
      "\n",
      "Epoch 34: val_loss did not improve from 1.08465\n",
      "7/7 - 0s - 19ms/step - accuracy: 0.7212 - loss: 0.6360 - val_accuracy: 0.3650 - val_loss: 1.8223\n",
      "Epoch 35/1000\n",
      "\n",
      "Epoch 35: val_loss did not improve from 1.08465\n",
      "7/7 - 0s - 19ms/step - accuracy: 0.7437 - loss: 0.5848 - val_accuracy: 0.3850 - val_loss: 1.9273\n",
      "Epoch 36/1000\n",
      "\n",
      "Epoch 36: val_loss did not improve from 1.08465\n",
      "7/7 - 0s - 20ms/step - accuracy: 0.7538 - loss: 0.5847 - val_accuracy: 0.3550 - val_loss: 1.9901\n",
      "Epoch 37/1000\n",
      "\n",
      "Epoch 37: val_loss did not improve from 1.08465\n",
      "7/7 - 0s - 18ms/step - accuracy: 0.7450 - loss: 0.5761 - val_accuracy: 0.3450 - val_loss: 2.0174\n",
      "Epoch 38/1000\n",
      "\n",
      "Epoch 38: val_loss did not improve from 1.08465\n",
      "7/7 - 0s - 18ms/step - accuracy: 0.7412 - loss: 0.5833 - val_accuracy: 0.3300 - val_loss: 2.0265\n",
      "Epoch 39/1000\n",
      "\n",
      "Epoch 39: val_loss did not improve from 1.08465\n",
      "7/7 - 0s - 18ms/step - accuracy: 0.7738 - loss: 0.5455 - val_accuracy: 0.3650 - val_loss: 2.0723\n",
      "Epoch 40/1000\n",
      "\n",
      "Epoch 40: val_loss did not improve from 1.08465\n",
      "7/7 - 0s - 18ms/step - accuracy: 0.7937 - loss: 0.5254 - val_accuracy: 0.3650 - val_loss: 2.1427\n",
      "Epoch 41/1000\n",
      "\n",
      "Epoch 41: val_loss did not improve from 1.08465\n",
      "7/7 - 0s - 21ms/step - accuracy: 0.7887 - loss: 0.5128 - val_accuracy: 0.3550 - val_loss: 2.2444\n",
      "Epoch 42/1000\n",
      "\n",
      "Epoch 42: val_loss did not improve from 1.08465\n",
      "7/7 - 0s - 20ms/step - accuracy: 0.7912 - loss: 0.4877 - val_accuracy: 0.3700 - val_loss: 2.2648\n",
      "Epoch 43/1000\n",
      "\n",
      "Epoch 43: val_loss did not improve from 1.08465\n",
      "7/7 - 0s - 19ms/step - accuracy: 0.7850 - loss: 0.4970 - val_accuracy: 0.3550 - val_loss: 2.4110\n",
      "Epoch 44/1000\n",
      "\n",
      "Epoch 44: val_loss did not improve from 1.08465\n",
      "7/7 - 0s - 25ms/step - accuracy: 0.7800 - loss: 0.5145 - val_accuracy: 0.3550 - val_loss: 2.4531\n",
      "Epoch 45/1000\n",
      "\n",
      "Epoch 45: val_loss did not improve from 1.08465\n",
      "7/7 - 0s - 20ms/step - accuracy: 0.7912 - loss: 0.4912 - val_accuracy: 0.3550 - val_loss: 2.3814\n",
      "Epoch 46/1000\n",
      "\n",
      "Epoch 46: val_loss did not improve from 1.08465\n",
      "7/7 - 0s - 20ms/step - accuracy: 0.8350 - loss: 0.4453 - val_accuracy: 0.3450 - val_loss: 2.3902\n",
      "Epoch 47/1000\n",
      "\n",
      "Epoch 47: val_loss did not improve from 1.08465\n",
      "7/7 - 0s - 21ms/step - accuracy: 0.8200 - loss: 0.4435 - val_accuracy: 0.3600 - val_loss: 2.4476\n",
      "Epoch 48/1000\n",
      "\n",
      "Epoch 48: val_loss did not improve from 1.08465\n",
      "7/7 - 0s - 20ms/step - accuracy: 0.8150 - loss: 0.4510 - val_accuracy: 0.3550 - val_loss: 2.5648\n",
      "Epoch 49/1000\n",
      "\n",
      "Epoch 49: val_loss did not improve from 1.08465\n",
      "7/7 - 0s - 19ms/step - accuracy: 0.8363 - loss: 0.4059 - val_accuracy: 0.3500 - val_loss: 2.6623\n",
      "Epoch 50/1000\n",
      "\n",
      "Epoch 50: val_loss did not improve from 1.08465\n",
      "7/7 - 0s - 19ms/step - accuracy: 0.8338 - loss: 0.4121 - val_accuracy: 0.3550 - val_loss: 2.7034\n",
      "Epoch 51/1000\n",
      "\n",
      "Epoch 51: val_loss did not improve from 1.08465\n",
      "7/7 - 0s - 18ms/step - accuracy: 0.8413 - loss: 0.4057 - val_accuracy: 0.3550 - val_loss: 2.7401\n",
      "Epoch 52/1000\n",
      "\n",
      "Epoch 52: val_loss did not improve from 1.08465\n",
      "7/7 - 0s - 18ms/step - accuracy: 0.8500 - loss: 0.4084 - val_accuracy: 0.3500 - val_loss: 2.7302\n",
      "Epoch 53/1000\n",
      "\n",
      "Epoch 53: val_loss did not improve from 1.08465\n",
      "7/7 - 0s - 19ms/step - accuracy: 0.8550 - loss: 0.3897 - val_accuracy: 0.3400 - val_loss: 2.8025\n",
      "Epoch 54/1000\n",
      "\n",
      "Epoch 54: val_loss did not improve from 1.08465\n",
      "7/7 - 0s - 19ms/step - accuracy: 0.8612 - loss: 0.3652 - val_accuracy: 0.3400 - val_loss: 2.9894\n",
      "Epoch 55/1000\n",
      "\n",
      "Epoch 55: val_loss did not improve from 1.08465\n",
      "7/7 - 0s - 18ms/step - accuracy: 0.8562 - loss: 0.3729 - val_accuracy: 0.3300 - val_loss: 2.9143\n",
      "Epoch 56/1000\n",
      "\n",
      "Epoch 56: val_loss did not improve from 1.08465\n",
      "7/7 - 0s - 18ms/step - accuracy: 0.8700 - loss: 0.3535 - val_accuracy: 0.3350 - val_loss: 2.9344\n",
      "Epoch 57/1000\n",
      "\n",
      "Epoch 57: val_loss did not improve from 1.08465\n",
      "7/7 - 0s - 18ms/step - accuracy: 0.8650 - loss: 0.3578 - val_accuracy: 0.3400 - val_loss: 3.0350\n",
      "Epoch 58/1000\n",
      "\n",
      "Epoch 58: val_loss did not improve from 1.08465\n",
      "7/7 - 0s - 18ms/step - accuracy: 0.8863 - loss: 0.3242 - val_accuracy: 0.3400 - val_loss: 3.1135\n",
      "Epoch 59/1000\n",
      "\n",
      "Epoch 59: val_loss did not improve from 1.08465\n",
      "7/7 - 0s - 18ms/step - accuracy: 0.8788 - loss: 0.3306 - val_accuracy: 0.3300 - val_loss: 3.2011\n",
      "Epoch 60/1000\n",
      "\n",
      "Epoch 60: val_loss did not improve from 1.08465\n",
      "7/7 - 0s - 17ms/step - accuracy: 0.8687 - loss: 0.3602 - val_accuracy: 0.3450 - val_loss: 3.2534\n",
      "Epoch 61/1000\n",
      "\n",
      "Epoch 61: val_loss did not improve from 1.08465\n",
      "7/7 - 0s - 20ms/step - accuracy: 0.8763 - loss: 0.3309 - val_accuracy: 0.3400 - val_loss: 3.1162\n",
      "Epoch 62/1000\n",
      "\n",
      "Epoch 62: val_loss did not improve from 1.08465\n",
      "7/7 - 0s - 19ms/step - accuracy: 0.8988 - loss: 0.2973 - val_accuracy: 0.3400 - val_loss: 3.2580\n",
      "Epoch 63/1000\n",
      "\n",
      "Epoch 63: val_loss did not improve from 1.08465\n",
      "7/7 - 0s - 20ms/step - accuracy: 0.9125 - loss: 0.2799 - val_accuracy: 0.3250 - val_loss: 3.4246\n",
      "Epoch 64/1000\n",
      "\n",
      "Epoch 64: val_loss did not improve from 1.08465\n",
      "7/7 - 0s - 19ms/step - accuracy: 0.9112 - loss: 0.2778 - val_accuracy: 0.3300 - val_loss: 3.5386\n",
      "Epoch 65/1000\n",
      "\n",
      "Epoch 65: val_loss did not improve from 1.08465\n",
      "7/7 - 0s - 19ms/step - accuracy: 0.9000 - loss: 0.2850 - val_accuracy: 0.3400 - val_loss: 3.4208\n",
      "Epoch 66/1000\n",
      "\n",
      "Epoch 66: val_loss did not improve from 1.08465\n",
      "7/7 - 0s - 19ms/step - accuracy: 0.8988 - loss: 0.2953 - val_accuracy: 0.3250 - val_loss: 3.4650\n",
      "Epoch 67/1000\n",
      "\n",
      "Epoch 67: val_loss did not improve from 1.08465\n",
      "7/7 - 0s - 19ms/step - accuracy: 0.9262 - loss: 0.2532 - val_accuracy: 0.3150 - val_loss: 3.5723\n",
      "Epoch 68/1000\n",
      "\n",
      "Epoch 68: val_loss did not improve from 1.08465\n",
      "7/7 - 0s - 18ms/step - accuracy: 0.9212 - loss: 0.2395 - val_accuracy: 0.3150 - val_loss: 3.7258\n",
      "Epoch 69/1000\n",
      "\n",
      "Epoch 69: val_loss did not improve from 1.08465\n",
      "7/7 - 0s - 18ms/step - accuracy: 0.9137 - loss: 0.2417 - val_accuracy: 0.3150 - val_loss: 3.7263\n",
      "Epoch 70/1000\n",
      "\n",
      "Epoch 70: val_loss did not improve from 1.08465\n",
      "7/7 - 0s - 20ms/step - accuracy: 0.9200 - loss: 0.2376 - val_accuracy: 0.3250 - val_loss: 3.8487\n",
      "Epoch 71/1000\n",
      "\n",
      "Epoch 71: val_loss did not improve from 1.08465\n",
      "7/7 - 0s - 21ms/step - accuracy: 0.9275 - loss: 0.2266 - val_accuracy: 0.3300 - val_loss: 3.9896\n",
      "Epoch 72/1000\n",
      "\n",
      "Epoch 72: val_loss did not improve from 1.08465\n",
      "7/7 - 0s - 20ms/step - accuracy: 0.9350 - loss: 0.2235 - val_accuracy: 0.3200 - val_loss: 4.1211\n",
      "Epoch 73/1000\n",
      "\n",
      "Epoch 73: val_loss did not improve from 1.08465\n",
      "7/7 - 0s - 19ms/step - accuracy: 0.9312 - loss: 0.1899 - val_accuracy: 0.3200 - val_loss: 4.1429\n",
      "Epoch 74/1000\n",
      "\n",
      "Epoch 74: val_loss did not improve from 1.08465\n",
      "7/7 - 0s - 19ms/step - accuracy: 0.9425 - loss: 0.2077 - val_accuracy: 0.3150 - val_loss: 4.0590\n",
      "Epoch 75/1000\n",
      "\n",
      "Epoch 75: val_loss did not improve from 1.08465\n",
      "7/7 - 0s - 19ms/step - accuracy: 0.9400 - loss: 0.1909 - val_accuracy: 0.3200 - val_loss: 4.2360\n",
      "Epoch 76/1000\n",
      "\n",
      "Epoch 76: val_loss did not improve from 1.08465\n",
      "7/7 - 0s - 19ms/step - accuracy: 0.9488 - loss: 0.1979 - val_accuracy: 0.3150 - val_loss: 4.3132\n",
      "Epoch 77/1000\n",
      "\n",
      "Epoch 77: val_loss did not improve from 1.08465\n",
      "7/7 - 0s - 21ms/step - accuracy: 0.9475 - loss: 0.1731 - val_accuracy: 0.3100 - val_loss: 4.3225\n",
      "Epoch 78/1000\n",
      "\n",
      "Epoch 78: val_loss did not improve from 1.08465\n",
      "7/7 - 0s - 20ms/step - accuracy: 0.9425 - loss: 0.1733 - val_accuracy: 0.3300 - val_loss: 4.3211\n",
      "Epoch 79/1000\n",
      "\n",
      "Epoch 79: val_loss did not improve from 1.08465\n",
      "7/7 - 0s - 21ms/step - accuracy: 0.9400 - loss: 0.1798 - val_accuracy: 0.3300 - val_loss: 4.3773\n",
      "Epoch 80/1000\n",
      "\n",
      "Epoch 80: val_loss did not improve from 1.08465\n",
      "7/7 - 0s - 19ms/step - accuracy: 0.9488 - loss: 0.1693 - val_accuracy: 0.3450 - val_loss: 4.2513\n",
      "Epoch 81/1000\n",
      "\n",
      "Epoch 81: val_loss did not improve from 1.08465\n",
      "7/7 - 0s - 19ms/step - accuracy: 0.9362 - loss: 0.1904 - val_accuracy: 0.3150 - val_loss: 4.4077\n",
      "Epoch 82/1000\n",
      "\n",
      "Epoch 82: val_loss did not improve from 1.08465\n",
      "7/7 - 0s - 18ms/step - accuracy: 0.9375 - loss: 0.1695 - val_accuracy: 0.3200 - val_loss: 4.3445\n",
      "Epoch 83/1000\n",
      "\n",
      "Epoch 83: val_loss did not improve from 1.08465\n",
      "7/7 - 0s - 19ms/step - accuracy: 0.9488 - loss: 0.1751 - val_accuracy: 0.3350 - val_loss: 4.3754\n",
      "Epoch 84/1000\n",
      "\n",
      "Epoch 84: val_loss did not improve from 1.08465\n",
      "7/7 - 0s - 19ms/step - accuracy: 0.9638 - loss: 0.1542 - val_accuracy: 0.3200 - val_loss: 4.6137\n",
      "Epoch 85/1000\n",
      "\n",
      "Epoch 85: val_loss did not improve from 1.08465\n",
      "7/7 - 0s - 18ms/step - accuracy: 0.9538 - loss: 0.1619 - val_accuracy: 0.3400 - val_loss: 4.5840\n",
      "Epoch 86/1000\n",
      "\n",
      "Epoch 86: val_loss did not improve from 1.08465\n",
      "7/7 - 0s - 18ms/step - accuracy: 0.9588 - loss: 0.1381 - val_accuracy: 0.3150 - val_loss: 4.6741\n",
      "Epoch 87/1000\n",
      "\n",
      "Epoch 87: val_loss did not improve from 1.08465\n",
      "7/7 - 0s - 17ms/step - accuracy: 0.9638 - loss: 0.1217 - val_accuracy: 0.3250 - val_loss: 4.7562\n",
      "Epoch 88/1000\n",
      "\n",
      "Epoch 88: val_loss did not improve from 1.08465\n",
      "7/7 - 0s - 17ms/step - accuracy: 0.9550 - loss: 0.1250 - val_accuracy: 0.3200 - val_loss: 4.9429\n",
      "Epoch 89/1000\n",
      "\n",
      "Epoch 89: val_loss did not improve from 1.08465\n",
      "7/7 - 0s - 17ms/step - accuracy: 0.9525 - loss: 0.1475 - val_accuracy: 0.3350 - val_loss: 4.8907\n",
      "Epoch 90/1000\n",
      "\n",
      "Epoch 90: val_loss did not improve from 1.08465\n",
      "7/7 - 0s - 17ms/step - accuracy: 0.9625 - loss: 0.1323 - val_accuracy: 0.3150 - val_loss: 5.0319\n",
      "Epoch 91/1000\n",
      "\n",
      "Epoch 91: val_loss did not improve from 1.08465\n",
      "7/7 - 0s - 16ms/step - accuracy: 0.9675 - loss: 0.1211 - val_accuracy: 0.3300 - val_loss: 5.0161\n",
      "Epoch 92/1000\n",
      "\n",
      "Epoch 92: val_loss did not improve from 1.08465\n",
      "7/7 - 0s - 17ms/step - accuracy: 0.9663 - loss: 0.1131 - val_accuracy: 0.3100 - val_loss: 5.1218\n",
      "Epoch 93/1000\n",
      "\n",
      "Epoch 93: val_loss did not improve from 1.08465\n",
      "7/7 - 0s - 17ms/step - accuracy: 0.9762 - loss: 0.1190 - val_accuracy: 0.3100 - val_loss: 5.1644\n",
      "Epoch 94/1000\n",
      "\n",
      "Epoch 94: val_loss did not improve from 1.08465\n",
      "7/7 - 0s - 17ms/step - accuracy: 0.9700 - loss: 0.1265 - val_accuracy: 0.3100 - val_loss: 5.0543\n",
      "Epoch 95/1000\n",
      "\n",
      "Epoch 95: val_loss did not improve from 1.08465\n",
      "7/7 - 0s - 18ms/step - accuracy: 0.9725 - loss: 0.1065 - val_accuracy: 0.3100 - val_loss: 5.1760\n",
      "Epoch 96/1000\n",
      "\n",
      "Epoch 96: val_loss did not improve from 1.08465\n",
      "7/7 - 0s - 18ms/step - accuracy: 0.9712 - loss: 0.1159 - val_accuracy: 0.3200 - val_loss: 5.3594\n",
      "Epoch 97/1000\n",
      "\n",
      "Epoch 97: val_loss did not improve from 1.08465\n",
      "7/7 - 0s - 18ms/step - accuracy: 0.9525 - loss: 0.1265 - val_accuracy: 0.3200 - val_loss: 5.1724\n",
      "Epoch 98/1000\n",
      "\n",
      "Epoch 98: val_loss did not improve from 1.08465\n",
      "7/7 - 0s - 19ms/step - accuracy: 0.9700 - loss: 0.1127 - val_accuracy: 0.2950 - val_loss: 5.5223\n",
      "Epoch 99/1000\n",
      "\n",
      "Epoch 99: val_loss did not improve from 1.08465\n",
      "7/7 - 0s - 18ms/step - accuracy: 0.9650 - loss: 0.1130 - val_accuracy: 0.3250 - val_loss: 5.3513\n",
      "Epoch 100/1000\n",
      "\n",
      "Epoch 100: val_loss did not improve from 1.08465\n",
      "7/7 - 0s - 19ms/step - accuracy: 0.9588 - loss: 0.1359 - val_accuracy: 0.3000 - val_loss: 5.4467\n",
      "Epoch 101/1000\n",
      "\n",
      "Epoch 101: val_loss did not improve from 1.08465\n",
      "7/7 - 0s - 19ms/step - accuracy: 0.9700 - loss: 0.1087 - val_accuracy: 0.3200 - val_loss: 5.5000\n",
      "Epoch 102/1000\n",
      "\n",
      "Epoch 102: val_loss did not improve from 1.08465\n",
      "7/7 - 0s - 19ms/step - accuracy: 0.9837 - loss: 0.0888 - val_accuracy: 0.3200 - val_loss: 5.4741\n",
      "Epoch 103/1000\n",
      "\n",
      "Epoch 103: val_loss did not improve from 1.08465\n",
      "7/7 - 0s - 18ms/step - accuracy: 0.9750 - loss: 0.0975 - val_accuracy: 0.3050 - val_loss: 5.5779\n",
      "Epoch 104/1000\n",
      "\n",
      "Epoch 104: val_loss did not improve from 1.08465\n",
      "7/7 - 0s - 18ms/step - accuracy: 0.9750 - loss: 0.0768 - val_accuracy: 0.3200 - val_loss: 5.6595\n",
      "Epoch 105/1000\n",
      "\n",
      "Epoch 105: val_loss did not improve from 1.08465\n",
      "7/7 - 0s - 18ms/step - accuracy: 0.9750 - loss: 0.0925 - val_accuracy: 0.3200 - val_loss: 5.8403\n",
      "Epoch 105: early stopping\n",
      "Restoring model weights from the end of the best epoch: 5.\n",
      "Elpased time: 0:00:22\n",
      "WARNING:tensorflow:5 out of the last 15 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x7fa1c868d620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "Fold score (accuracy): 0.41\n",
      "Fold #4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/arsi/miniconda3/envs/tensorflow/lib/python3.12/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"testnet\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"testnet\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">320</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12544</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,605,760</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">387</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │           \u001b[38;5;34m320\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │        \u001b[38;5;34m18,496\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d (\u001b[38;5;33mMaxPooling2D\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12544\u001b[0m)          │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │     \u001b[38;5;34m1,605,760\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m)              │           \u001b[38;5;34m387\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,624,963</span> (6.20 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,624,963\u001b[0m (6.20 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,624,963</span> (6.20 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,624,963\u001b[0m (6.20 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "\n",
      "Epoch 1: val_loss improved from inf to 1.09853, saving model to /mnt/g/My Drive/Projects/110_JetscapeMl/hm_jetscapeml_source/models/testnet/model.keras\n",
      "7/7 - 5s - 695ms/step - accuracy: 0.3125 - loss: 1.0995 - val_accuracy: 0.3450 - val_loss: 1.0985\n",
      "Epoch 2/1000\n",
      "\n",
      "Epoch 2: val_loss improved from 1.09853 to 1.09814, saving model to /mnt/g/My Drive/Projects/110_JetscapeMl/hm_jetscapeml_source/models/testnet/model.keras\n",
      "7/7 - 1s - 79ms/step - accuracy: 0.3887 - loss: 1.0955 - val_accuracy: 0.3550 - val_loss: 1.0981\n",
      "Epoch 3/1000\n",
      "\n",
      "Epoch 3: val_loss did not improve from 1.09814\n",
      "7/7 - 0s - 21ms/step - accuracy: 0.4137 - loss: 1.0894 - val_accuracy: 0.3350 - val_loss: 1.0985\n",
      "Epoch 4/1000\n",
      "\n",
      "Epoch 4: val_loss did not improve from 1.09814\n",
      "7/7 - 0s - 21ms/step - accuracy: 0.4212 - loss: 1.0791 - val_accuracy: 0.3800 - val_loss: 1.1021\n",
      "Epoch 5/1000\n",
      "\n",
      "Epoch 5: val_loss did not improve from 1.09814\n",
      "7/7 - 0s - 18ms/step - accuracy: 0.4525 - loss: 1.0590 - val_accuracy: 0.3600 - val_loss: 1.1134\n",
      "Epoch 6/1000\n",
      "\n",
      "Epoch 6: val_loss did not improve from 1.09814\n",
      "7/7 - 0s - 19ms/step - accuracy: 0.4650 - loss: 1.0409 - val_accuracy: 0.3600 - val_loss: 1.1317\n",
      "Epoch 7/1000\n",
      "\n",
      "Epoch 7: val_loss did not improve from 1.09814\n",
      "7/7 - 0s - 18ms/step - accuracy: 0.4538 - loss: 1.0288 - val_accuracy: 0.3400 - val_loss: 1.1384\n",
      "Epoch 8/1000\n",
      "\n",
      "Epoch 8: val_loss did not improve from 1.09814\n",
      "7/7 - 0s - 18ms/step - accuracy: 0.4613 - loss: 1.0154 - val_accuracy: 0.3550 - val_loss: 1.1347\n",
      "Epoch 9/1000\n",
      "\n",
      "Epoch 9: val_loss did not improve from 1.09814\n",
      "7/7 - 0s - 20ms/step - accuracy: 0.4950 - loss: 0.9935 - val_accuracy: 0.3700 - val_loss: 1.1436\n",
      "Epoch 10/1000\n",
      "\n",
      "Epoch 10: val_loss did not improve from 1.09814\n",
      "7/7 - 0s - 22ms/step - accuracy: 0.5100 - loss: 0.9812 - val_accuracy: 0.3550 - val_loss: 1.1471\n",
      "Epoch 11/1000\n",
      "\n",
      "Epoch 11: val_loss did not improve from 1.09814\n",
      "7/7 - 0s - 24ms/step - accuracy: 0.5088 - loss: 0.9645 - val_accuracy: 0.3600 - val_loss: 1.1583\n",
      "Epoch 12/1000\n",
      "\n",
      "Epoch 12: val_loss did not improve from 1.09814\n",
      "7/7 - 0s - 22ms/step - accuracy: 0.5113 - loss: 0.9501 - val_accuracy: 0.3550 - val_loss: 1.1912\n",
      "Epoch 13/1000\n",
      "\n",
      "Epoch 13: val_loss did not improve from 1.09814\n",
      "7/7 - 0s - 21ms/step - accuracy: 0.5263 - loss: 0.9392 - val_accuracy: 0.3800 - val_loss: 1.1933\n",
      "Epoch 14/1000\n",
      "\n",
      "Epoch 14: val_loss did not improve from 1.09814\n",
      "7/7 - 0s - 20ms/step - accuracy: 0.5500 - loss: 0.9139 - val_accuracy: 0.3700 - val_loss: 1.2209\n",
      "Epoch 15/1000\n",
      "\n",
      "Epoch 15: val_loss did not improve from 1.09814\n",
      "7/7 - 0s - 20ms/step - accuracy: 0.5562 - loss: 0.8987 - val_accuracy: 0.3600 - val_loss: 1.2602\n",
      "Epoch 16/1000\n",
      "\n",
      "Epoch 16: val_loss did not improve from 1.09814\n",
      "7/7 - 0s - 19ms/step - accuracy: 0.5638 - loss: 0.8801 - val_accuracy: 0.3250 - val_loss: 1.2815\n",
      "Epoch 17/1000\n",
      "\n",
      "Epoch 17: val_loss did not improve from 1.09814\n",
      "7/7 - 0s - 19ms/step - accuracy: 0.5612 - loss: 0.8953 - val_accuracy: 0.3600 - val_loss: 1.2793\n",
      "Epoch 18/1000\n",
      "\n",
      "Epoch 18: val_loss did not improve from 1.09814\n",
      "7/7 - 0s - 19ms/step - accuracy: 0.5788 - loss: 0.8617 - val_accuracy: 0.3550 - val_loss: 1.3110\n",
      "Epoch 19/1000\n",
      "\n",
      "Epoch 19: val_loss did not improve from 1.09814\n",
      "7/7 - 0s - 19ms/step - accuracy: 0.5925 - loss: 0.8473 - val_accuracy: 0.3550 - val_loss: 1.3459\n",
      "Epoch 20/1000\n",
      "\n",
      "Epoch 20: val_loss did not improve from 1.09814\n",
      "7/7 - 0s - 21ms/step - accuracy: 0.6288 - loss: 0.8126 - val_accuracy: 0.3400 - val_loss: 1.3459\n",
      "Epoch 21/1000\n",
      "\n",
      "Epoch 21: val_loss did not improve from 1.09814\n",
      "7/7 - 0s - 19ms/step - accuracy: 0.5962 - loss: 0.8158 - val_accuracy: 0.3450 - val_loss: 1.3771\n",
      "Epoch 22/1000\n",
      "\n",
      "Epoch 22: val_loss did not improve from 1.09814\n",
      "7/7 - 0s - 18ms/step - accuracy: 0.6288 - loss: 0.7952 - val_accuracy: 0.3350 - val_loss: 1.3955\n",
      "Epoch 23/1000\n",
      "\n",
      "Epoch 23: val_loss did not improve from 1.09814\n",
      "7/7 - 0s - 19ms/step - accuracy: 0.6237 - loss: 0.7799 - val_accuracy: 0.3650 - val_loss: 1.4330\n",
      "Epoch 24/1000\n",
      "\n",
      "Epoch 24: val_loss did not improve from 1.09814\n",
      "7/7 - 0s - 21ms/step - accuracy: 0.6413 - loss: 0.7576 - val_accuracy: 0.3300 - val_loss: 1.4613\n",
      "Epoch 25/1000\n",
      "\n",
      "Epoch 25: val_loss did not improve from 1.09814\n",
      "7/7 - 0s - 20ms/step - accuracy: 0.6438 - loss: 0.7758 - val_accuracy: 0.3300 - val_loss: 1.4815\n",
      "Epoch 26/1000\n",
      "\n",
      "Epoch 26: val_loss did not improve from 1.09814\n",
      "7/7 - 0s - 21ms/step - accuracy: 0.6712 - loss: 0.7275 - val_accuracy: 0.3400 - val_loss: 1.5270\n",
      "Epoch 27/1000\n",
      "\n",
      "Epoch 27: val_loss did not improve from 1.09814\n",
      "7/7 - 0s - 21ms/step - accuracy: 0.6662 - loss: 0.7153 - val_accuracy: 0.3400 - val_loss: 1.6120\n",
      "Epoch 28/1000\n",
      "\n",
      "Epoch 28: val_loss did not improve from 1.09814\n",
      "7/7 - 0s - 21ms/step - accuracy: 0.6450 - loss: 0.7298 - val_accuracy: 0.2900 - val_loss: 1.5434\n",
      "Epoch 29/1000\n",
      "\n",
      "Epoch 29: val_loss did not improve from 1.09814\n",
      "7/7 - 0s - 20ms/step - accuracy: 0.6787 - loss: 0.7015 - val_accuracy: 0.3350 - val_loss: 1.6031\n",
      "Epoch 30/1000\n",
      "\n",
      "Epoch 30: val_loss did not improve from 1.09814\n",
      "7/7 - 0s - 18ms/step - accuracy: 0.6913 - loss: 0.6957 - val_accuracy: 0.3400 - val_loss: 1.6308\n",
      "Epoch 31/1000\n",
      "\n",
      "Epoch 31: val_loss did not improve from 1.09814\n",
      "7/7 - 0s - 19ms/step - accuracy: 0.6812 - loss: 0.6778 - val_accuracy: 0.3800 - val_loss: 1.6364\n",
      "Epoch 32/1000\n",
      "\n",
      "Epoch 32: val_loss did not improve from 1.09814\n",
      "7/7 - 0s - 18ms/step - accuracy: 0.7150 - loss: 0.6385 - val_accuracy: 0.3550 - val_loss: 1.6718\n",
      "Epoch 33/1000\n",
      "\n",
      "Epoch 33: val_loss did not improve from 1.09814\n",
      "7/7 - 0s - 19ms/step - accuracy: 0.7050 - loss: 0.6443 - val_accuracy: 0.3700 - val_loss: 1.7111\n",
      "Epoch 34/1000\n",
      "\n",
      "Epoch 34: val_loss did not improve from 1.09814\n",
      "7/7 - 0s - 20ms/step - accuracy: 0.7225 - loss: 0.6141 - val_accuracy: 0.3550 - val_loss: 1.7328\n",
      "Epoch 35/1000\n",
      "\n",
      "Epoch 35: val_loss did not improve from 1.09814\n",
      "7/7 - 0s - 18ms/step - accuracy: 0.7337 - loss: 0.6131 - val_accuracy: 0.3700 - val_loss: 1.7683\n",
      "Epoch 36/1000\n",
      "\n",
      "Epoch 36: val_loss did not improve from 1.09814\n",
      "7/7 - 0s - 20ms/step - accuracy: 0.7613 - loss: 0.5754 - val_accuracy: 0.3300 - val_loss: 1.8248\n",
      "Epoch 37/1000\n",
      "\n",
      "Epoch 37: val_loss did not improve from 1.09814\n",
      "7/7 - 0s - 19ms/step - accuracy: 0.7550 - loss: 0.5697 - val_accuracy: 0.3550 - val_loss: 1.9047\n",
      "Epoch 38/1000\n",
      "\n",
      "Epoch 38: val_loss did not improve from 1.09814\n",
      "7/7 - 0s - 20ms/step - accuracy: 0.7650 - loss: 0.5591 - val_accuracy: 0.3550 - val_loss: 1.9739\n",
      "Epoch 39/1000\n",
      "\n",
      "Epoch 39: val_loss did not improve from 1.09814\n",
      "7/7 - 0s - 22ms/step - accuracy: 0.7575 - loss: 0.5536 - val_accuracy: 0.3400 - val_loss: 2.0405\n",
      "Epoch 40/1000\n",
      "\n",
      "Epoch 40: val_loss did not improve from 1.09814\n",
      "7/7 - 0s - 22ms/step - accuracy: 0.7713 - loss: 0.5196 - val_accuracy: 0.3250 - val_loss: 2.0647\n",
      "Epoch 41/1000\n",
      "\n",
      "Epoch 41: val_loss did not improve from 1.09814\n",
      "7/7 - 0s - 19ms/step - accuracy: 0.7937 - loss: 0.4958 - val_accuracy: 0.3200 - val_loss: 2.0357\n",
      "Epoch 42/1000\n",
      "\n",
      "Epoch 42: val_loss did not improve from 1.09814\n",
      "7/7 - 0s - 19ms/step - accuracy: 0.8050 - loss: 0.4998 - val_accuracy: 0.3400 - val_loss: 2.1356\n",
      "Epoch 43/1000\n",
      "\n",
      "Epoch 43: val_loss did not improve from 1.09814\n",
      "7/7 - 0s - 21ms/step - accuracy: 0.7912 - loss: 0.4897 - val_accuracy: 0.3450 - val_loss: 2.1151\n",
      "Epoch 44/1000\n",
      "\n",
      "Epoch 44: val_loss did not improve from 1.09814\n",
      "7/7 - 0s - 22ms/step - accuracy: 0.8300 - loss: 0.4377 - val_accuracy: 0.3650 - val_loss: 2.1680\n",
      "Epoch 45/1000\n",
      "\n",
      "Epoch 45: val_loss did not improve from 1.09814\n",
      "7/7 - 0s - 23ms/step - accuracy: 0.8150 - loss: 0.4559 - val_accuracy: 0.3700 - val_loss: 2.2460\n",
      "Epoch 46/1000\n",
      "\n",
      "Epoch 46: val_loss did not improve from 1.09814\n",
      "7/7 - 0s - 22ms/step - accuracy: 0.8313 - loss: 0.4566 - val_accuracy: 0.3450 - val_loss: 2.2913\n",
      "Epoch 47/1000\n",
      "\n",
      "Epoch 47: val_loss did not improve from 1.09814\n",
      "7/7 - 0s - 21ms/step - accuracy: 0.8363 - loss: 0.4262 - val_accuracy: 0.3350 - val_loss: 2.3596\n",
      "Epoch 48/1000\n",
      "\n",
      "Epoch 48: val_loss did not improve from 1.09814\n",
      "7/7 - 0s - 19ms/step - accuracy: 0.8537 - loss: 0.4035 - val_accuracy: 0.2950 - val_loss: 2.3792\n",
      "Epoch 49/1000\n",
      "\n",
      "Epoch 49: val_loss did not improve from 1.09814\n",
      "7/7 - 0s - 18ms/step - accuracy: 0.8375 - loss: 0.3961 - val_accuracy: 0.3400 - val_loss: 2.5121\n",
      "Epoch 50/1000\n",
      "\n",
      "Epoch 50: val_loss did not improve from 1.09814\n",
      "7/7 - 0s - 18ms/step - accuracy: 0.8487 - loss: 0.4000 - val_accuracy: 0.3250 - val_loss: 2.5466\n",
      "Epoch 51/1000\n",
      "\n",
      "Epoch 51: val_loss did not improve from 1.09814\n",
      "7/7 - 0s - 18ms/step - accuracy: 0.8587 - loss: 0.3665 - val_accuracy: 0.3450 - val_loss: 2.5513\n",
      "Epoch 52/1000\n",
      "\n",
      "Epoch 52: val_loss did not improve from 1.09814\n",
      "7/7 - 0s - 17ms/step - accuracy: 0.8600 - loss: 0.3696 - val_accuracy: 0.3550 - val_loss: 2.6822\n",
      "Epoch 53/1000\n",
      "\n",
      "Epoch 53: val_loss did not improve from 1.09814\n",
      "7/7 - 0s - 17ms/step - accuracy: 0.8775 - loss: 0.3384 - val_accuracy: 0.3350 - val_loss: 2.6796\n",
      "Epoch 54/1000\n",
      "\n",
      "Epoch 54: val_loss did not improve from 1.09814\n",
      "7/7 - 0s - 17ms/step - accuracy: 0.8813 - loss: 0.3287 - val_accuracy: 0.3450 - val_loss: 2.7862\n",
      "Epoch 55/1000\n",
      "\n",
      "Epoch 55: val_loss did not improve from 1.09814\n",
      "7/7 - 0s - 17ms/step - accuracy: 0.8763 - loss: 0.3393 - val_accuracy: 0.3400 - val_loss: 2.8468\n",
      "Epoch 56/1000\n",
      "\n",
      "Epoch 56: val_loss did not improve from 1.09814\n",
      "7/7 - 0s - 17ms/step - accuracy: 0.8863 - loss: 0.3053 - val_accuracy: 0.3300 - val_loss: 2.8936\n",
      "Epoch 57/1000\n",
      "\n",
      "Epoch 57: val_loss did not improve from 1.09814\n",
      "7/7 - 0s - 18ms/step - accuracy: 0.8737 - loss: 0.3182 - val_accuracy: 0.3250 - val_loss: 2.8803\n",
      "Epoch 58/1000\n",
      "\n",
      "Epoch 58: val_loss did not improve from 1.09814\n",
      "7/7 - 0s - 19ms/step - accuracy: 0.8950 - loss: 0.2874 - val_accuracy: 0.3200 - val_loss: 2.8892\n",
      "Epoch 59/1000\n",
      "\n",
      "Epoch 59: val_loss did not improve from 1.09814\n",
      "7/7 - 0s - 18ms/step - accuracy: 0.9038 - loss: 0.2897 - val_accuracy: 0.3300 - val_loss: 3.0200\n",
      "Epoch 60/1000\n",
      "\n",
      "Epoch 60: val_loss did not improve from 1.09814\n",
      "7/7 - 0s - 18ms/step - accuracy: 0.9075 - loss: 0.2645 - val_accuracy: 0.3250 - val_loss: 3.0817\n",
      "Epoch 61/1000\n",
      "\n",
      "Epoch 61: val_loss did not improve from 1.09814\n",
      "7/7 - 0s - 18ms/step - accuracy: 0.9025 - loss: 0.2673 - val_accuracy: 0.3100 - val_loss: 3.1594\n",
      "Epoch 62/1000\n",
      "\n",
      "Epoch 62: val_loss did not improve from 1.09814\n",
      "7/7 - 0s - 18ms/step - accuracy: 0.9112 - loss: 0.2514 - val_accuracy: 0.3300 - val_loss: 3.2985\n",
      "Epoch 63/1000\n",
      "\n",
      "Epoch 63: val_loss did not improve from 1.09814\n",
      "7/7 - 0s - 18ms/step - accuracy: 0.9075 - loss: 0.2507 - val_accuracy: 0.3150 - val_loss: 3.4484\n",
      "Epoch 64/1000\n",
      "\n",
      "Epoch 64: val_loss did not improve from 1.09814\n",
      "7/7 - 0s - 18ms/step - accuracy: 0.9200 - loss: 0.2320 - val_accuracy: 0.3050 - val_loss: 3.4577\n",
      "Epoch 65/1000\n",
      "\n",
      "Epoch 65: val_loss did not improve from 1.09814\n",
      "7/7 - 0s - 19ms/step - accuracy: 0.9162 - loss: 0.2289 - val_accuracy: 0.3200 - val_loss: 3.3907\n",
      "Epoch 66/1000\n",
      "\n",
      "Epoch 66: val_loss did not improve from 1.09814\n",
      "7/7 - 0s - 17ms/step - accuracy: 0.9262 - loss: 0.2258 - val_accuracy: 0.3050 - val_loss: 3.4388\n",
      "Epoch 67/1000\n",
      "\n",
      "Epoch 67: val_loss did not improve from 1.09814\n",
      "7/7 - 0s - 25ms/step - accuracy: 0.9337 - loss: 0.2106 - val_accuracy: 0.3250 - val_loss: 3.5294\n",
      "Epoch 68/1000\n",
      "\n",
      "Epoch 68: val_loss did not improve from 1.09814\n",
      "7/7 - 0s - 33ms/step - accuracy: 0.9287 - loss: 0.2011 - val_accuracy: 0.3000 - val_loss: 3.5730\n",
      "Epoch 69/1000\n",
      "\n",
      "Epoch 69: val_loss did not improve from 1.09814\n",
      "7/7 - 0s - 26ms/step - accuracy: 0.9350 - loss: 0.2060 - val_accuracy: 0.3300 - val_loss: 3.6945\n",
      "Epoch 70/1000\n",
      "\n",
      "Epoch 70: val_loss did not improve from 1.09814\n",
      "7/7 - 0s - 26ms/step - accuracy: 0.9463 - loss: 0.1825 - val_accuracy: 0.3150 - val_loss: 3.6783\n",
      "Epoch 71/1000\n",
      "\n",
      "Epoch 71: val_loss did not improve from 1.09814\n",
      "7/7 - 0s - 25ms/step - accuracy: 0.9575 - loss: 0.1550 - val_accuracy: 0.3250 - val_loss: 3.7721\n",
      "Epoch 72/1000\n",
      "\n",
      "Epoch 72: val_loss did not improve from 1.09814\n",
      "7/7 - 0s - 26ms/step - accuracy: 0.9400 - loss: 0.1653 - val_accuracy: 0.3100 - val_loss: 3.7783\n",
      "Epoch 73/1000\n",
      "\n",
      "Epoch 73: val_loss did not improve from 1.09814\n",
      "7/7 - 0s - 25ms/step - accuracy: 0.9463 - loss: 0.1876 - val_accuracy: 0.3150 - val_loss: 3.8305\n",
      "Epoch 74/1000\n",
      "\n",
      "Epoch 74: val_loss did not improve from 1.09814\n",
      "7/7 - 0s - 23ms/step - accuracy: 0.9538 - loss: 0.1684 - val_accuracy: 0.3050 - val_loss: 3.8959\n",
      "Epoch 75/1000\n",
      "\n",
      "Epoch 75: val_loss did not improve from 1.09814\n",
      "7/7 - 0s - 20ms/step - accuracy: 0.9337 - loss: 0.1778 - val_accuracy: 0.3300 - val_loss: 3.9154\n",
      "Epoch 76/1000\n",
      "\n",
      "Epoch 76: val_loss did not improve from 1.09814\n",
      "7/7 - 0s - 19ms/step - accuracy: 0.9550 - loss: 0.1645 - val_accuracy: 0.3100 - val_loss: 4.0356\n",
      "Epoch 77/1000\n",
      "\n",
      "Epoch 77: val_loss did not improve from 1.09814\n",
      "7/7 - 0s - 19ms/step - accuracy: 0.9575 - loss: 0.1587 - val_accuracy: 0.3050 - val_loss: 4.1763\n",
      "Epoch 78/1000\n",
      "\n",
      "Epoch 78: val_loss did not improve from 1.09814\n",
      "7/7 - 0s - 19ms/step - accuracy: 0.9563 - loss: 0.1546 - val_accuracy: 0.3100 - val_loss: 4.2147\n",
      "Epoch 79/1000\n",
      "\n",
      "Epoch 79: val_loss did not improve from 1.09814\n",
      "7/7 - 0s - 20ms/step - accuracy: 0.9450 - loss: 0.1637 - val_accuracy: 0.3200 - val_loss: 4.1191\n",
      "Epoch 80/1000\n",
      "\n",
      "Epoch 80: val_loss did not improve from 1.09814\n",
      "7/7 - 0s - 21ms/step - accuracy: 0.9675 - loss: 0.1466 - val_accuracy: 0.3150 - val_loss: 4.1513\n",
      "Epoch 81/1000\n",
      "\n",
      "Epoch 81: val_loss did not improve from 1.09814\n",
      "7/7 - 0s - 22ms/step - accuracy: 0.9563 - loss: 0.1479 - val_accuracy: 0.3150 - val_loss: 4.2719\n",
      "Epoch 82/1000\n",
      "\n",
      "Epoch 82: val_loss did not improve from 1.09814\n",
      "7/7 - 0s - 24ms/step - accuracy: 0.9575 - loss: 0.1525 - val_accuracy: 0.3250 - val_loss: 4.2384\n",
      "Epoch 83/1000\n",
      "\n",
      "Epoch 83: val_loss did not improve from 1.09814\n",
      "7/7 - 0s - 20ms/step - accuracy: 0.9600 - loss: 0.1332 - val_accuracy: 0.3000 - val_loss: 4.3646\n",
      "Epoch 84/1000\n",
      "\n",
      "Epoch 84: val_loss did not improve from 1.09814\n",
      "7/7 - 0s - 23ms/step - accuracy: 0.9762 - loss: 0.1141 - val_accuracy: 0.2950 - val_loss: 4.4915\n",
      "Epoch 85/1000\n",
      "\n",
      "Epoch 85: val_loss did not improve from 1.09814\n",
      "7/7 - 0s - 26ms/step - accuracy: 0.9563 - loss: 0.1457 - val_accuracy: 0.3000 - val_loss: 4.5107\n",
      "Epoch 86/1000\n",
      "\n",
      "Epoch 86: val_loss did not improve from 1.09814\n",
      "7/7 - 0s - 21ms/step - accuracy: 0.9613 - loss: 0.1182 - val_accuracy: 0.3050 - val_loss: 4.6077\n",
      "Epoch 87/1000\n",
      "\n",
      "Epoch 87: val_loss did not improve from 1.09814\n",
      "7/7 - 0s - 21ms/step - accuracy: 0.9638 - loss: 0.1138 - val_accuracy: 0.3200 - val_loss: 4.6222\n",
      "Epoch 88/1000\n",
      "\n",
      "Epoch 88: val_loss did not improve from 1.09814\n",
      "7/7 - 0s - 22ms/step - accuracy: 0.9688 - loss: 0.1070 - val_accuracy: 0.2950 - val_loss: 4.6136\n",
      "Epoch 89/1000\n",
      "\n",
      "Epoch 89: val_loss did not improve from 1.09814\n",
      "7/7 - 0s - 21ms/step - accuracy: 0.9700 - loss: 0.1120 - val_accuracy: 0.3150 - val_loss: 4.6903\n",
      "Epoch 90/1000\n",
      "\n",
      "Epoch 90: val_loss did not improve from 1.09814\n",
      "7/7 - 0s - 20ms/step - accuracy: 0.9675 - loss: 0.1129 - val_accuracy: 0.3200 - val_loss: 4.7788\n",
      "Epoch 91/1000\n",
      "\n",
      "Epoch 91: val_loss did not improve from 1.09814\n",
      "7/7 - 0s - 22ms/step - accuracy: 0.9663 - loss: 0.1108 - val_accuracy: 0.3050 - val_loss: 4.7413\n",
      "Epoch 92/1000\n",
      "\n",
      "Epoch 92: val_loss did not improve from 1.09814\n",
      "7/7 - 0s - 20ms/step - accuracy: 0.9737 - loss: 0.1060 - val_accuracy: 0.3100 - val_loss: 4.8177\n",
      "Epoch 93/1000\n",
      "\n",
      "Epoch 93: val_loss did not improve from 1.09814\n",
      "7/7 - 0s - 19ms/step - accuracy: 0.9700 - loss: 0.1130 - val_accuracy: 0.2950 - val_loss: 4.9144\n",
      "Epoch 94/1000\n",
      "\n",
      "Epoch 94: val_loss did not improve from 1.09814\n",
      "7/7 - 0s - 19ms/step - accuracy: 0.9800 - loss: 0.0833 - val_accuracy: 0.3200 - val_loss: 5.0574\n",
      "Epoch 95/1000\n",
      "\n",
      "Epoch 95: val_loss did not improve from 1.09814\n",
      "7/7 - 0s - 18ms/step - accuracy: 0.9650 - loss: 0.1115 - val_accuracy: 0.3050 - val_loss: 4.9133\n",
      "Epoch 96/1000\n",
      "\n",
      "Epoch 96: val_loss did not improve from 1.09814\n",
      "7/7 - 0s - 18ms/step - accuracy: 0.9675 - loss: 0.1019 - val_accuracy: 0.3050 - val_loss: 4.8615\n",
      "Epoch 97/1000\n",
      "\n",
      "Epoch 97: val_loss did not improve from 1.09814\n",
      "7/7 - 0s - 18ms/step - accuracy: 0.9787 - loss: 0.0892 - val_accuracy: 0.3100 - val_loss: 4.9109\n",
      "Epoch 98/1000\n",
      "\n",
      "Epoch 98: val_loss did not improve from 1.09814\n",
      "7/7 - 0s - 18ms/step - accuracy: 0.9725 - loss: 0.0888 - val_accuracy: 0.3050 - val_loss: 4.9266\n",
      "Epoch 99/1000\n",
      "\n",
      "Epoch 99: val_loss did not improve from 1.09814\n",
      "7/7 - 0s - 18ms/step - accuracy: 0.9775 - loss: 0.0920 - val_accuracy: 0.3100 - val_loss: 5.0370\n",
      "Epoch 100/1000\n",
      "\n",
      "Epoch 100: val_loss did not improve from 1.09814\n",
      "7/7 - 0s - 17ms/step - accuracy: 0.9775 - loss: 0.0933 - val_accuracy: 0.3150 - val_loss: 5.1030\n",
      "Epoch 101/1000\n",
      "\n",
      "Epoch 101: val_loss did not improve from 1.09814\n",
      "7/7 - 0s - 19ms/step - accuracy: 0.9700 - loss: 0.0893 - val_accuracy: 0.3000 - val_loss: 5.0728\n",
      "Epoch 101: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Elpased time: 0:00:20\n",
      "WARNING:tensorflow:5 out of the last 15 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x7fa15c0ce660> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
      "Fold score (accuracy): 0.345\n",
      "Fold #5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/arsi/miniconda3/envs/tensorflow/lib/python3.12/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"testnet\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"testnet\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">320</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12544</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,605,760</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">387</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │           \u001b[38;5;34m320\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │        \u001b[38;5;34m18,496\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d (\u001b[38;5;33mMaxPooling2D\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12544\u001b[0m)          │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │     \u001b[38;5;34m1,605,760\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m)              │           \u001b[38;5;34m387\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,624,963</span> (6.20 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,624,963\u001b[0m (6.20 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,624,963</span> (6.20 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,624,963\u001b[0m (6.20 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "\n",
      "Epoch 1: val_loss improved from inf to 1.09841, saving model to /mnt/g/My Drive/Projects/110_JetscapeMl/hm_jetscapeml_source/models/testnet/model.keras\n",
      "7/7 - 5s - 737ms/step - accuracy: 0.3438 - loss: 1.0988 - val_accuracy: 0.3800 - val_loss: 1.0984\n",
      "Epoch 2/1000\n",
      "\n",
      "Epoch 2: val_loss improved from 1.09841 to 1.09701, saving model to /mnt/g/My Drive/Projects/110_JetscapeMl/hm_jetscapeml_source/models/testnet/model.keras\n",
      "7/7 - 1s - 79ms/step - accuracy: 0.3663 - loss: 1.0934 - val_accuracy: 0.3350 - val_loss: 1.0970\n",
      "Epoch 3/1000\n",
      "\n",
      "Epoch 3: val_loss improved from 1.09701 to 1.09584, saving model to /mnt/g/My Drive/Projects/110_JetscapeMl/hm_jetscapeml_source/models/testnet/model.keras\n",
      "7/7 - 0s - 70ms/step - accuracy: 0.4313 - loss: 1.0827 - val_accuracy: 0.3550 - val_loss: 1.0958\n",
      "Epoch 4/1000\n",
      "\n",
      "Epoch 4: val_loss did not improve from 1.09584\n",
      "7/7 - 0s - 25ms/step - accuracy: 0.4325 - loss: 1.0653 - val_accuracy: 0.3950 - val_loss: 1.1007\n",
      "Epoch 5/1000\n",
      "\n",
      "Epoch 5: val_loss did not improve from 1.09584\n",
      "7/7 - 0s - 23ms/step - accuracy: 0.4387 - loss: 1.0461 - val_accuracy: 0.3850 - val_loss: 1.1163\n",
      "Epoch 6/1000\n",
      "\n",
      "Epoch 6: val_loss did not improve from 1.09584\n",
      "7/7 - 0s - 19ms/step - accuracy: 0.4762 - loss: 1.0258 - val_accuracy: 0.4000 - val_loss: 1.1485\n",
      "Epoch 7/1000\n",
      "\n",
      "Epoch 7: val_loss did not improve from 1.09584\n",
      "7/7 - 0s - 19ms/step - accuracy: 0.4800 - loss: 1.0151 - val_accuracy: 0.4350 - val_loss: 1.1574\n",
      "Epoch 8/1000\n",
      "\n",
      "Epoch 8: val_loss did not improve from 1.09584\n",
      "7/7 - 0s - 19ms/step - accuracy: 0.4875 - loss: 1.0021 - val_accuracy: 0.3950 - val_loss: 1.1635\n",
      "Epoch 9/1000\n",
      "\n",
      "Epoch 9: val_loss did not improve from 1.09584\n",
      "7/7 - 0s - 18ms/step - accuracy: 0.5175 - loss: 0.9875 - val_accuracy: 0.4100 - val_loss: 1.1878\n",
      "Epoch 10/1000\n",
      "\n",
      "Epoch 10: val_loss did not improve from 1.09584\n",
      "7/7 - 0s - 21ms/step - accuracy: 0.5138 - loss: 0.9672 - val_accuracy: 0.4050 - val_loss: 1.2036\n",
      "Epoch 11/1000\n",
      "\n",
      "Epoch 11: val_loss did not improve from 1.09584\n",
      "7/7 - 0s - 19ms/step - accuracy: 0.5213 - loss: 0.9674 - val_accuracy: 0.4200 - val_loss: 1.2125\n",
      "Epoch 12/1000\n",
      "\n",
      "Epoch 12: val_loss did not improve from 1.09584\n",
      "7/7 - 0s - 21ms/step - accuracy: 0.5150 - loss: 0.9507 - val_accuracy: 0.4150 - val_loss: 1.2213\n",
      "Epoch 13/1000\n",
      "\n",
      "Epoch 13: val_loss did not improve from 1.09584\n",
      "7/7 - 0s - 20ms/step - accuracy: 0.5188 - loss: 0.9443 - val_accuracy: 0.3900 - val_loss: 1.2057\n",
      "Epoch 14/1000\n",
      "\n",
      "Epoch 14: val_loss did not improve from 1.09584\n",
      "7/7 - 0s - 19ms/step - accuracy: 0.5437 - loss: 0.9304 - val_accuracy: 0.3900 - val_loss: 1.2560\n",
      "Epoch 15/1000\n",
      "\n",
      "Epoch 15: val_loss did not improve from 1.09584\n",
      "7/7 - 0s - 19ms/step - accuracy: 0.5387 - loss: 0.9306 - val_accuracy: 0.4100 - val_loss: 1.2283\n",
      "Epoch 16/1000\n",
      "\n",
      "Epoch 16: val_loss did not improve from 1.09584\n",
      "7/7 - 0s - 19ms/step - accuracy: 0.5487 - loss: 0.9308 - val_accuracy: 0.4050 - val_loss: 1.2376\n",
      "Epoch 17/1000\n",
      "\n",
      "Epoch 17: val_loss did not improve from 1.09584\n",
      "7/7 - 0s - 18ms/step - accuracy: 0.5738 - loss: 0.8969 - val_accuracy: 0.4200 - val_loss: 1.2653\n",
      "Epoch 18/1000\n",
      "\n",
      "Epoch 18: val_loss did not improve from 1.09584\n",
      "7/7 - 0s - 17ms/step - accuracy: 0.5512 - loss: 0.8910 - val_accuracy: 0.4150 - val_loss: 1.2802\n",
      "Epoch 19/1000\n",
      "\n",
      "Epoch 19: val_loss did not improve from 1.09584\n",
      "7/7 - 0s - 18ms/step - accuracy: 0.5725 - loss: 0.8817 - val_accuracy: 0.3900 - val_loss: 1.3045\n",
      "Epoch 20/1000\n",
      "\n",
      "Epoch 20: val_loss did not improve from 1.09584\n",
      "7/7 - 0s - 18ms/step - accuracy: 0.5675 - loss: 0.8719 - val_accuracy: 0.4100 - val_loss: 1.2852\n",
      "Epoch 21/1000\n",
      "\n",
      "Epoch 21: val_loss did not improve from 1.09584\n",
      "7/7 - 0s - 18ms/step - accuracy: 0.5825 - loss: 0.8591 - val_accuracy: 0.3750 - val_loss: 1.2770\n",
      "Epoch 22/1000\n",
      "\n",
      "Epoch 22: val_loss did not improve from 1.09584\n",
      "7/7 - 0s - 18ms/step - accuracy: 0.5950 - loss: 0.8584 - val_accuracy: 0.4200 - val_loss: 1.3088\n",
      "Epoch 23/1000\n",
      "\n",
      "Epoch 23: val_loss did not improve from 1.09584\n",
      "7/7 - 0s - 21ms/step - accuracy: 0.5950 - loss: 0.8282 - val_accuracy: 0.4300 - val_loss: 1.3359\n",
      "Epoch 24/1000\n",
      "\n",
      "Epoch 24: val_loss did not improve from 1.09584\n",
      "7/7 - 0s - 23ms/step - accuracy: 0.6150 - loss: 0.8215 - val_accuracy: 0.4150 - val_loss: 1.3370\n",
      "Epoch 25/1000\n",
      "\n",
      "Epoch 25: val_loss did not improve from 1.09584\n",
      "7/7 - 0s - 22ms/step - accuracy: 0.6087 - loss: 0.8205 - val_accuracy: 0.4050 - val_loss: 1.3620\n",
      "Epoch 26/1000\n",
      "\n",
      "Epoch 26: val_loss did not improve from 1.09584\n",
      "7/7 - 0s - 19ms/step - accuracy: 0.6050 - loss: 0.8141 - val_accuracy: 0.4150 - val_loss: 1.3865\n",
      "Epoch 27/1000\n",
      "\n",
      "Epoch 27: val_loss did not improve from 1.09584\n",
      "7/7 - 0s - 18ms/step - accuracy: 0.6187 - loss: 0.8066 - val_accuracy: 0.4150 - val_loss: 1.4291\n",
      "Epoch 28/1000\n",
      "\n",
      "Epoch 28: val_loss did not improve from 1.09584\n",
      "7/7 - 0s - 18ms/step - accuracy: 0.6363 - loss: 0.7867 - val_accuracy: 0.4300 - val_loss: 1.4230\n",
      "Epoch 29/1000\n",
      "\n",
      "Epoch 29: val_loss did not improve from 1.09584\n",
      "7/7 - 0s - 21ms/step - accuracy: 0.6225 - loss: 0.7823 - val_accuracy: 0.4300 - val_loss: 1.4226\n",
      "Epoch 30/1000\n",
      "\n",
      "Epoch 30: val_loss did not improve from 1.09584\n",
      "7/7 - 0s - 25ms/step - accuracy: 0.6513 - loss: 0.7671 - val_accuracy: 0.4250 - val_loss: 1.4704\n",
      "Epoch 31/1000\n",
      "\n",
      "Epoch 31: val_loss did not improve from 1.09584\n",
      "7/7 - 0s - 25ms/step - accuracy: 0.6463 - loss: 0.7337 - val_accuracy: 0.3750 - val_loss: 1.4833\n",
      "Epoch 32/1000\n",
      "\n",
      "Epoch 32: val_loss did not improve from 1.09584\n",
      "7/7 - 0s - 21ms/step - accuracy: 0.6700 - loss: 0.7379 - val_accuracy: 0.4100 - val_loss: 1.5180\n",
      "Epoch 33/1000\n",
      "\n",
      "Epoch 33: val_loss did not improve from 1.09584\n",
      "7/7 - 0s - 19ms/step - accuracy: 0.6625 - loss: 0.7331 - val_accuracy: 0.4400 - val_loss: 1.5238\n",
      "Epoch 34/1000\n",
      "\n",
      "Epoch 34: val_loss did not improve from 1.09584\n",
      "7/7 - 0s - 19ms/step - accuracy: 0.6837 - loss: 0.7251 - val_accuracy: 0.4300 - val_loss: 1.5404\n",
      "Epoch 35/1000\n",
      "\n",
      "Epoch 35: val_loss did not improve from 1.09584\n",
      "7/7 - 0s - 19ms/step - accuracy: 0.6900 - loss: 0.6785 - val_accuracy: 0.4200 - val_loss: 1.5687\n",
      "Epoch 36/1000\n",
      "\n",
      "Epoch 36: val_loss did not improve from 1.09584\n",
      "7/7 - 0s - 18ms/step - accuracy: 0.6888 - loss: 0.6815 - val_accuracy: 0.4000 - val_loss: 1.5764\n",
      "Epoch 37/1000\n",
      "\n",
      "Epoch 37: val_loss did not improve from 1.09584\n",
      "7/7 - 0s - 18ms/step - accuracy: 0.7100 - loss: 0.6648 - val_accuracy: 0.4050 - val_loss: 1.5946\n",
      "Epoch 38/1000\n",
      "\n",
      "Epoch 38: val_loss did not improve from 1.09584\n",
      "7/7 - 0s - 18ms/step - accuracy: 0.7088 - loss: 0.6651 - val_accuracy: 0.4000 - val_loss: 1.6443\n",
      "Epoch 39/1000\n",
      "\n",
      "Epoch 39: val_loss did not improve from 1.09584\n",
      "7/7 - 0s - 18ms/step - accuracy: 0.7412 - loss: 0.6290 - val_accuracy: 0.4050 - val_loss: 1.6884\n",
      "Epoch 40/1000\n",
      "\n",
      "Epoch 40: val_loss did not improve from 1.09584\n",
      "7/7 - 0s - 18ms/step - accuracy: 0.7212 - loss: 0.6371 - val_accuracy: 0.4250 - val_loss: 1.6979\n",
      "Epoch 41/1000\n",
      "\n",
      "Epoch 41: val_loss did not improve from 1.09584\n",
      "7/7 - 0s - 21ms/step - accuracy: 0.7275 - loss: 0.6092 - val_accuracy: 0.4000 - val_loss: 1.7047\n",
      "Epoch 42/1000\n",
      "\n",
      "Epoch 42: val_loss did not improve from 1.09584\n",
      "7/7 - 0s - 20ms/step - accuracy: 0.7450 - loss: 0.5961 - val_accuracy: 0.3800 - val_loss: 1.7589\n",
      "Epoch 43/1000\n",
      "\n",
      "Epoch 43: val_loss did not improve from 1.09584\n",
      "7/7 - 0s - 18ms/step - accuracy: 0.7538 - loss: 0.5882 - val_accuracy: 0.4050 - val_loss: 1.7637\n",
      "Epoch 44/1000\n",
      "\n",
      "Epoch 44: val_loss did not improve from 1.09584\n",
      "7/7 - 0s - 18ms/step - accuracy: 0.7375 - loss: 0.5993 - val_accuracy: 0.4300 - val_loss: 1.7954\n",
      "Epoch 45/1000\n",
      "\n",
      "Epoch 45: val_loss did not improve from 1.09584\n",
      "7/7 - 0s - 21ms/step - accuracy: 0.7763 - loss: 0.5290 - val_accuracy: 0.3800 - val_loss: 1.8361\n",
      "Epoch 46/1000\n",
      "\n",
      "Epoch 46: val_loss did not improve from 1.09584\n",
      "7/7 - 0s - 19ms/step - accuracy: 0.7763 - loss: 0.5503 - val_accuracy: 0.3900 - val_loss: 1.8964\n",
      "Epoch 47/1000\n",
      "\n",
      "Epoch 47: val_loss did not improve from 1.09584\n",
      "7/7 - 0s - 19ms/step - accuracy: 0.7663 - loss: 0.5359 - val_accuracy: 0.3950 - val_loss: 1.9655\n",
      "Epoch 48/1000\n",
      "\n",
      "Epoch 48: val_loss did not improve from 1.09584\n",
      "7/7 - 0s - 18ms/step - accuracy: 0.7738 - loss: 0.5298 - val_accuracy: 0.3900 - val_loss: 1.9920\n",
      "Epoch 49/1000\n",
      "\n",
      "Epoch 49: val_loss did not improve from 1.09584\n",
      "7/7 - 0s - 18ms/step - accuracy: 0.7862 - loss: 0.5183 - val_accuracy: 0.3800 - val_loss: 1.9837\n",
      "Epoch 50/1000\n",
      "\n",
      "Epoch 50: val_loss did not improve from 1.09584\n",
      "7/7 - 0s - 19ms/step - accuracy: 0.8100 - loss: 0.4809 - val_accuracy: 0.3700 - val_loss: 1.9976\n",
      "Epoch 51/1000\n",
      "\n",
      "Epoch 51: val_loss did not improve from 1.09584\n",
      "7/7 - 0s - 19ms/step - accuracy: 0.8238 - loss: 0.4698 - val_accuracy: 0.3950 - val_loss: 2.0551\n",
      "Epoch 52/1000\n",
      "\n",
      "Epoch 52: val_loss did not improve from 1.09584\n",
      "7/7 - 0s - 18ms/step - accuracy: 0.8100 - loss: 0.4950 - val_accuracy: 0.3750 - val_loss: 2.0611\n",
      "Epoch 53/1000\n",
      "\n",
      "Epoch 53: val_loss did not improve from 1.09584\n",
      "7/7 - 0s - 21ms/step - accuracy: 0.8325 - loss: 0.4526 - val_accuracy: 0.3600 - val_loss: 2.1476\n",
      "Epoch 54/1000\n",
      "\n",
      "Epoch 54: val_loss did not improve from 1.09584\n",
      "7/7 - 0s - 18ms/step - accuracy: 0.8213 - loss: 0.4459 - val_accuracy: 0.3650 - val_loss: 2.2476\n",
      "Epoch 55/1000\n",
      "\n",
      "Epoch 55: val_loss did not improve from 1.09584\n",
      "7/7 - 0s - 18ms/step - accuracy: 0.8512 - loss: 0.3995 - val_accuracy: 0.3650 - val_loss: 2.2278\n",
      "Epoch 56/1000\n",
      "\n",
      "Epoch 56: val_loss did not improve from 1.09584\n",
      "7/7 - 0s - 19ms/step - accuracy: 0.8537 - loss: 0.3873 - val_accuracy: 0.3800 - val_loss: 2.2658\n",
      "Epoch 57/1000\n",
      "\n",
      "Epoch 57: val_loss did not improve from 1.09584\n",
      "7/7 - 0s - 20ms/step - accuracy: 0.8350 - loss: 0.4242 - val_accuracy: 0.3800 - val_loss: 2.3018\n",
      "Epoch 58/1000\n",
      "\n",
      "Epoch 58: val_loss did not improve from 1.09584\n",
      "7/7 - 0s - 20ms/step - accuracy: 0.8450 - loss: 0.4146 - val_accuracy: 0.4000 - val_loss: 2.3359\n",
      "Epoch 59/1000\n",
      "\n",
      "Epoch 59: val_loss did not improve from 1.09584\n",
      "7/7 - 0s - 20ms/step - accuracy: 0.8500 - loss: 0.4058 - val_accuracy: 0.3800 - val_loss: 2.3057\n",
      "Epoch 60/1000\n",
      "\n",
      "Epoch 60: val_loss did not improve from 1.09584\n",
      "7/7 - 0s - 24ms/step - accuracy: 0.8525 - loss: 0.3857 - val_accuracy: 0.4050 - val_loss: 2.2728\n",
      "Epoch 61/1000\n",
      "\n",
      "Epoch 61: val_loss did not improve from 1.09584\n",
      "7/7 - 0s - 23ms/step - accuracy: 0.8725 - loss: 0.3636 - val_accuracy: 0.3850 - val_loss: 2.3806\n",
      "Epoch 62/1000\n",
      "\n",
      "Epoch 62: val_loss did not improve from 1.09584\n",
      "7/7 - 0s - 24ms/step - accuracy: 0.8562 - loss: 0.3565 - val_accuracy: 0.3800 - val_loss: 2.4360\n",
      "Epoch 63/1000\n",
      "\n",
      "Epoch 63: val_loss did not improve from 1.09584\n",
      "7/7 - 0s - 25ms/step - accuracy: 0.8900 - loss: 0.3183 - val_accuracy: 0.3700 - val_loss: 2.4753\n",
      "Epoch 64/1000\n",
      "\n",
      "Epoch 64: val_loss did not improve from 1.09584\n",
      "7/7 - 0s - 25ms/step - accuracy: 0.8900 - loss: 0.3176 - val_accuracy: 0.3850 - val_loss: 2.5040\n",
      "Epoch 65/1000\n",
      "\n",
      "Epoch 65: val_loss did not improve from 1.09584\n",
      "7/7 - 0s - 21ms/step - accuracy: 0.8850 - loss: 0.3135 - val_accuracy: 0.4200 - val_loss: 2.5547\n",
      "Epoch 66/1000\n",
      "\n",
      "Epoch 66: val_loss did not improve from 1.09584\n",
      "7/7 - 0s - 21ms/step - accuracy: 0.9025 - loss: 0.2951 - val_accuracy: 0.4000 - val_loss: 2.5820\n",
      "Epoch 67/1000\n",
      "\n",
      "Epoch 67: val_loss did not improve from 1.09584\n",
      "7/7 - 0s - 20ms/step - accuracy: 0.9100 - loss: 0.2746 - val_accuracy: 0.4000 - val_loss: 2.6985\n",
      "Epoch 68/1000\n",
      "\n",
      "Epoch 68: val_loss did not improve from 1.09584\n",
      "7/7 - 0s - 23ms/step - accuracy: 0.9050 - loss: 0.2991 - val_accuracy: 0.3750 - val_loss: 2.6416\n",
      "Epoch 69/1000\n",
      "\n",
      "Epoch 69: val_loss did not improve from 1.09584\n",
      "7/7 - 0s - 19ms/step - accuracy: 0.9075 - loss: 0.2737 - val_accuracy: 0.3900 - val_loss: 2.6367\n",
      "Epoch 70/1000\n",
      "\n",
      "Epoch 70: val_loss did not improve from 1.09584\n",
      "7/7 - 0s - 19ms/step - accuracy: 0.9262 - loss: 0.2532 - val_accuracy: 0.3900 - val_loss: 2.7693\n",
      "Epoch 71/1000\n",
      "\n",
      "Epoch 71: val_loss did not improve from 1.09584\n",
      "7/7 - 0s - 20ms/step - accuracy: 0.9175 - loss: 0.2561 - val_accuracy: 0.4100 - val_loss: 2.7381\n",
      "Epoch 72/1000\n",
      "\n",
      "Epoch 72: val_loss did not improve from 1.09584\n",
      "7/7 - 0s - 19ms/step - accuracy: 0.9075 - loss: 0.2758 - val_accuracy: 0.4050 - val_loss: 2.7535\n",
      "Epoch 73/1000\n",
      "\n",
      "Epoch 73: val_loss did not improve from 1.09584\n",
      "7/7 - 0s - 18ms/step - accuracy: 0.9038 - loss: 0.2738 - val_accuracy: 0.3800 - val_loss: 2.8537\n",
      "Epoch 74/1000\n",
      "\n",
      "Epoch 74: val_loss did not improve from 1.09584\n",
      "7/7 - 0s - 19ms/step - accuracy: 0.9187 - loss: 0.2603 - val_accuracy: 0.3950 - val_loss: 2.8879\n",
      "Epoch 75/1000\n",
      "\n",
      "Epoch 75: val_loss did not improve from 1.09584\n",
      "7/7 - 0s - 19ms/step - accuracy: 0.8988 - loss: 0.2722 - val_accuracy: 0.3800 - val_loss: 2.8416\n",
      "Epoch 76/1000\n",
      "\n",
      "Epoch 76: val_loss did not improve from 1.09584\n",
      "7/7 - 0s - 20ms/step - accuracy: 0.9212 - loss: 0.2308 - val_accuracy: 0.3850 - val_loss: 2.8833\n",
      "Epoch 77/1000\n",
      "\n",
      "Epoch 77: val_loss did not improve from 1.09584\n",
      "7/7 - 0s - 24ms/step - accuracy: 0.9262 - loss: 0.2336 - val_accuracy: 0.4100 - val_loss: 2.8195\n",
      "Epoch 78/1000\n",
      "\n",
      "Epoch 78: val_loss did not improve from 1.09584\n",
      "7/7 - 0s - 21ms/step - accuracy: 0.9388 - loss: 0.2161 - val_accuracy: 0.4000 - val_loss: 2.9376\n",
      "Epoch 79/1000\n",
      "\n",
      "Epoch 79: val_loss did not improve from 1.09584\n",
      "7/7 - 0s - 23ms/step - accuracy: 0.9300 - loss: 0.2281 - val_accuracy: 0.4000 - val_loss: 2.9660\n",
      "Epoch 80/1000\n",
      "\n",
      "Epoch 80: val_loss did not improve from 1.09584\n",
      "7/7 - 0s - 21ms/step - accuracy: 0.9450 - loss: 0.2141 - val_accuracy: 0.4000 - val_loss: 3.0831\n",
      "Epoch 81/1000\n",
      "\n",
      "Epoch 81: val_loss did not improve from 1.09584\n",
      "7/7 - 0s - 20ms/step - accuracy: 0.9500 - loss: 0.1794 - val_accuracy: 0.3900 - val_loss: 3.1429\n",
      "Epoch 82/1000\n",
      "\n",
      "Epoch 82: val_loss did not improve from 1.09584\n",
      "7/7 - 0s - 22ms/step - accuracy: 0.9375 - loss: 0.1817 - val_accuracy: 0.3900 - val_loss: 3.1829\n",
      "Epoch 83/1000\n",
      "\n",
      "Epoch 83: val_loss did not improve from 1.09584\n",
      "7/7 - 0s - 21ms/step - accuracy: 0.9475 - loss: 0.1749 - val_accuracy: 0.3950 - val_loss: 3.2120\n",
      "Epoch 84/1000\n",
      "\n",
      "Epoch 84: val_loss did not improve from 1.09584\n",
      "7/7 - 0s - 22ms/step - accuracy: 0.9513 - loss: 0.1587 - val_accuracy: 0.4050 - val_loss: 3.1964\n",
      "Epoch 85/1000\n",
      "\n",
      "Epoch 85: val_loss did not improve from 1.09584\n",
      "7/7 - 0s - 26ms/step - accuracy: 0.9500 - loss: 0.1631 - val_accuracy: 0.3750 - val_loss: 3.2422\n",
      "Epoch 86/1000\n",
      "\n",
      "Epoch 86: val_loss did not improve from 1.09584\n",
      "7/7 - 0s - 25ms/step - accuracy: 0.9525 - loss: 0.1658 - val_accuracy: 0.3900 - val_loss: 3.2805\n",
      "Epoch 87/1000\n",
      "\n",
      "Epoch 87: val_loss did not improve from 1.09584\n",
      "7/7 - 0s - 24ms/step - accuracy: 0.9525 - loss: 0.1521 - val_accuracy: 0.3700 - val_loss: 3.3616\n",
      "Epoch 88/1000\n",
      "\n",
      "Epoch 88: val_loss did not improve from 1.09584\n",
      "7/7 - 0s - 25ms/step - accuracy: 0.9625 - loss: 0.1387 - val_accuracy: 0.3950 - val_loss: 3.3931\n",
      "Epoch 89/1000\n",
      "\n",
      "Epoch 89: val_loss did not improve from 1.09584\n",
      "7/7 - 0s - 20ms/step - accuracy: 0.9450 - loss: 0.1506 - val_accuracy: 0.3900 - val_loss: 3.4844\n",
      "Epoch 90/1000\n",
      "\n",
      "Epoch 90: val_loss did not improve from 1.09584\n",
      "7/7 - 0s - 19ms/step - accuracy: 0.9550 - loss: 0.1549 - val_accuracy: 0.3850 - val_loss: 3.4242\n",
      "Epoch 91/1000\n",
      "\n",
      "Epoch 91: val_loss did not improve from 1.09584\n",
      "7/7 - 0s - 21ms/step - accuracy: 0.9688 - loss: 0.1223 - val_accuracy: 0.3900 - val_loss: 3.5207\n",
      "Epoch 92/1000\n",
      "\n",
      "Epoch 92: val_loss did not improve from 1.09584\n",
      "7/7 - 0s - 19ms/step - accuracy: 0.9675 - loss: 0.1172 - val_accuracy: 0.3900 - val_loss: 3.5153\n",
      "Epoch 93/1000\n",
      "\n",
      "Epoch 93: val_loss did not improve from 1.09584\n",
      "7/7 - 0s - 19ms/step - accuracy: 0.9575 - loss: 0.1334 - val_accuracy: 0.3800 - val_loss: 3.4420\n",
      "Epoch 94/1000\n",
      "\n",
      "Epoch 94: val_loss did not improve from 1.09584\n",
      "7/7 - 0s - 18ms/step - accuracy: 0.9675 - loss: 0.1334 - val_accuracy: 0.3900 - val_loss: 3.4225\n",
      "Epoch 95/1000\n",
      "\n",
      "Epoch 95: val_loss did not improve from 1.09584\n",
      "7/7 - 0s - 18ms/step - accuracy: 0.9750 - loss: 0.1008 - val_accuracy: 0.3800 - val_loss: 3.5078\n",
      "Epoch 96/1000\n",
      "\n",
      "Epoch 96: val_loss did not improve from 1.09584\n",
      "7/7 - 0s - 17ms/step - accuracy: 0.9675 - loss: 0.1325 - val_accuracy: 0.4050 - val_loss: 3.5190\n",
      "Epoch 97/1000\n",
      "\n",
      "Epoch 97: val_loss did not improve from 1.09584\n",
      "7/7 - 0s - 17ms/step - accuracy: 0.9600 - loss: 0.1359 - val_accuracy: 0.3950 - val_loss: 3.5937\n",
      "Epoch 98/1000\n",
      "\n",
      "Epoch 98: val_loss did not improve from 1.09584\n",
      "7/7 - 0s - 18ms/step - accuracy: 0.9787 - loss: 0.1001 - val_accuracy: 0.3900 - val_loss: 3.5638\n",
      "Epoch 99/1000\n",
      "\n",
      "Epoch 99: val_loss did not improve from 1.09584\n",
      "7/7 - 0s - 17ms/step - accuracy: 0.9725 - loss: 0.1166 - val_accuracy: 0.3950 - val_loss: 3.5894\n",
      "Epoch 100/1000\n",
      "\n",
      "Epoch 100: val_loss did not improve from 1.09584\n",
      "7/7 - 0s - 17ms/step - accuracy: 0.9762 - loss: 0.1020 - val_accuracy: 0.3850 - val_loss: 3.6699\n",
      "Epoch 101/1000\n",
      "\n",
      "Epoch 101: val_loss did not improve from 1.09584\n",
      "7/7 - 0s - 17ms/step - accuracy: 0.9625 - loss: 0.1170 - val_accuracy: 0.4050 - val_loss: 3.7146\n",
      "Epoch 102/1000\n",
      "\n",
      "Epoch 102: val_loss did not improve from 1.09584\n",
      "7/7 - 0s - 17ms/step - accuracy: 0.9775 - loss: 0.0884 - val_accuracy: 0.3800 - val_loss: 3.6698\n",
      "Epoch 103/1000\n",
      "\n",
      "Epoch 103: val_loss did not improve from 1.09584\n",
      "7/7 - 0s - 17ms/step - accuracy: 0.9787 - loss: 0.0901 - val_accuracy: 0.3950 - val_loss: 3.7947\n",
      "Epoch 103: early stopping\n",
      "Restoring model weights from the end of the best epoch: 3.\n",
      "Elpased time: 0:00:20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "Fold score (accuracy): 0.355\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn import metrics\n",
    "k_fold=StratifiedKFold(5,shuffle=False)\n",
    "\n",
    "out_of_sample_y=[]\n",
    "out_of_sample_pred=[]\n",
    "fold=0\n",
    "\n",
    "#Must specify y StratifiedKFold for classification\n",
    "for train,test in k_fold.split(x,y_raw):\n",
    "    fold+=1\n",
    "    print(f\"Fold #{fold}\")\n",
    "\n",
    "    x_train=x[train]\n",
    "    y_train=y[train]\n",
    "    x_test=x[test]\n",
    "    y_test=y[test]\n",
    "\n",
    "    import jet_ml.models.test_net as test_net\n",
    "    input_shape=x[0].shape\n",
    "    output_shape=y.shape[1]\n",
    "    activation='softmax'\n",
    "    model=test_net.build_model(input_shape,output_shape,activation)\n",
    "    model=test_net.compile_model(model)\n",
    "    model.summary()\n",
    "\n",
    "\n",
    "    batch_size=128\n",
    "    epochs=1000\n",
    "    monitor='val_loss' #'val_accuracy' or 'val_loss'\n",
    "    model, history=test_net.train_model(model,\n",
    "                                        x_train,y_train, x_test,y_test, \n",
    "                                        epochs, batch_size, monitor)\n",
    "    \n",
    "    pred = model.predict(x_test)\n",
    "\n",
    "    out_of_sample_y.append(y_test)\n",
    "    # raw probabilities to chosen class (highest probability)\n",
    "    pred = np.argmax(pred,axis=1) \n",
    "    out_of_sample_pred.append(pred)\n",
    "\n",
    "    # Measure this fold's accuracy\n",
    "    y_compare = np.argmax(y_test,axis=1) # For accuracy calculation\n",
    "    score = metrics.accuracy_score(y_compare, pred)   \n",
    "    print(f\"Fold score (accuracy): {score}\")\n",
    "\n",
    "# Build the oos prediction list and calculate the error.\n",
    "out_of_sample_y=np.concatenate(out_of_sample_y)\n",
    "out_of_sample_pred=np.concatenate(out_of_sample_pred)\n",
    "out_of_sample_y_compare=np.argmax(out_of_sample_y,axis=1)# For accuracy calculation\n",
    "\n",
    "score=metrics.accuracy_score(out_of_sample_y_compare,out_of_sample_pred)\n",
    "out_of_sample_y=pd.DataFrame(out_of_sample_y)\n",
    "out_of_sample_pred=pd.DataFrame(out_of_sample_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.374"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "display(score)\n",
    "out_of_sample_y=pd.DataFrame(out_of_sample_y)\n",
    "out_of_sample_pred=pd.DataFrame(out_of_sample_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_of_sample_DF=pd.concat([y_df,out_of_sample_y,out_of_sample_pred],axis=1)\n",
    "import jet_ml.config as config\n",
    "import os\n",
    "out_of_sample_DF.to_csv(os.path.join(config.REPORTS_DIR,\"alpha_s_test_net_5_fold_1000_epoch_1k.csv\"),index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(    \n",
    "    x, y, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/arsi/miniconda3/envs/tensorflow/lib/python3.12/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"testnet\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"testnet\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">320</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12544</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,605,760</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">387</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │           \u001b[38;5;34m320\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │        \u001b[38;5;34m18,496\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d (\u001b[38;5;33mMaxPooling2D\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12544\u001b[0m)          │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │     \u001b[38;5;34m1,605,760\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m)              │           \u001b[38;5;34m387\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,624,963</span> (6.20 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,624,963\u001b[0m (6.20 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,624,963</span> (6.20 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,624,963\u001b[0m (6.20 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import jet_ml.models.test_net as test_net\n",
    "input_shape=x[0].shape\n",
    "activation='softmax'\n",
    "model=test_net.build_model(input_shape,3,activation)\n",
    "model=test_net.compile_model(model)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "\n",
      "Epoch 1: val_loss improved from inf to 1.09768, saving model to /mnt/g/My Drive/Projects/110_JetscapeMl/hm_jetscapeml_source/models/testnet/model.keras\n",
      "6/6 - 9s - 1s/step - accuracy: 0.3347 - loss: 1.0997 - val_accuracy: 0.4200 - val_loss: 1.0977\n",
      "Epoch 2/1000\n",
      "\n",
      "Epoch 2: val_loss improved from 1.09768 to 1.09540, saving model to /mnt/g/My Drive/Projects/110_JetscapeMl/hm_jetscapeml_source/models/testnet/model.keras\n",
      "6/6 - 1s - 86ms/step - accuracy: 0.3947 - loss: 1.0934 - val_accuracy: 0.3800 - val_loss: 1.0954\n",
      "Epoch 3/1000\n",
      "\n",
      "Epoch 3: val_loss improved from 1.09540 to 1.09055, saving model to /mnt/g/My Drive/Projects/110_JetscapeMl/hm_jetscapeml_source/models/testnet/model.keras\n",
      "6/6 - 1s - 88ms/step - accuracy: 0.3947 - loss: 1.0861 - val_accuracy: 0.3600 - val_loss: 1.0905\n",
      "Epoch 4/1000\n",
      "\n",
      "Epoch 4: val_loss improved from 1.09055 to 1.08627, saving model to /mnt/g/My Drive/Projects/110_JetscapeMl/hm_jetscapeml_source/models/testnet/model.keras\n",
      "6/6 - 1s - 100ms/step - accuracy: 0.4307 - loss: 1.0751 - val_accuracy: 0.3880 - val_loss: 1.0863\n",
      "Epoch 5/1000\n",
      "\n",
      "Epoch 5: val_loss improved from 1.08627 to 1.08500, saving model to /mnt/g/My Drive/Projects/110_JetscapeMl/hm_jetscapeml_source/models/testnet/model.keras\n",
      "6/6 - 1s - 98ms/step - accuracy: 0.4480 - loss: 1.0546 - val_accuracy: 0.3360 - val_loss: 1.0850\n",
      "Epoch 6/1000\n",
      "\n",
      "Epoch 6: val_loss did not improve from 1.08500\n",
      "6/6 - 0s - 26ms/step - accuracy: 0.4333 - loss: 1.0411 - val_accuracy: 0.4000 - val_loss: 1.0908\n",
      "Epoch 7/1000\n",
      "\n",
      "Epoch 7: val_loss did not improve from 1.08500\n",
      "6/6 - 0s - 24ms/step - accuracy: 0.4707 - loss: 1.0214 - val_accuracy: 0.3760 - val_loss: 1.1004\n",
      "Epoch 8/1000\n",
      "\n",
      "Epoch 8: val_loss did not improve from 1.08500\n",
      "6/6 - 0s - 25ms/step - accuracy: 0.4853 - loss: 1.0027 - val_accuracy: 0.3640 - val_loss: 1.1192\n",
      "Epoch 9/1000\n",
      "\n",
      "Epoch 9: val_loss did not improve from 1.08500\n",
      "6/6 - 0s - 25ms/step - accuracy: 0.4880 - loss: 0.9887 - val_accuracy: 0.3520 - val_loss: 1.1259\n",
      "Epoch 10/1000\n",
      "\n",
      "Epoch 10: val_loss did not improve from 1.08500\n",
      "6/6 - 0s - 23ms/step - accuracy: 0.4960 - loss: 0.9667 - val_accuracy: 0.3840 - val_loss: 1.1362\n",
      "Epoch 11/1000\n",
      "\n",
      "Epoch 11: val_loss did not improve from 1.08500\n",
      "6/6 - 0s - 22ms/step - accuracy: 0.5160 - loss: 0.9527 - val_accuracy: 0.3800 - val_loss: 1.1552\n",
      "Epoch 12/1000\n",
      "\n",
      "Epoch 12: val_loss did not improve from 1.08500\n",
      "6/6 - 0s - 25ms/step - accuracy: 0.5133 - loss: 0.9382 - val_accuracy: 0.3600 - val_loss: 1.1626\n",
      "Epoch 13/1000\n",
      "\n",
      "Epoch 13: val_loss did not improve from 1.08500\n",
      "6/6 - 0s - 27ms/step - accuracy: 0.5387 - loss: 0.9211 - val_accuracy: 0.3840 - val_loss: 1.1926\n",
      "Epoch 14/1000\n",
      "\n",
      "Epoch 14: val_loss did not improve from 1.08500\n",
      "6/6 - 0s - 25ms/step - accuracy: 0.5173 - loss: 0.9247 - val_accuracy: 0.3520 - val_loss: 1.1978\n",
      "Epoch 15/1000\n",
      "\n",
      "Epoch 15: val_loss did not improve from 1.08500\n",
      "6/6 - 0s - 24ms/step - accuracy: 0.5440 - loss: 0.9041 - val_accuracy: 0.3920 - val_loss: 1.2032\n",
      "Epoch 16/1000\n",
      "\n",
      "Epoch 16: val_loss did not improve from 1.08500\n",
      "6/6 - 0s - 24ms/step - accuracy: 0.5493 - loss: 0.8868 - val_accuracy: 0.4000 - val_loss: 1.2337\n",
      "Epoch 17/1000\n",
      "\n",
      "Epoch 17: val_loss did not improve from 1.08500\n",
      "6/6 - 0s - 24ms/step - accuracy: 0.5493 - loss: 0.8730 - val_accuracy: 0.4120 - val_loss: 1.2524\n",
      "Epoch 18/1000\n",
      "\n",
      "Epoch 18: val_loss did not improve from 1.08500\n",
      "6/6 - 0s - 20ms/step - accuracy: 0.5853 - loss: 0.8494 - val_accuracy: 0.3760 - val_loss: 1.2856\n",
      "Epoch 19/1000\n",
      "\n",
      "Epoch 19: val_loss did not improve from 1.08500\n",
      "6/6 - 0s - 24ms/step - accuracy: 0.5773 - loss: 0.8382 - val_accuracy: 0.3520 - val_loss: 1.3160\n",
      "Epoch 20/1000\n",
      "\n",
      "Epoch 20: val_loss did not improve from 1.08500\n",
      "6/6 - 0s - 24ms/step - accuracy: 0.5853 - loss: 0.8427 - val_accuracy: 0.3680 - val_loss: 1.3149\n",
      "Epoch 21/1000\n",
      "\n",
      "Epoch 21: val_loss did not improve from 1.08500\n",
      "6/6 - 0s - 22ms/step - accuracy: 0.6093 - loss: 0.8090 - val_accuracy: 0.4000 - val_loss: 1.3606\n",
      "Epoch 22/1000\n",
      "\n",
      "Epoch 22: val_loss did not improve from 1.08500\n",
      "6/6 - 0s - 21ms/step - accuracy: 0.6120 - loss: 0.8027 - val_accuracy: 0.3600 - val_loss: 1.3518\n",
      "Epoch 23/1000\n",
      "\n",
      "Epoch 23: val_loss did not improve from 1.08500\n",
      "6/6 - 0s - 21ms/step - accuracy: 0.6253 - loss: 0.7769 - val_accuracy: 0.4000 - val_loss: 1.3735\n",
      "Epoch 24/1000\n",
      "\n",
      "Epoch 24: val_loss did not improve from 1.08500\n",
      "6/6 - 0s - 20ms/step - accuracy: 0.6453 - loss: 0.7668 - val_accuracy: 0.3600 - val_loss: 1.3936\n",
      "Epoch 25/1000\n",
      "\n",
      "Epoch 25: val_loss did not improve from 1.08500\n",
      "6/6 - 0s - 22ms/step - accuracy: 0.6373 - loss: 0.7568 - val_accuracy: 0.3800 - val_loss: 1.4144\n",
      "Epoch 26/1000\n",
      "\n",
      "Epoch 26: val_loss did not improve from 1.08500\n",
      "6/6 - 0s - 31ms/step - accuracy: 0.6707 - loss: 0.7202 - val_accuracy: 0.4000 - val_loss: 1.4538\n",
      "Epoch 27/1000\n",
      "\n",
      "Epoch 27: val_loss did not improve from 1.08500\n",
      "6/6 - 0s - 27ms/step - accuracy: 0.6760 - loss: 0.7211 - val_accuracy: 0.3680 - val_loss: 1.4942\n",
      "Epoch 28/1000\n",
      "\n",
      "Epoch 28: val_loss did not improve from 1.08500\n",
      "6/6 - 0s - 27ms/step - accuracy: 0.6547 - loss: 0.7239 - val_accuracy: 0.3800 - val_loss: 1.4943\n",
      "Epoch 29/1000\n",
      "\n",
      "Epoch 29: val_loss did not improve from 1.08500\n",
      "6/6 - 0s - 26ms/step - accuracy: 0.6853 - loss: 0.7087 - val_accuracy: 0.3840 - val_loss: 1.5536\n",
      "Epoch 30/1000\n",
      "\n",
      "Epoch 30: val_loss did not improve from 1.08500\n",
      "6/6 - 0s - 25ms/step - accuracy: 0.6853 - loss: 0.6783 - val_accuracy: 0.3840 - val_loss: 1.5276\n",
      "Epoch 31/1000\n",
      "\n",
      "Epoch 31: val_loss did not improve from 1.08500\n",
      "6/6 - 0s - 26ms/step - accuracy: 0.7067 - loss: 0.6427 - val_accuracy: 0.3960 - val_loss: 1.5965\n",
      "Epoch 32/1000\n",
      "\n",
      "Epoch 32: val_loss did not improve from 1.08500\n",
      "6/6 - 0s - 25ms/step - accuracy: 0.7280 - loss: 0.6283 - val_accuracy: 0.3840 - val_loss: 1.6239\n",
      "Epoch 33/1000\n",
      "\n",
      "Epoch 33: val_loss did not improve from 1.08500\n",
      "6/6 - 0s - 22ms/step - accuracy: 0.7253 - loss: 0.6177 - val_accuracy: 0.3960 - val_loss: 1.7055\n",
      "Epoch 34/1000\n",
      "\n",
      "Epoch 34: val_loss did not improve from 1.08500\n",
      "6/6 - 0s - 26ms/step - accuracy: 0.7440 - loss: 0.5916 - val_accuracy: 0.3840 - val_loss: 1.7124\n",
      "Epoch 35/1000\n",
      "\n",
      "Epoch 35: val_loss did not improve from 1.08500\n",
      "6/6 - 0s - 28ms/step - accuracy: 0.7413 - loss: 0.5912 - val_accuracy: 0.3760 - val_loss: 1.7392\n",
      "Epoch 36/1000\n",
      "\n",
      "Epoch 36: val_loss did not improve from 1.08500\n",
      "6/6 - 0s - 31ms/step - accuracy: 0.7413 - loss: 0.5704 - val_accuracy: 0.3800 - val_loss: 1.7518\n",
      "Epoch 37/1000\n",
      "\n",
      "Epoch 37: val_loss did not improve from 1.08500\n",
      "6/6 - 0s - 28ms/step - accuracy: 0.7733 - loss: 0.5615 - val_accuracy: 0.3840 - val_loss: 1.8144\n",
      "Epoch 38/1000\n",
      "\n",
      "Epoch 38: val_loss did not improve from 1.08500\n",
      "6/6 - 0s - 25ms/step - accuracy: 0.7627 - loss: 0.5636 - val_accuracy: 0.3960 - val_loss: 1.8126\n",
      "Epoch 39/1000\n",
      "\n",
      "Epoch 39: val_loss did not improve from 1.08500\n",
      "6/6 - 0s - 24ms/step - accuracy: 0.7733 - loss: 0.5508 - val_accuracy: 0.3720 - val_loss: 1.8215\n",
      "Epoch 40/1000\n",
      "\n",
      "Epoch 40: val_loss did not improve from 1.08500\n",
      "6/6 - 0s - 24ms/step - accuracy: 0.7760 - loss: 0.5202 - val_accuracy: 0.3760 - val_loss: 1.8855\n",
      "Epoch 41/1000\n",
      "\n",
      "Epoch 41: val_loss did not improve from 1.08500\n",
      "6/6 - 0s - 22ms/step - accuracy: 0.8160 - loss: 0.4915 - val_accuracy: 0.3840 - val_loss: 1.8907\n",
      "Epoch 42/1000\n",
      "\n",
      "Epoch 42: val_loss did not improve from 1.08500\n",
      "6/6 - 0s - 22ms/step - accuracy: 0.8013 - loss: 0.5040 - val_accuracy: 0.3720 - val_loss: 1.9222\n",
      "Epoch 43/1000\n",
      "\n",
      "Epoch 43: val_loss did not improve from 1.08500\n",
      "6/6 - 0s - 22ms/step - accuracy: 0.8160 - loss: 0.4699 - val_accuracy: 0.3960 - val_loss: 2.0388\n",
      "Epoch 44/1000\n",
      "\n",
      "Epoch 44: val_loss did not improve from 1.08500\n",
      "6/6 - 0s - 23ms/step - accuracy: 0.8440 - loss: 0.4221 - val_accuracy: 0.3800 - val_loss: 2.0422\n",
      "Epoch 45/1000\n",
      "\n",
      "Epoch 45: val_loss did not improve from 1.08500\n",
      "6/6 - 0s - 23ms/step - accuracy: 0.8600 - loss: 0.4262 - val_accuracy: 0.3880 - val_loss: 2.1594\n",
      "Epoch 46/1000\n",
      "\n",
      "Epoch 46: val_loss did not improve from 1.08500\n",
      "6/6 - 0s - 22ms/step - accuracy: 0.8387 - loss: 0.4313 - val_accuracy: 0.3720 - val_loss: 2.1409\n",
      "Epoch 47/1000\n",
      "\n",
      "Epoch 47: val_loss did not improve from 1.08500\n",
      "6/6 - 0s - 23ms/step - accuracy: 0.8480 - loss: 0.4083 - val_accuracy: 0.3720 - val_loss: 2.1451\n",
      "Epoch 48/1000\n",
      "\n",
      "Epoch 48: val_loss did not improve from 1.08500\n",
      "6/6 - 0s - 24ms/step - accuracy: 0.8533 - loss: 0.3875 - val_accuracy: 0.3640 - val_loss: 2.1345\n",
      "Epoch 49/1000\n",
      "\n",
      "Epoch 49: val_loss did not improve from 1.08500\n",
      "6/6 - 0s - 27ms/step - accuracy: 0.8480 - loss: 0.3891 - val_accuracy: 0.3960 - val_loss: 2.1893\n",
      "Epoch 50/1000\n",
      "\n",
      "Epoch 50: val_loss did not improve from 1.08500\n",
      "6/6 - 0s - 28ms/step - accuracy: 0.8573 - loss: 0.3966 - val_accuracy: 0.3840 - val_loss: 2.2728\n",
      "Epoch 51/1000\n",
      "\n",
      "Epoch 51: val_loss did not improve from 1.08500\n",
      "6/6 - 0s - 28ms/step - accuracy: 0.8547 - loss: 0.3709 - val_accuracy: 0.3760 - val_loss: 2.2941\n",
      "Epoch 52/1000\n",
      "\n",
      "Epoch 52: val_loss did not improve from 1.08500\n",
      "6/6 - 0s - 25ms/step - accuracy: 0.8640 - loss: 0.3740 - val_accuracy: 0.3640 - val_loss: 2.3625\n",
      "Epoch 53/1000\n",
      "\n",
      "Epoch 53: val_loss did not improve from 1.08500\n",
      "6/6 - 0s - 24ms/step - accuracy: 0.8773 - loss: 0.3235 - val_accuracy: 0.4080 - val_loss: 2.3570\n",
      "Epoch 54/1000\n",
      "\n",
      "Epoch 54: val_loss did not improve from 1.08500\n",
      "6/6 - 0s - 25ms/step - accuracy: 0.8760 - loss: 0.3267 - val_accuracy: 0.3760 - val_loss: 2.4309\n",
      "Epoch 55/1000\n",
      "\n",
      "Epoch 55: val_loss did not improve from 1.08500\n",
      "6/6 - 0s - 26ms/step - accuracy: 0.8827 - loss: 0.3356 - val_accuracy: 0.3720 - val_loss: 2.4910\n",
      "Epoch 56/1000\n",
      "\n",
      "Epoch 56: val_loss did not improve from 1.08500\n",
      "6/6 - 0s - 28ms/step - accuracy: 0.9053 - loss: 0.3212 - val_accuracy: 0.3840 - val_loss: 2.5837\n",
      "Epoch 57/1000\n",
      "\n",
      "Epoch 57: val_loss did not improve from 1.08500\n",
      "6/6 - 0s - 25ms/step - accuracy: 0.9067 - loss: 0.2739 - val_accuracy: 0.3920 - val_loss: 2.6854\n",
      "Epoch 58/1000\n",
      "\n",
      "Epoch 58: val_loss did not improve from 1.08500\n",
      "6/6 - 0s - 26ms/step - accuracy: 0.9067 - loss: 0.2705 - val_accuracy: 0.3680 - val_loss: 2.6720\n",
      "Epoch 59/1000\n",
      "\n",
      "Epoch 59: val_loss did not improve from 1.08500\n",
      "6/6 - 0s - 26ms/step - accuracy: 0.9000 - loss: 0.2752 - val_accuracy: 0.3760 - val_loss: 2.7700\n",
      "Epoch 60/1000\n",
      "\n",
      "Epoch 60: val_loss did not improve from 1.08500\n",
      "6/6 - 0s - 25ms/step - accuracy: 0.9067 - loss: 0.2616 - val_accuracy: 0.3920 - val_loss: 2.7882\n",
      "Epoch 61/1000\n",
      "\n",
      "Epoch 61: val_loss did not improve from 1.08500\n",
      "6/6 - 0s - 27ms/step - accuracy: 0.9267 - loss: 0.2380 - val_accuracy: 0.3920 - val_loss: 2.8754\n",
      "Epoch 62/1000\n",
      "\n",
      "Epoch 62: val_loss did not improve from 1.08500\n",
      "6/6 - 0s - 30ms/step - accuracy: 0.9240 - loss: 0.2531 - val_accuracy: 0.3760 - val_loss: 2.9961\n",
      "Epoch 63/1000\n",
      "\n",
      "Epoch 63: val_loss did not improve from 1.08500\n",
      "6/6 - 0s - 31ms/step - accuracy: 0.9227 - loss: 0.2362 - val_accuracy: 0.3640 - val_loss: 3.0131\n",
      "Epoch 64/1000\n",
      "\n",
      "Epoch 64: val_loss did not improve from 1.08500\n",
      "6/6 - 0s - 28ms/step - accuracy: 0.9093 - loss: 0.2381 - val_accuracy: 0.3720 - val_loss: 3.0498\n",
      "Epoch 65/1000\n",
      "\n",
      "Epoch 65: val_loss did not improve from 1.08500\n",
      "6/6 - 0s - 32ms/step - accuracy: 0.9413 - loss: 0.2207 - val_accuracy: 0.3880 - val_loss: 3.1194\n",
      "Epoch 66/1000\n",
      "\n",
      "Epoch 66: val_loss did not improve from 1.08500\n",
      "6/6 - 0s - 32ms/step - accuracy: 0.9240 - loss: 0.2303 - val_accuracy: 0.3800 - val_loss: 3.1312\n",
      "Epoch 67/1000\n",
      "\n",
      "Epoch 67: val_loss did not improve from 1.08500\n",
      "6/6 - 0s - 27ms/step - accuracy: 0.9267 - loss: 0.2311 - val_accuracy: 0.3680 - val_loss: 3.1986\n",
      "Epoch 68/1000\n",
      "\n",
      "Epoch 68: val_loss did not improve from 1.08500\n",
      "6/6 - 0s - 26ms/step - accuracy: 0.9387 - loss: 0.1845 - val_accuracy: 0.3640 - val_loss: 3.1581\n",
      "Epoch 69/1000\n",
      "\n",
      "Epoch 69: val_loss did not improve from 1.08500\n",
      "6/6 - 0s - 26ms/step - accuracy: 0.9320 - loss: 0.2051 - val_accuracy: 0.3760 - val_loss: 3.2011\n",
      "Epoch 70/1000\n",
      "\n",
      "Epoch 70: val_loss did not improve from 1.08500\n",
      "6/6 - 0s - 24ms/step - accuracy: 0.9560 - loss: 0.1784 - val_accuracy: 0.3840 - val_loss: 3.2856\n",
      "Epoch 71/1000\n",
      "\n",
      "Epoch 71: val_loss did not improve from 1.08500\n",
      "6/6 - 0s - 24ms/step - accuracy: 0.9480 - loss: 0.1939 - val_accuracy: 0.3680 - val_loss: 3.3028\n",
      "Epoch 72/1000\n",
      "\n",
      "Epoch 72: val_loss did not improve from 1.08500\n",
      "6/6 - 0s - 28ms/step - accuracy: 0.9493 - loss: 0.1705 - val_accuracy: 0.3720 - val_loss: 3.4090\n",
      "Epoch 73/1000\n",
      "\n",
      "Epoch 73: val_loss did not improve from 1.08500\n",
      "6/6 - 0s - 27ms/step - accuracy: 0.9533 - loss: 0.1504 - val_accuracy: 0.3720 - val_loss: 3.3295\n",
      "Epoch 74/1000\n",
      "\n",
      "Epoch 74: val_loss did not improve from 1.08500\n",
      "6/6 - 0s - 27ms/step - accuracy: 0.9493 - loss: 0.1539 - val_accuracy: 0.3720 - val_loss: 3.4423\n",
      "Epoch 75/1000\n",
      "\n",
      "Epoch 75: val_loss did not improve from 1.08500\n",
      "6/6 - 0s - 25ms/step - accuracy: 0.9573 - loss: 0.1462 - val_accuracy: 0.3680 - val_loss: 3.5293\n",
      "Epoch 76/1000\n",
      "\n",
      "Epoch 76: val_loss did not improve from 1.08500\n",
      "6/6 - 0s - 27ms/step - accuracy: 0.9560 - loss: 0.1338 - val_accuracy: 0.3840 - val_loss: 3.5506\n",
      "Epoch 77/1000\n",
      "\n",
      "Epoch 77: val_loss did not improve from 1.08500\n",
      "6/6 - 0s - 25ms/step - accuracy: 0.9507 - loss: 0.1522 - val_accuracy: 0.3560 - val_loss: 3.6181\n",
      "Epoch 78/1000\n",
      "\n",
      "Epoch 78: val_loss did not improve from 1.08500\n",
      "6/6 - 0s - 26ms/step - accuracy: 0.9600 - loss: 0.1524 - val_accuracy: 0.3600 - val_loss: 3.5934\n",
      "Epoch 79/1000\n",
      "\n",
      "Epoch 79: val_loss did not improve from 1.08500\n",
      "6/6 - 0s - 26ms/step - accuracy: 0.9600 - loss: 0.1455 - val_accuracy: 0.3560 - val_loss: 3.6327\n",
      "Epoch 80/1000\n",
      "\n",
      "Epoch 80: val_loss did not improve from 1.08500\n",
      "6/6 - 0s - 25ms/step - accuracy: 0.9627 - loss: 0.1423 - val_accuracy: 0.3600 - val_loss: 3.6928\n",
      "Epoch 81/1000\n",
      "\n",
      "Epoch 81: val_loss did not improve from 1.08500\n",
      "6/6 - 0s - 25ms/step - accuracy: 0.9667 - loss: 0.1197 - val_accuracy: 0.3880 - val_loss: 3.7215\n",
      "Epoch 82/1000\n",
      "\n",
      "Epoch 82: val_loss did not improve from 1.08500\n",
      "6/6 - 0s - 28ms/step - accuracy: 0.9560 - loss: 0.1447 - val_accuracy: 0.3800 - val_loss: 3.7426\n",
      "Epoch 83/1000\n",
      "\n",
      "Epoch 83: val_loss did not improve from 1.08500\n",
      "6/6 - 0s - 27ms/step - accuracy: 0.9747 - loss: 0.1204 - val_accuracy: 0.3720 - val_loss: 3.7915\n",
      "Epoch 84/1000\n",
      "\n",
      "Epoch 84: val_loss did not improve from 1.08500\n",
      "6/6 - 0s - 27ms/step - accuracy: 0.9640 - loss: 0.1191 - val_accuracy: 0.3720 - val_loss: 3.8139\n",
      "Epoch 85/1000\n",
      "\n",
      "Epoch 85: val_loss did not improve from 1.08500\n",
      "6/6 - 0s - 28ms/step - accuracy: 0.9747 - loss: 0.1053 - val_accuracy: 0.3520 - val_loss: 3.8959\n",
      "Epoch 86/1000\n",
      "\n",
      "Epoch 86: val_loss did not improve from 1.08500\n",
      "6/6 - 0s - 25ms/step - accuracy: 0.9707 - loss: 0.1108 - val_accuracy: 0.3520 - val_loss: 3.9308\n",
      "Epoch 87/1000\n",
      "\n",
      "Epoch 87: val_loss did not improve from 1.08500\n",
      "6/6 - 0s - 26ms/step - accuracy: 0.9773 - loss: 0.0997 - val_accuracy: 0.3800 - val_loss: 3.9522\n",
      "Epoch 88/1000\n",
      "\n",
      "Epoch 88: val_loss did not improve from 1.08500\n",
      "6/6 - 0s - 25ms/step - accuracy: 0.9613 - loss: 0.1219 - val_accuracy: 0.3560 - val_loss: 3.9038\n",
      "Epoch 89/1000\n",
      "\n",
      "Epoch 89: val_loss did not improve from 1.08500\n",
      "6/6 - 0s - 26ms/step - accuracy: 0.9693 - loss: 0.1009 - val_accuracy: 0.3680 - val_loss: 4.0671\n",
      "Epoch 90/1000\n",
      "\n",
      "Epoch 90: val_loss did not improve from 1.08500\n",
      "6/6 - 0s - 25ms/step - accuracy: 0.9760 - loss: 0.0988 - val_accuracy: 0.3520 - val_loss: 4.0124\n",
      "Epoch 91/1000\n",
      "\n",
      "Epoch 91: val_loss did not improve from 1.08500\n",
      "6/6 - 0s - 25ms/step - accuracy: 0.9653 - loss: 0.1197 - val_accuracy: 0.3600 - val_loss: 4.1090\n",
      "Epoch 92/1000\n",
      "\n",
      "Epoch 92: val_loss did not improve from 1.08500\n",
      "6/6 - 0s - 25ms/step - accuracy: 0.9773 - loss: 0.0849 - val_accuracy: 0.3680 - val_loss: 4.1007\n",
      "Epoch 93/1000\n",
      "\n",
      "Epoch 93: val_loss did not improve from 1.08500\n",
      "6/6 - 0s - 27ms/step - accuracy: 0.9773 - loss: 0.0844 - val_accuracy: 0.3640 - val_loss: 4.1375\n",
      "Epoch 94/1000\n",
      "\n",
      "Epoch 94: val_loss did not improve from 1.08500\n",
      "6/6 - 0s - 28ms/step - accuracy: 0.9787 - loss: 0.0825 - val_accuracy: 0.3520 - val_loss: 4.2300\n",
      "Epoch 95/1000\n",
      "\n",
      "Epoch 95: val_loss did not improve from 1.08500\n",
      "6/6 - 0s - 28ms/step - accuracy: 0.9760 - loss: 0.1004 - val_accuracy: 0.3440 - val_loss: 4.2579\n",
      "Epoch 96/1000\n",
      "\n",
      "Epoch 96: val_loss did not improve from 1.08500\n",
      "6/6 - 0s - 29ms/step - accuracy: 0.9787 - loss: 0.0758 - val_accuracy: 0.3720 - val_loss: 4.2142\n",
      "Epoch 97/1000\n",
      "\n",
      "Epoch 97: val_loss did not improve from 1.08500\n",
      "6/6 - 0s - 31ms/step - accuracy: 0.9880 - loss: 0.0695 - val_accuracy: 0.3640 - val_loss: 4.3480\n",
      "Epoch 98/1000\n",
      "\n",
      "Epoch 98: val_loss did not improve from 1.08500\n",
      "6/6 - 0s - 28ms/step - accuracy: 0.9733 - loss: 0.0894 - val_accuracy: 0.3520 - val_loss: 4.3870\n",
      "Epoch 99/1000\n",
      "\n",
      "Epoch 99: val_loss did not improve from 1.08500\n",
      "6/6 - 0s - 28ms/step - accuracy: 0.9827 - loss: 0.0725 - val_accuracy: 0.3640 - val_loss: 4.5324\n",
      "Epoch 100/1000\n",
      "\n",
      "Epoch 100: val_loss did not improve from 1.08500\n",
      "6/6 - 0s - 28ms/step - accuracy: 0.9707 - loss: 0.0929 - val_accuracy: 0.3680 - val_loss: 4.5288\n",
      "Epoch 101/1000\n",
      "\n",
      "Epoch 101: val_loss did not improve from 1.08500\n",
      "6/6 - 0s - 27ms/step - accuracy: 0.9853 - loss: 0.0752 - val_accuracy: 0.3680 - val_loss: 4.4410\n",
      "Epoch 102/1000\n",
      "\n",
      "Epoch 102: val_loss did not improve from 1.08500\n",
      "6/6 - 0s - 30ms/step - accuracy: 0.9707 - loss: 0.0954 - val_accuracy: 0.3480 - val_loss: 4.4860\n",
      "Epoch 103/1000\n",
      "\n",
      "Epoch 103: val_loss did not improve from 1.08500\n",
      "6/6 - 0s - 28ms/step - accuracy: 0.9840 - loss: 0.0861 - val_accuracy: 0.3560 - val_loss: 4.5934\n",
      "Epoch 104/1000\n",
      "\n",
      "Epoch 104: val_loss did not improve from 1.08500\n",
      "6/6 - 0s - 28ms/step - accuracy: 0.9867 - loss: 0.0630 - val_accuracy: 0.3600 - val_loss: 4.6779\n",
      "Epoch 105/1000\n",
      "\n",
      "Epoch 105: val_loss did not improve from 1.08500\n",
      "6/6 - 0s - 28ms/step - accuracy: 0.9800 - loss: 0.0762 - val_accuracy: 0.3680 - val_loss: 4.7367\n",
      "Epoch 105: early stopping\n",
      "Restoring model weights from the end of the best epoch: 5.\n",
      "Elpased time: 0:00:27\n"
     ]
    }
   ],
   "source": [
    "batch_size=128\n",
    "epochs=1000\n",
    "monitor='val_loss' #'val_accuracy' or 'val_loss'\n",
    "model, history=test_net.train_model(model,\n",
    "                                    x_train,y_train, x_test,y_test, \n",
    "                                    epochs, batch_size, monitor)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss 1.0849977731704712\n",
      "Test accuracy: 0.335999995470047\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 241ms/step\n",
      "Test accuracy: 0.36363636363636365\n"
     ]
    }
   ],
   "source": [
    "import jet_ml.evaluation as eval\n",
    "eval.get_accuracy_cpu(model=model,x_test=x_test,y_test=y_test)\n",
    "eval.get_accuracy_gpu(model=model,x_test=x_test,y_test=y_test,batch_size=100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.12.5 (wsl-tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
