{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_namespace():\n",
    "    import sys\n",
    "    sys.path.insert(1,f'/wsu/home/gy/gy40/gy4065/hm.jetscapeml_source')\n",
    "    sys.path.insert(1,'/content/drive/My Drive/Projects/110_JetscapeMl/hm_jetscapeml_source')\n",
    "    sys.path.insert(1,'/content/drive/MyDrive/Projects/110_JetscapeMl/hm_jetscapeml_source')\n",
    "    sys.path.insert(1,f'/mnt/g/My Drive/Projects/110_JetscapeMl/hm_jetscapeml_source')\n",
    "    sys.path.insert(1,'G:\\\\My Drive\\\\Projects\\\\110_JetscapeMl\\\\hm_jetscapeml_source')\n",
    "load_namespace()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All Path are set\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-20 07:49:35.099053: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-08-20 07:49:35.207201: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-08-20 07:49:35.234336: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-08-20 07:49:35.407998: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-08-20 07:49:37.151240: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor Flow Version: 2.17.0\n",
      "Keras Version: 3.5.0\n",
      "\n",
      "Python 3.12.5 | packaged by conda-forge | (main, Aug  8 2024, 18:36:51) [GCC 12.4.0]\n",
      "Pandas 2.2.2\n",
      "Scikit-Learn 1.5.1\n",
      "GPU is available\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1724154579.874520     101 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1724154580.068216     101 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1724154580.068767     101 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n"
     ]
    }
   ],
   "source": [
    "from  jet_ml.config import check_environments_versions\n",
    "check_environments_versions()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aggregatring all parameters values\n",
      "label_items:\n",
      " {'eloss_items': ['MMAT', 'MLBT'], 'alpha_s_items': [0.2, 0.3, 0.4], 'q0_items': [1.5, 2.0, 2.5]}\n",
      "Building required params for the loading the dataset file\n",
      "labels_str:\n",
      " {'eloss_items_str': 'MMAT_MLBT', 'alpha_s_items_str': '0.2_0.3_0.4', 'q0_items_str': '1.5_2.0_2.5'}\n",
      "Loading the whole dataset\n",
      "Extract the working column#1 for classification\n",
      "dataset.x: <class 'numpy.ndarray'> 1024000 (1000, 32, 32)\n",
      "dataset.y: <class 'numpy.ndarray'> 1000 (1000,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Index(['0.2', '0.3', '0.4'], dtype='object')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [1, 0, 0],\n",
       "       ...,\n",
       "       [0, 1, 0],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import jet_ml.classifiers.alpha_s.preprocess_dataset as pred\n",
    "(x,y_raw,y_df)=pred.preprocess_dataset_for_alpha_s(1000)\n",
    "# pred.get_preprocess_dataset_info(x,y)\n",
    "y_classes=y_df.columns\n",
    "y=y_df.values\n",
    "display(y_classes)\n",
    "display(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     1  2  3\n",
       "0    0  0  1\n",
       "1    0  0  1\n",
       "2    1  0  0\n",
       "3    0  0  1\n",
       "4    0  0  1\n",
       "..  .. .. ..\n",
       "995  0  0  1\n",
       "996  0  0  1\n",
       "997  0  1  0\n",
       "998  0  0  1\n",
       "999  0  0  1\n",
       "\n",
       "[1000 rows x 3 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df_y=pd.DataFrame(data=y,columns= [1,2,3])\n",
    "display(df_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/arsi/miniconda3/envs/tensorflow/lib/python3.12/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "I0000 00:00:1724154760.799737     101 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1724154760.800581     101 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1724154760.800870     101 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1724154761.006963     101 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1724154761.007214     101 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-08-20 07:52:41.007265: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2112] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "I0000 00:00:1724154761.007480     101 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-08-20 07:52:41.007962: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 2242 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1650 Ti with Max-Q Design, pci bus id: 0000:01:00.0, compute capability: 7.5\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"testnet\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"testnet\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">320</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12544</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,605,760</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">387</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │           \u001b[38;5;34m320\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │        \u001b[38;5;34m18,496\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d (\u001b[38;5;33mMaxPooling2D\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12544\u001b[0m)          │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │     \u001b[38;5;34m1,605,760\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m)              │           \u001b[38;5;34m387\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,624,963</span> (6.20 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,624,963\u001b[0m (6.20 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,624,963</span> (6.20 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,624,963\u001b[0m (6.20 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1724154763.774510     173 service.cc:146] XLA service 0x7f65d4004cf0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1724154763.774547     173 service.cc:154]   StreamExecutor device (0): NVIDIA GeForce GTX 1650 Ti with Max-Q Design, Compute Capability 7.5\n",
      "2024-08-20 07:52:43.843709: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2024-08-20 07:52:44.126633: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:531] Loaded cuDNN version 8900\n",
      "I0000 00:00:1724154768.005573     173 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: val_loss improved from inf to 1.09669, saving model to /mnt/g/My Drive/Projects/110_JetscapeMl/hm_jetscapeml_source/models/testnet/model.keras\n",
      "7/7 - 10s - 1s/step - accuracy: 0.3663 - loss: 1.0993 - val_accuracy: 0.4100 - val_loss: 1.0967\n",
      "Epoch 2/1000\n",
      "\n",
      "Epoch 2: val_loss improved from 1.09669 to 1.09367, saving model to /mnt/g/My Drive/Projects/110_JetscapeMl/hm_jetscapeml_source/models/testnet/model.keras\n",
      "7/7 - 0s - 62ms/step - accuracy: 0.4238 - loss: 1.0933 - val_accuracy: 0.3600 - val_loss: 1.0937\n",
      "Epoch 3/1000\n",
      "\n",
      "Epoch 3: val_loss improved from 1.09367 to 1.09063, saving model to /mnt/g/My Drive/Projects/110_JetscapeMl/hm_jetscapeml_source/models/testnet/model.keras\n",
      "7/7 - 0s - 65ms/step - accuracy: 0.4125 - loss: 1.0846 - val_accuracy: 0.3800 - val_loss: 1.0906\n",
      "Epoch 4/1000\n",
      "\n",
      "Epoch 4: val_loss improved from 1.09063 to 1.08915, saving model to /mnt/g/My Drive/Projects/110_JetscapeMl/hm_jetscapeml_source/models/testnet/model.keras\n",
      "7/7 - 0s - 59ms/step - accuracy: 0.4663 - loss: 1.0678 - val_accuracy: 0.4050 - val_loss: 1.0892\n",
      "Epoch 5/1000\n",
      "\n",
      "Epoch 5: val_loss did not improve from 1.08915\n",
      "7/7 - 0s - 19ms/step - accuracy: 0.4437 - loss: 1.0506 - val_accuracy: 0.3600 - val_loss: 1.0947\n",
      "Epoch 6/1000\n",
      "\n",
      "Epoch 6: val_loss did not improve from 1.08915\n",
      "7/7 - 0s - 18ms/step - accuracy: 0.4437 - loss: 1.0432 - val_accuracy: 0.3600 - val_loss: 1.0999\n",
      "Epoch 7/1000\n",
      "\n",
      "Epoch 7: val_loss did not improve from 1.08915\n",
      "7/7 - 0s - 19ms/step - accuracy: 0.4762 - loss: 1.0238 - val_accuracy: 0.3700 - val_loss: 1.1031\n",
      "Epoch 8/1000\n",
      "\n",
      "Epoch 8: val_loss did not improve from 1.08915\n",
      "7/7 - 0s - 19ms/step - accuracy: 0.5013 - loss: 1.0105 - val_accuracy: 0.3950 - val_loss: 1.1127\n",
      "Epoch 9/1000\n",
      "\n",
      "Epoch 9: val_loss did not improve from 1.08915\n",
      "7/7 - 0s - 19ms/step - accuracy: 0.4988 - loss: 0.9939 - val_accuracy: 0.3900 - val_loss: 1.1180\n",
      "Epoch 10/1000\n",
      "\n",
      "Epoch 10: val_loss did not improve from 1.08915\n",
      "7/7 - 0s - 19ms/step - accuracy: 0.5113 - loss: 0.9810 - val_accuracy: 0.3250 - val_loss: 1.1303\n",
      "Epoch 11/1000\n",
      "\n",
      "Epoch 11: val_loss did not improve from 1.08915\n",
      "7/7 - 0s - 19ms/step - accuracy: 0.5038 - loss: 0.9707 - val_accuracy: 0.3300 - val_loss: 1.1473\n",
      "Epoch 12/1000\n",
      "\n",
      "Epoch 12: val_loss did not improve from 1.08915\n",
      "7/7 - 0s - 19ms/step - accuracy: 0.5412 - loss: 0.9488 - val_accuracy: 0.3800 - val_loss: 1.1767\n",
      "Epoch 13/1000\n",
      "\n",
      "Epoch 13: val_loss did not improve from 1.08915\n",
      "7/7 - 0s - 19ms/step - accuracy: 0.5350 - loss: 0.9374 - val_accuracy: 0.3600 - val_loss: 1.2167\n",
      "Epoch 14/1000\n",
      "\n",
      "Epoch 14: val_loss did not improve from 1.08915\n",
      "7/7 - 0s - 19ms/step - accuracy: 0.5350 - loss: 0.9340 - val_accuracy: 0.3150 - val_loss: 1.1902\n",
      "Epoch 15/1000\n",
      "\n",
      "Epoch 15: val_loss did not improve from 1.08915\n",
      "7/7 - 0s - 20ms/step - accuracy: 0.5412 - loss: 0.9219 - val_accuracy: 0.3850 - val_loss: 1.2018\n",
      "Epoch 16/1000\n",
      "\n",
      "Epoch 16: val_loss did not improve from 1.08915\n",
      "7/7 - 0s - 19ms/step - accuracy: 0.5375 - loss: 0.9114 - val_accuracy: 0.3550 - val_loss: 1.2320\n",
      "Epoch 17/1000\n",
      "\n",
      "Epoch 17: val_loss did not improve from 1.08915\n",
      "7/7 - 0s - 19ms/step - accuracy: 0.5612 - loss: 0.8743 - val_accuracy: 0.3550 - val_loss: 1.2643\n",
      "Epoch 18/1000\n",
      "\n",
      "Epoch 18: val_loss did not improve from 1.08915\n",
      "7/7 - 0s - 18ms/step - accuracy: 0.5750 - loss: 0.8666 - val_accuracy: 0.3850 - val_loss: 1.2828\n",
      "Epoch 19/1000\n",
      "\n",
      "Epoch 19: val_loss did not improve from 1.08915\n",
      "7/7 - 0s - 20ms/step - accuracy: 0.6012 - loss: 0.8452 - val_accuracy: 0.3450 - val_loss: 1.3017\n",
      "Epoch 20/1000\n",
      "\n",
      "Epoch 20: val_loss did not improve from 1.08915\n",
      "7/7 - 0s - 20ms/step - accuracy: 0.6025 - loss: 0.8510 - val_accuracy: 0.4050 - val_loss: 1.3272\n",
      "Epoch 21/1000\n",
      "\n",
      "Epoch 21: val_loss did not improve from 1.08915\n",
      "7/7 - 0s - 20ms/step - accuracy: 0.5800 - loss: 0.8549 - val_accuracy: 0.3600 - val_loss: 1.3306\n",
      "Epoch 22/1000\n",
      "\n",
      "Epoch 22: val_loss did not improve from 1.08915\n",
      "7/7 - 0s - 20ms/step - accuracy: 0.6037 - loss: 0.8236 - val_accuracy: 0.3700 - val_loss: 1.3476\n",
      "Epoch 23/1000\n",
      "\n",
      "Epoch 23: val_loss did not improve from 1.08915\n",
      "7/7 - 0s - 20ms/step - accuracy: 0.6388 - loss: 0.7916 - val_accuracy: 0.3600 - val_loss: 1.3862\n",
      "Epoch 24/1000\n",
      "\n",
      "Epoch 24: val_loss did not improve from 1.08915\n",
      "7/7 - 0s - 20ms/step - accuracy: 0.6625 - loss: 0.7897 - val_accuracy: 0.3550 - val_loss: 1.3859\n",
      "Epoch 25/1000\n",
      "\n",
      "Epoch 25: val_loss did not improve from 1.08915\n",
      "7/7 - 0s - 19ms/step - accuracy: 0.6413 - loss: 0.7667 - val_accuracy: 0.3850 - val_loss: 1.4284\n",
      "Epoch 26/1000\n",
      "\n",
      "Epoch 26: val_loss did not improve from 1.08915\n",
      "7/7 - 0s - 20ms/step - accuracy: 0.6463 - loss: 0.7662 - val_accuracy: 0.3550 - val_loss: 1.4481\n",
      "Epoch 27/1000\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 32\u001b[0m\n\u001b[1;32m     30\u001b[0m epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1000\u001b[39m\n\u001b[1;32m     31\u001b[0m monitor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_loss\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;66;03m#'val_accuracy' or 'val_loss'\u001b[39;00m\n\u001b[0;32m---> 32\u001b[0m model, history\u001b[38;5;241m=\u001b[39m\u001b[43mtest_net\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     33\u001b[0m \u001b[43m                                    \u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43my_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     34\u001b[0m \u001b[43m                                    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmonitor\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     36\u001b[0m pred \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(x_test)\n\u001b[1;32m     38\u001b[0m out_of_sample_y\u001b[38;5;241m.\u001b[39mappend(y_test)\n",
      "File \u001b[0;32m/mnt/g/My Drive/Projects/110_JetscapeMl/hm_jetscapeml_source/jet_ml/models/test_net.py:55\u001b[0m, in \u001b[0;36mtrain_model\u001b[0;34m(model, x_train, y_train, x_test, y_test, epochs, batch_size, monitor)\u001b[0m\n\u001b[1;32m     52\u001b[0m callbacks \u001b[38;5;241m=\u001b[39m get_callbacks(monitor, simulation_path)\n\u001b[1;32m     53\u001b[0m start_time\u001b[38;5;241m=\u001b[39mtime\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m---> 55\u001b[0m history\u001b[38;5;241m=\u001b[39m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     56\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     57\u001b[0m \u001b[43m        \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     58\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     59\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mx_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43my_test\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     60\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     61\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     62\u001b[0m elapsed_time\u001b[38;5;241m=\u001b[39mtime\u001b[38;5;241m.\u001b[39mtime()\u001b[38;5;241m-\u001b[39mstart_time\n\u001b[1;32m     63\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mjet_ml\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mhelpers\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mhelpers\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/tensorflow/lib/python3.12/site-packages/keras/src/utils/traceback_utils.py:117\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/miniconda3/envs/tensorflow/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py:360\u001b[0m, in \u001b[0;36mTensorFlowTrainer.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[1;32m    355\u001b[0m     val_logs \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    356\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mval_\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m name: val \u001b[38;5;28;01mfor\u001b[39;00m name, val \u001b[38;5;129;01min\u001b[39;00m val_logs\u001b[38;5;241m.\u001b[39mitems()\n\u001b[1;32m    357\u001b[0m     }\n\u001b[1;32m    358\u001b[0m     epoch_logs\u001b[38;5;241m.\u001b[39mupdate(val_logs)\n\u001b[0;32m--> 360\u001b[0m \u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mon_epoch_end\u001b[49m\u001b[43m(\u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepoch_logs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    361\u001b[0m training_logs \u001b[38;5;241m=\u001b[39m epoch_logs\n\u001b[1;32m    362\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstop_training:\n",
      "File \u001b[0;32m~/miniconda3/envs/tensorflow/lib/python3.12/site-packages/keras/src/callbacks/callback_list.py:96\u001b[0m, in \u001b[0;36mCallbackList.on_epoch_end\u001b[0;34m(self, epoch, logs)\u001b[0m\n\u001b[1;32m     94\u001b[0m logs \u001b[38;5;241m=\u001b[39m logs \u001b[38;5;129;01mor\u001b[39;00m {}\n\u001b[1;32m     95\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m callback \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallbacks:\n\u001b[0;32m---> 96\u001b[0m     \u001b[43mcallback\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mon_epoch_end\u001b[49m\u001b[43m(\u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/tensorflow/lib/python3.12/site-packages/keras/src/callbacks/model_checkpoint.py:206\u001b[0m, in \u001b[0;36mModelCheckpoint.on_epoch_end\u001b[0;34m(self, epoch, logs)\u001b[0m\n\u001b[1;32m    204\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mon_epoch_end\u001b[39m(\u001b[38;5;28mself\u001b[39m, epoch, logs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    205\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msave_freq \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mepoch\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 206\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_save_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mepoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/tensorflow/lib/python3.12/site-packages/keras/src/callbacks/model_checkpoint.py:238\u001b[0m, in \u001b[0;36mModelCheckpoint._save_model\u001b[0;34m(self, epoch, batch, logs)\u001b[0m\n\u001b[1;32m    236\u001b[0m \u001b[38;5;66;03m# Create host directory if it doesn't exist.\u001b[39;00m\n\u001b[1;32m    237\u001b[0m dirname \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mdirname(filepath)\n\u001b[0;32m--> 238\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dirname \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[43mfile_utils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexists\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdirname\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m    239\u001b[0m     file_utils\u001b[38;5;241m.\u001b[39mmakedirs(dirname)\n\u001b[1;32m    241\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/tensorflow/lib/python3.12/site-packages/keras/src/utils/file_utils.py:427\u001b[0m, in \u001b[0;36mexists\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m    425\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    426\u001b[0m         _raise_if_no_gfile(path)\n\u001b[0;32m--> 427\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexists\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/tensorflow/lib/python3.12/genericpath.py:19\u001b[0m, in \u001b[0;36mexists\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Test whether a path exists.  Returns False for broken symbolic links\"\"\"\u001b[39;00m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 19\u001b[0m     \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mOSError\u001b[39;00m, \u001b[38;5;167;01mValueError\u001b[39;00m):\n\u001b[1;32m     21\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn import metrics\n",
    "k_fold=StratifiedKFold(5,shuffle=False)\n",
    "\n",
    "out_of_sample_y=[]\n",
    "out_of_sample_pred=[]\n",
    "fold=0\n",
    "\n",
    "#Must specify y StratifiedKFold for classification\n",
    "for train,test in k_fold.split(x,y_raw):\n",
    "    fold+=1\n",
    "    print(f\"Fold #{fold}\")\n",
    "\n",
    "    x_train=x[train]\n",
    "    y_train=y[train]\n",
    "    x_test=x[test]\n",
    "    y_test=y[test]\n",
    "\n",
    "    import jet_ml.models.test_net as test_net\n",
    "    input_shape=x[0].shape\n",
    "    output_shape=y.shape[1]\n",
    "    activation='softmax'\n",
    "    model=test_net.build_model(input_shape,output_shape,activation)\n",
    "    model=test_net.compile_model(model)\n",
    "    model.summary()\n",
    "\n",
    "\n",
    "    batch_size=128\n",
    "    epochs=1000\n",
    "    monitor='val_loss' #'val_accuracy' or 'val_loss'\n",
    "    model, history=test_net.train_model(model,\n",
    "                                        x_train,y_train, x_test,y_test, \n",
    "                                        epochs, batch_size, monitor)\n",
    "    \n",
    "    pred = model.predict(x_test)\n",
    "\n",
    "    out_of_sample_y.append(y_test)\n",
    "    # raw probabilities to chosen class (highest probability)\n",
    "    pred = np.argmax(pred,axis=1) \n",
    "    out_of_sample_pred.append(pred)\n",
    "\n",
    "    # Measure this fold's accuracy\n",
    "    y_compare = np.argmax(y_test,axis=1) # For accuracy calculation\n",
    "    score = metrics.accuracy_score(y_compare, pred)   \n",
    "    print(f\"Fold score (accuracy): {score}\")\n",
    "\n",
    "# Build the oos prediction list and calculate the error.\n",
    "out_of_sample_y=np.concatenate(out_of_sample_y)\n",
    "out_of_sample_pred=np.concatenate(out_of_sample_pred)\n",
    "out_of_sample_y_compare=np.argmax(out_of_sample_y,axis=1)# For accuracy calculation\n",
    "\n",
    "score=metrics.accuracy_score(out_of_sample_y_compare,out_of_sample_pred)\n",
    "out_of_sample_y=pd.DataFrame(out_of_sample_y)\n",
    "out_of_sample_pred=pd.DataFrame(out_of_sample_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.374"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "display(score)\n",
    "out_of_sample_y=pd.DataFrame(out_of_sample_y)\n",
    "out_of_sample_pred=pd.DataFrame(out_of_sample_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_of_sample_DF=pd.concat([y_df,out_of_sample_y,out_of_sample_pred],axis=1)\n",
    "import jet_ml.config as config\n",
    "import os\n",
    "out_of_sample_DF.to_csv(os.path.join(config.REPORTS_DIR,\"alpha_s_test_net_5_fold_1000_epoch_1k.csv\"),index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(    \n",
    "    x, y, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/arsi/miniconda3/envs/tensorflow/lib/python3.12/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"testnet\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"testnet\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">320</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12544</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,605,760</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">387</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │           \u001b[38;5;34m320\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │        \u001b[38;5;34m18,496\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d (\u001b[38;5;33mMaxPooling2D\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12544\u001b[0m)          │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │     \u001b[38;5;34m1,605,760\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m)              │           \u001b[38;5;34m387\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,624,963</span> (6.20 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,624,963\u001b[0m (6.20 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,624,963</span> (6.20 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,624,963\u001b[0m (6.20 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import jet_ml.models.test_net as test_net\n",
    "input_shape=x[0].shape\n",
    "activation='softmax'\n",
    "model=test_net.build_model(input_shape,3,activation)\n",
    "model=test_net.compile_model(model)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "\n",
      "Epoch 1: val_loss improved from inf to 1.09768, saving model to /mnt/g/My Drive/Projects/110_JetscapeMl/hm_jetscapeml_source/models/testnet/model.keras\n",
      "6/6 - 9s - 1s/step - accuracy: 0.3347 - loss: 1.0997 - val_accuracy: 0.4200 - val_loss: 1.0977\n",
      "Epoch 2/1000\n",
      "\n",
      "Epoch 2: val_loss improved from 1.09768 to 1.09540, saving model to /mnt/g/My Drive/Projects/110_JetscapeMl/hm_jetscapeml_source/models/testnet/model.keras\n",
      "6/6 - 1s - 86ms/step - accuracy: 0.3947 - loss: 1.0934 - val_accuracy: 0.3800 - val_loss: 1.0954\n",
      "Epoch 3/1000\n",
      "\n",
      "Epoch 3: val_loss improved from 1.09540 to 1.09055, saving model to /mnt/g/My Drive/Projects/110_JetscapeMl/hm_jetscapeml_source/models/testnet/model.keras\n",
      "6/6 - 1s - 88ms/step - accuracy: 0.3947 - loss: 1.0861 - val_accuracy: 0.3600 - val_loss: 1.0905\n",
      "Epoch 4/1000\n",
      "\n",
      "Epoch 4: val_loss improved from 1.09055 to 1.08627, saving model to /mnt/g/My Drive/Projects/110_JetscapeMl/hm_jetscapeml_source/models/testnet/model.keras\n",
      "6/6 - 1s - 100ms/step - accuracy: 0.4307 - loss: 1.0751 - val_accuracy: 0.3880 - val_loss: 1.0863\n",
      "Epoch 5/1000\n",
      "\n",
      "Epoch 5: val_loss improved from 1.08627 to 1.08500, saving model to /mnt/g/My Drive/Projects/110_JetscapeMl/hm_jetscapeml_source/models/testnet/model.keras\n",
      "6/6 - 1s - 98ms/step - accuracy: 0.4480 - loss: 1.0546 - val_accuracy: 0.3360 - val_loss: 1.0850\n",
      "Epoch 6/1000\n",
      "\n",
      "Epoch 6: val_loss did not improve from 1.08500\n",
      "6/6 - 0s - 26ms/step - accuracy: 0.4333 - loss: 1.0411 - val_accuracy: 0.4000 - val_loss: 1.0908\n",
      "Epoch 7/1000\n",
      "\n",
      "Epoch 7: val_loss did not improve from 1.08500\n",
      "6/6 - 0s - 24ms/step - accuracy: 0.4707 - loss: 1.0214 - val_accuracy: 0.3760 - val_loss: 1.1004\n",
      "Epoch 8/1000\n",
      "\n",
      "Epoch 8: val_loss did not improve from 1.08500\n",
      "6/6 - 0s - 25ms/step - accuracy: 0.4853 - loss: 1.0027 - val_accuracy: 0.3640 - val_loss: 1.1192\n",
      "Epoch 9/1000\n",
      "\n",
      "Epoch 9: val_loss did not improve from 1.08500\n",
      "6/6 - 0s - 25ms/step - accuracy: 0.4880 - loss: 0.9887 - val_accuracy: 0.3520 - val_loss: 1.1259\n",
      "Epoch 10/1000\n",
      "\n",
      "Epoch 10: val_loss did not improve from 1.08500\n",
      "6/6 - 0s - 23ms/step - accuracy: 0.4960 - loss: 0.9667 - val_accuracy: 0.3840 - val_loss: 1.1362\n",
      "Epoch 11/1000\n",
      "\n",
      "Epoch 11: val_loss did not improve from 1.08500\n",
      "6/6 - 0s - 22ms/step - accuracy: 0.5160 - loss: 0.9527 - val_accuracy: 0.3800 - val_loss: 1.1552\n",
      "Epoch 12/1000\n",
      "\n",
      "Epoch 12: val_loss did not improve from 1.08500\n",
      "6/6 - 0s - 25ms/step - accuracy: 0.5133 - loss: 0.9382 - val_accuracy: 0.3600 - val_loss: 1.1626\n",
      "Epoch 13/1000\n",
      "\n",
      "Epoch 13: val_loss did not improve from 1.08500\n",
      "6/6 - 0s - 27ms/step - accuracy: 0.5387 - loss: 0.9211 - val_accuracy: 0.3840 - val_loss: 1.1926\n",
      "Epoch 14/1000\n",
      "\n",
      "Epoch 14: val_loss did not improve from 1.08500\n",
      "6/6 - 0s - 25ms/step - accuracy: 0.5173 - loss: 0.9247 - val_accuracy: 0.3520 - val_loss: 1.1978\n",
      "Epoch 15/1000\n",
      "\n",
      "Epoch 15: val_loss did not improve from 1.08500\n",
      "6/6 - 0s - 24ms/step - accuracy: 0.5440 - loss: 0.9041 - val_accuracy: 0.3920 - val_loss: 1.2032\n",
      "Epoch 16/1000\n",
      "\n",
      "Epoch 16: val_loss did not improve from 1.08500\n",
      "6/6 - 0s - 24ms/step - accuracy: 0.5493 - loss: 0.8868 - val_accuracy: 0.4000 - val_loss: 1.2337\n",
      "Epoch 17/1000\n",
      "\n",
      "Epoch 17: val_loss did not improve from 1.08500\n",
      "6/6 - 0s - 24ms/step - accuracy: 0.5493 - loss: 0.8730 - val_accuracy: 0.4120 - val_loss: 1.2524\n",
      "Epoch 18/1000\n",
      "\n",
      "Epoch 18: val_loss did not improve from 1.08500\n",
      "6/6 - 0s - 20ms/step - accuracy: 0.5853 - loss: 0.8494 - val_accuracy: 0.3760 - val_loss: 1.2856\n",
      "Epoch 19/1000\n",
      "\n",
      "Epoch 19: val_loss did not improve from 1.08500\n",
      "6/6 - 0s - 24ms/step - accuracy: 0.5773 - loss: 0.8382 - val_accuracy: 0.3520 - val_loss: 1.3160\n",
      "Epoch 20/1000\n",
      "\n",
      "Epoch 20: val_loss did not improve from 1.08500\n",
      "6/6 - 0s - 24ms/step - accuracy: 0.5853 - loss: 0.8427 - val_accuracy: 0.3680 - val_loss: 1.3149\n",
      "Epoch 21/1000\n",
      "\n",
      "Epoch 21: val_loss did not improve from 1.08500\n",
      "6/6 - 0s - 22ms/step - accuracy: 0.6093 - loss: 0.8090 - val_accuracy: 0.4000 - val_loss: 1.3606\n",
      "Epoch 22/1000\n",
      "\n",
      "Epoch 22: val_loss did not improve from 1.08500\n",
      "6/6 - 0s - 21ms/step - accuracy: 0.6120 - loss: 0.8027 - val_accuracy: 0.3600 - val_loss: 1.3518\n",
      "Epoch 23/1000\n",
      "\n",
      "Epoch 23: val_loss did not improve from 1.08500\n",
      "6/6 - 0s - 21ms/step - accuracy: 0.6253 - loss: 0.7769 - val_accuracy: 0.4000 - val_loss: 1.3735\n",
      "Epoch 24/1000\n",
      "\n",
      "Epoch 24: val_loss did not improve from 1.08500\n",
      "6/6 - 0s - 20ms/step - accuracy: 0.6453 - loss: 0.7668 - val_accuracy: 0.3600 - val_loss: 1.3936\n",
      "Epoch 25/1000\n",
      "\n",
      "Epoch 25: val_loss did not improve from 1.08500\n",
      "6/6 - 0s - 22ms/step - accuracy: 0.6373 - loss: 0.7568 - val_accuracy: 0.3800 - val_loss: 1.4144\n",
      "Epoch 26/1000\n",
      "\n",
      "Epoch 26: val_loss did not improve from 1.08500\n",
      "6/6 - 0s - 31ms/step - accuracy: 0.6707 - loss: 0.7202 - val_accuracy: 0.4000 - val_loss: 1.4538\n",
      "Epoch 27/1000\n",
      "\n",
      "Epoch 27: val_loss did not improve from 1.08500\n",
      "6/6 - 0s - 27ms/step - accuracy: 0.6760 - loss: 0.7211 - val_accuracy: 0.3680 - val_loss: 1.4942\n",
      "Epoch 28/1000\n",
      "\n",
      "Epoch 28: val_loss did not improve from 1.08500\n",
      "6/6 - 0s - 27ms/step - accuracy: 0.6547 - loss: 0.7239 - val_accuracy: 0.3800 - val_loss: 1.4943\n",
      "Epoch 29/1000\n",
      "\n",
      "Epoch 29: val_loss did not improve from 1.08500\n",
      "6/6 - 0s - 26ms/step - accuracy: 0.6853 - loss: 0.7087 - val_accuracy: 0.3840 - val_loss: 1.5536\n",
      "Epoch 30/1000\n",
      "\n",
      "Epoch 30: val_loss did not improve from 1.08500\n",
      "6/6 - 0s - 25ms/step - accuracy: 0.6853 - loss: 0.6783 - val_accuracy: 0.3840 - val_loss: 1.5276\n",
      "Epoch 31/1000\n",
      "\n",
      "Epoch 31: val_loss did not improve from 1.08500\n",
      "6/6 - 0s - 26ms/step - accuracy: 0.7067 - loss: 0.6427 - val_accuracy: 0.3960 - val_loss: 1.5965\n",
      "Epoch 32/1000\n",
      "\n",
      "Epoch 32: val_loss did not improve from 1.08500\n",
      "6/6 - 0s - 25ms/step - accuracy: 0.7280 - loss: 0.6283 - val_accuracy: 0.3840 - val_loss: 1.6239\n",
      "Epoch 33/1000\n",
      "\n",
      "Epoch 33: val_loss did not improve from 1.08500\n",
      "6/6 - 0s - 22ms/step - accuracy: 0.7253 - loss: 0.6177 - val_accuracy: 0.3960 - val_loss: 1.7055\n",
      "Epoch 34/1000\n",
      "\n",
      "Epoch 34: val_loss did not improve from 1.08500\n",
      "6/6 - 0s - 26ms/step - accuracy: 0.7440 - loss: 0.5916 - val_accuracy: 0.3840 - val_loss: 1.7124\n",
      "Epoch 35/1000\n",
      "\n",
      "Epoch 35: val_loss did not improve from 1.08500\n",
      "6/6 - 0s - 28ms/step - accuracy: 0.7413 - loss: 0.5912 - val_accuracy: 0.3760 - val_loss: 1.7392\n",
      "Epoch 36/1000\n",
      "\n",
      "Epoch 36: val_loss did not improve from 1.08500\n",
      "6/6 - 0s - 31ms/step - accuracy: 0.7413 - loss: 0.5704 - val_accuracy: 0.3800 - val_loss: 1.7518\n",
      "Epoch 37/1000\n",
      "\n",
      "Epoch 37: val_loss did not improve from 1.08500\n",
      "6/6 - 0s - 28ms/step - accuracy: 0.7733 - loss: 0.5615 - val_accuracy: 0.3840 - val_loss: 1.8144\n",
      "Epoch 38/1000\n",
      "\n",
      "Epoch 38: val_loss did not improve from 1.08500\n",
      "6/6 - 0s - 25ms/step - accuracy: 0.7627 - loss: 0.5636 - val_accuracy: 0.3960 - val_loss: 1.8126\n",
      "Epoch 39/1000\n",
      "\n",
      "Epoch 39: val_loss did not improve from 1.08500\n",
      "6/6 - 0s - 24ms/step - accuracy: 0.7733 - loss: 0.5508 - val_accuracy: 0.3720 - val_loss: 1.8215\n",
      "Epoch 40/1000\n",
      "\n",
      "Epoch 40: val_loss did not improve from 1.08500\n",
      "6/6 - 0s - 24ms/step - accuracy: 0.7760 - loss: 0.5202 - val_accuracy: 0.3760 - val_loss: 1.8855\n",
      "Epoch 41/1000\n",
      "\n",
      "Epoch 41: val_loss did not improve from 1.08500\n",
      "6/6 - 0s - 22ms/step - accuracy: 0.8160 - loss: 0.4915 - val_accuracy: 0.3840 - val_loss: 1.8907\n",
      "Epoch 42/1000\n",
      "\n",
      "Epoch 42: val_loss did not improve from 1.08500\n",
      "6/6 - 0s - 22ms/step - accuracy: 0.8013 - loss: 0.5040 - val_accuracy: 0.3720 - val_loss: 1.9222\n",
      "Epoch 43/1000\n",
      "\n",
      "Epoch 43: val_loss did not improve from 1.08500\n",
      "6/6 - 0s - 22ms/step - accuracy: 0.8160 - loss: 0.4699 - val_accuracy: 0.3960 - val_loss: 2.0388\n",
      "Epoch 44/1000\n",
      "\n",
      "Epoch 44: val_loss did not improve from 1.08500\n",
      "6/6 - 0s - 23ms/step - accuracy: 0.8440 - loss: 0.4221 - val_accuracy: 0.3800 - val_loss: 2.0422\n",
      "Epoch 45/1000\n",
      "\n",
      "Epoch 45: val_loss did not improve from 1.08500\n",
      "6/6 - 0s - 23ms/step - accuracy: 0.8600 - loss: 0.4262 - val_accuracy: 0.3880 - val_loss: 2.1594\n",
      "Epoch 46/1000\n",
      "\n",
      "Epoch 46: val_loss did not improve from 1.08500\n",
      "6/6 - 0s - 22ms/step - accuracy: 0.8387 - loss: 0.4313 - val_accuracy: 0.3720 - val_loss: 2.1409\n",
      "Epoch 47/1000\n",
      "\n",
      "Epoch 47: val_loss did not improve from 1.08500\n",
      "6/6 - 0s - 23ms/step - accuracy: 0.8480 - loss: 0.4083 - val_accuracy: 0.3720 - val_loss: 2.1451\n",
      "Epoch 48/1000\n",
      "\n",
      "Epoch 48: val_loss did not improve from 1.08500\n",
      "6/6 - 0s - 24ms/step - accuracy: 0.8533 - loss: 0.3875 - val_accuracy: 0.3640 - val_loss: 2.1345\n",
      "Epoch 49/1000\n",
      "\n",
      "Epoch 49: val_loss did not improve from 1.08500\n",
      "6/6 - 0s - 27ms/step - accuracy: 0.8480 - loss: 0.3891 - val_accuracy: 0.3960 - val_loss: 2.1893\n",
      "Epoch 50/1000\n",
      "\n",
      "Epoch 50: val_loss did not improve from 1.08500\n",
      "6/6 - 0s - 28ms/step - accuracy: 0.8573 - loss: 0.3966 - val_accuracy: 0.3840 - val_loss: 2.2728\n",
      "Epoch 51/1000\n",
      "\n",
      "Epoch 51: val_loss did not improve from 1.08500\n",
      "6/6 - 0s - 28ms/step - accuracy: 0.8547 - loss: 0.3709 - val_accuracy: 0.3760 - val_loss: 2.2941\n",
      "Epoch 52/1000\n",
      "\n",
      "Epoch 52: val_loss did not improve from 1.08500\n",
      "6/6 - 0s - 25ms/step - accuracy: 0.8640 - loss: 0.3740 - val_accuracy: 0.3640 - val_loss: 2.3625\n",
      "Epoch 53/1000\n",
      "\n",
      "Epoch 53: val_loss did not improve from 1.08500\n",
      "6/6 - 0s - 24ms/step - accuracy: 0.8773 - loss: 0.3235 - val_accuracy: 0.4080 - val_loss: 2.3570\n",
      "Epoch 54/1000\n",
      "\n",
      "Epoch 54: val_loss did not improve from 1.08500\n",
      "6/6 - 0s - 25ms/step - accuracy: 0.8760 - loss: 0.3267 - val_accuracy: 0.3760 - val_loss: 2.4309\n",
      "Epoch 55/1000\n",
      "\n",
      "Epoch 55: val_loss did not improve from 1.08500\n",
      "6/6 - 0s - 26ms/step - accuracy: 0.8827 - loss: 0.3356 - val_accuracy: 0.3720 - val_loss: 2.4910\n",
      "Epoch 56/1000\n",
      "\n",
      "Epoch 56: val_loss did not improve from 1.08500\n",
      "6/6 - 0s - 28ms/step - accuracy: 0.9053 - loss: 0.3212 - val_accuracy: 0.3840 - val_loss: 2.5837\n",
      "Epoch 57/1000\n",
      "\n",
      "Epoch 57: val_loss did not improve from 1.08500\n",
      "6/6 - 0s - 25ms/step - accuracy: 0.9067 - loss: 0.2739 - val_accuracy: 0.3920 - val_loss: 2.6854\n",
      "Epoch 58/1000\n",
      "\n",
      "Epoch 58: val_loss did not improve from 1.08500\n",
      "6/6 - 0s - 26ms/step - accuracy: 0.9067 - loss: 0.2705 - val_accuracy: 0.3680 - val_loss: 2.6720\n",
      "Epoch 59/1000\n",
      "\n",
      "Epoch 59: val_loss did not improve from 1.08500\n",
      "6/6 - 0s - 26ms/step - accuracy: 0.9000 - loss: 0.2752 - val_accuracy: 0.3760 - val_loss: 2.7700\n",
      "Epoch 60/1000\n",
      "\n",
      "Epoch 60: val_loss did not improve from 1.08500\n",
      "6/6 - 0s - 25ms/step - accuracy: 0.9067 - loss: 0.2616 - val_accuracy: 0.3920 - val_loss: 2.7882\n",
      "Epoch 61/1000\n",
      "\n",
      "Epoch 61: val_loss did not improve from 1.08500\n",
      "6/6 - 0s - 27ms/step - accuracy: 0.9267 - loss: 0.2380 - val_accuracy: 0.3920 - val_loss: 2.8754\n",
      "Epoch 62/1000\n",
      "\n",
      "Epoch 62: val_loss did not improve from 1.08500\n",
      "6/6 - 0s - 30ms/step - accuracy: 0.9240 - loss: 0.2531 - val_accuracy: 0.3760 - val_loss: 2.9961\n",
      "Epoch 63/1000\n",
      "\n",
      "Epoch 63: val_loss did not improve from 1.08500\n",
      "6/6 - 0s - 31ms/step - accuracy: 0.9227 - loss: 0.2362 - val_accuracy: 0.3640 - val_loss: 3.0131\n",
      "Epoch 64/1000\n",
      "\n",
      "Epoch 64: val_loss did not improve from 1.08500\n",
      "6/6 - 0s - 28ms/step - accuracy: 0.9093 - loss: 0.2381 - val_accuracy: 0.3720 - val_loss: 3.0498\n",
      "Epoch 65/1000\n",
      "\n",
      "Epoch 65: val_loss did not improve from 1.08500\n",
      "6/6 - 0s - 32ms/step - accuracy: 0.9413 - loss: 0.2207 - val_accuracy: 0.3880 - val_loss: 3.1194\n",
      "Epoch 66/1000\n",
      "\n",
      "Epoch 66: val_loss did not improve from 1.08500\n",
      "6/6 - 0s - 32ms/step - accuracy: 0.9240 - loss: 0.2303 - val_accuracy: 0.3800 - val_loss: 3.1312\n",
      "Epoch 67/1000\n",
      "\n",
      "Epoch 67: val_loss did not improve from 1.08500\n",
      "6/6 - 0s - 27ms/step - accuracy: 0.9267 - loss: 0.2311 - val_accuracy: 0.3680 - val_loss: 3.1986\n",
      "Epoch 68/1000\n",
      "\n",
      "Epoch 68: val_loss did not improve from 1.08500\n",
      "6/6 - 0s - 26ms/step - accuracy: 0.9387 - loss: 0.1845 - val_accuracy: 0.3640 - val_loss: 3.1581\n",
      "Epoch 69/1000\n",
      "\n",
      "Epoch 69: val_loss did not improve from 1.08500\n",
      "6/6 - 0s - 26ms/step - accuracy: 0.9320 - loss: 0.2051 - val_accuracy: 0.3760 - val_loss: 3.2011\n",
      "Epoch 70/1000\n",
      "\n",
      "Epoch 70: val_loss did not improve from 1.08500\n",
      "6/6 - 0s - 24ms/step - accuracy: 0.9560 - loss: 0.1784 - val_accuracy: 0.3840 - val_loss: 3.2856\n",
      "Epoch 71/1000\n",
      "\n",
      "Epoch 71: val_loss did not improve from 1.08500\n",
      "6/6 - 0s - 24ms/step - accuracy: 0.9480 - loss: 0.1939 - val_accuracy: 0.3680 - val_loss: 3.3028\n",
      "Epoch 72/1000\n",
      "\n",
      "Epoch 72: val_loss did not improve from 1.08500\n",
      "6/6 - 0s - 28ms/step - accuracy: 0.9493 - loss: 0.1705 - val_accuracy: 0.3720 - val_loss: 3.4090\n",
      "Epoch 73/1000\n",
      "\n",
      "Epoch 73: val_loss did not improve from 1.08500\n",
      "6/6 - 0s - 27ms/step - accuracy: 0.9533 - loss: 0.1504 - val_accuracy: 0.3720 - val_loss: 3.3295\n",
      "Epoch 74/1000\n",
      "\n",
      "Epoch 74: val_loss did not improve from 1.08500\n",
      "6/6 - 0s - 27ms/step - accuracy: 0.9493 - loss: 0.1539 - val_accuracy: 0.3720 - val_loss: 3.4423\n",
      "Epoch 75/1000\n",
      "\n",
      "Epoch 75: val_loss did not improve from 1.08500\n",
      "6/6 - 0s - 25ms/step - accuracy: 0.9573 - loss: 0.1462 - val_accuracy: 0.3680 - val_loss: 3.5293\n",
      "Epoch 76/1000\n",
      "\n",
      "Epoch 76: val_loss did not improve from 1.08500\n",
      "6/6 - 0s - 27ms/step - accuracy: 0.9560 - loss: 0.1338 - val_accuracy: 0.3840 - val_loss: 3.5506\n",
      "Epoch 77/1000\n",
      "\n",
      "Epoch 77: val_loss did not improve from 1.08500\n",
      "6/6 - 0s - 25ms/step - accuracy: 0.9507 - loss: 0.1522 - val_accuracy: 0.3560 - val_loss: 3.6181\n",
      "Epoch 78/1000\n",
      "\n",
      "Epoch 78: val_loss did not improve from 1.08500\n",
      "6/6 - 0s - 26ms/step - accuracy: 0.9600 - loss: 0.1524 - val_accuracy: 0.3600 - val_loss: 3.5934\n",
      "Epoch 79/1000\n",
      "\n",
      "Epoch 79: val_loss did not improve from 1.08500\n",
      "6/6 - 0s - 26ms/step - accuracy: 0.9600 - loss: 0.1455 - val_accuracy: 0.3560 - val_loss: 3.6327\n",
      "Epoch 80/1000\n",
      "\n",
      "Epoch 80: val_loss did not improve from 1.08500\n",
      "6/6 - 0s - 25ms/step - accuracy: 0.9627 - loss: 0.1423 - val_accuracy: 0.3600 - val_loss: 3.6928\n",
      "Epoch 81/1000\n",
      "\n",
      "Epoch 81: val_loss did not improve from 1.08500\n",
      "6/6 - 0s - 25ms/step - accuracy: 0.9667 - loss: 0.1197 - val_accuracy: 0.3880 - val_loss: 3.7215\n",
      "Epoch 82/1000\n",
      "\n",
      "Epoch 82: val_loss did not improve from 1.08500\n",
      "6/6 - 0s - 28ms/step - accuracy: 0.9560 - loss: 0.1447 - val_accuracy: 0.3800 - val_loss: 3.7426\n",
      "Epoch 83/1000\n",
      "\n",
      "Epoch 83: val_loss did not improve from 1.08500\n",
      "6/6 - 0s - 27ms/step - accuracy: 0.9747 - loss: 0.1204 - val_accuracy: 0.3720 - val_loss: 3.7915\n",
      "Epoch 84/1000\n",
      "\n",
      "Epoch 84: val_loss did not improve from 1.08500\n",
      "6/6 - 0s - 27ms/step - accuracy: 0.9640 - loss: 0.1191 - val_accuracy: 0.3720 - val_loss: 3.8139\n",
      "Epoch 85/1000\n",
      "\n",
      "Epoch 85: val_loss did not improve from 1.08500\n",
      "6/6 - 0s - 28ms/step - accuracy: 0.9747 - loss: 0.1053 - val_accuracy: 0.3520 - val_loss: 3.8959\n",
      "Epoch 86/1000\n",
      "\n",
      "Epoch 86: val_loss did not improve from 1.08500\n",
      "6/6 - 0s - 25ms/step - accuracy: 0.9707 - loss: 0.1108 - val_accuracy: 0.3520 - val_loss: 3.9308\n",
      "Epoch 87/1000\n",
      "\n",
      "Epoch 87: val_loss did not improve from 1.08500\n",
      "6/6 - 0s - 26ms/step - accuracy: 0.9773 - loss: 0.0997 - val_accuracy: 0.3800 - val_loss: 3.9522\n",
      "Epoch 88/1000\n",
      "\n",
      "Epoch 88: val_loss did not improve from 1.08500\n",
      "6/6 - 0s - 25ms/step - accuracy: 0.9613 - loss: 0.1219 - val_accuracy: 0.3560 - val_loss: 3.9038\n",
      "Epoch 89/1000\n",
      "\n",
      "Epoch 89: val_loss did not improve from 1.08500\n",
      "6/6 - 0s - 26ms/step - accuracy: 0.9693 - loss: 0.1009 - val_accuracy: 0.3680 - val_loss: 4.0671\n",
      "Epoch 90/1000\n",
      "\n",
      "Epoch 90: val_loss did not improve from 1.08500\n",
      "6/6 - 0s - 25ms/step - accuracy: 0.9760 - loss: 0.0988 - val_accuracy: 0.3520 - val_loss: 4.0124\n",
      "Epoch 91/1000\n",
      "\n",
      "Epoch 91: val_loss did not improve from 1.08500\n",
      "6/6 - 0s - 25ms/step - accuracy: 0.9653 - loss: 0.1197 - val_accuracy: 0.3600 - val_loss: 4.1090\n",
      "Epoch 92/1000\n",
      "\n",
      "Epoch 92: val_loss did not improve from 1.08500\n",
      "6/6 - 0s - 25ms/step - accuracy: 0.9773 - loss: 0.0849 - val_accuracy: 0.3680 - val_loss: 4.1007\n",
      "Epoch 93/1000\n",
      "\n",
      "Epoch 93: val_loss did not improve from 1.08500\n",
      "6/6 - 0s - 27ms/step - accuracy: 0.9773 - loss: 0.0844 - val_accuracy: 0.3640 - val_loss: 4.1375\n",
      "Epoch 94/1000\n",
      "\n",
      "Epoch 94: val_loss did not improve from 1.08500\n",
      "6/6 - 0s - 28ms/step - accuracy: 0.9787 - loss: 0.0825 - val_accuracy: 0.3520 - val_loss: 4.2300\n",
      "Epoch 95/1000\n",
      "\n",
      "Epoch 95: val_loss did not improve from 1.08500\n",
      "6/6 - 0s - 28ms/step - accuracy: 0.9760 - loss: 0.1004 - val_accuracy: 0.3440 - val_loss: 4.2579\n",
      "Epoch 96/1000\n",
      "\n",
      "Epoch 96: val_loss did not improve from 1.08500\n",
      "6/6 - 0s - 29ms/step - accuracy: 0.9787 - loss: 0.0758 - val_accuracy: 0.3720 - val_loss: 4.2142\n",
      "Epoch 97/1000\n",
      "\n",
      "Epoch 97: val_loss did not improve from 1.08500\n",
      "6/6 - 0s - 31ms/step - accuracy: 0.9880 - loss: 0.0695 - val_accuracy: 0.3640 - val_loss: 4.3480\n",
      "Epoch 98/1000\n",
      "\n",
      "Epoch 98: val_loss did not improve from 1.08500\n",
      "6/6 - 0s - 28ms/step - accuracy: 0.9733 - loss: 0.0894 - val_accuracy: 0.3520 - val_loss: 4.3870\n",
      "Epoch 99/1000\n",
      "\n",
      "Epoch 99: val_loss did not improve from 1.08500\n",
      "6/6 - 0s - 28ms/step - accuracy: 0.9827 - loss: 0.0725 - val_accuracy: 0.3640 - val_loss: 4.5324\n",
      "Epoch 100/1000\n",
      "\n",
      "Epoch 100: val_loss did not improve from 1.08500\n",
      "6/6 - 0s - 28ms/step - accuracy: 0.9707 - loss: 0.0929 - val_accuracy: 0.3680 - val_loss: 4.5288\n",
      "Epoch 101/1000\n",
      "\n",
      "Epoch 101: val_loss did not improve from 1.08500\n",
      "6/6 - 0s - 27ms/step - accuracy: 0.9853 - loss: 0.0752 - val_accuracy: 0.3680 - val_loss: 4.4410\n",
      "Epoch 102/1000\n",
      "\n",
      "Epoch 102: val_loss did not improve from 1.08500\n",
      "6/6 - 0s - 30ms/step - accuracy: 0.9707 - loss: 0.0954 - val_accuracy: 0.3480 - val_loss: 4.4860\n",
      "Epoch 103/1000\n",
      "\n",
      "Epoch 103: val_loss did not improve from 1.08500\n",
      "6/6 - 0s - 28ms/step - accuracy: 0.9840 - loss: 0.0861 - val_accuracy: 0.3560 - val_loss: 4.5934\n",
      "Epoch 104/1000\n",
      "\n",
      "Epoch 104: val_loss did not improve from 1.08500\n",
      "6/6 - 0s - 28ms/step - accuracy: 0.9867 - loss: 0.0630 - val_accuracy: 0.3600 - val_loss: 4.6779\n",
      "Epoch 105/1000\n",
      "\n",
      "Epoch 105: val_loss did not improve from 1.08500\n",
      "6/6 - 0s - 28ms/step - accuracy: 0.9800 - loss: 0.0762 - val_accuracy: 0.3680 - val_loss: 4.7367\n",
      "Epoch 105: early stopping\n",
      "Restoring model weights from the end of the best epoch: 5.\n",
      "Elpased time: 0:00:27\n"
     ]
    }
   ],
   "source": [
    "batch_size=128\n",
    "epochs=1000\n",
    "monitor='val_loss' #'val_accuracy' or 'val_loss'\n",
    "model, history=test_net.train_model(model,\n",
    "                                    x_train,y_train, x_test,y_test, \n",
    "                                    epochs, batch_size, monitor)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss 1.0849977731704712\n",
      "Test accuracy: 0.335999995470047\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 241ms/step\n",
      "Test accuracy: 0.36363636363636365\n"
     ]
    }
   ],
   "source": [
    "import jet_ml.evaluation as eval\n",
    "eval.get_accuracy_cpu(model=model,x_test=x_test,y_test=y_test)\n",
    "eval.get_accuracy_gpu(model=model,x_test=x_test,y_test=y_test,batch_size=100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.12.5 (wsl-tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
