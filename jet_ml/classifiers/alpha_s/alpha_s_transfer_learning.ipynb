{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_namespace():\n",
    "    import sys\n",
    "    sys.path.insert(1,f'/wsu/home/gy/gy40/gy4065/hm_jetscapeml_source')#WSU Grid\n",
    "    sys.path.insert(1,'/content/drive/My Drive/Projects/110_JetscapeMl/hm_jetscapeml_source')#Colab GDrive v1\n",
    "    sys.path.insert(1,'/content/drive/MyDrive/Projects/110_JetscapeMl/hm_jetscapeml_source')#Colab GDrive v2\n",
    "    sys.path.insert(1,f'/mnt/g/My Drive/Projects/110_JetscapeMl/hm_jetscapeml_source')#wsl gdrive\n",
    "    sys.path.insert(1,'G:\\\\My Drive\\\\Projects\\\\110_JetscapeMl\\\\hm_jetscapeml_source') #Windows GDrive\n",
    "    sys.path.insert(1,'/home/arsalan/Projects/110_JetscapeML/hm_jetscapeml_source/') #office tower\n",
    "    \n",
    "load_namespace()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-29 11:39:45.933390: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-08-29 11:39:45.940752: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-08-29 11:39:45.949987: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-08-29 11:39:45.952558: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-08-29 11:39:45.959179: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-08-29 11:39:46.471610: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory /home/arsalan/Projects/110_JetscapeML/hm_jetscapeml_source/models/alpha_s_res_net_5_fold_2_epoch_1k_dataset_size already exists.\n",
      "Directory /home/arsalan/Projects/110_JetscapeML/hm_jetscapeml_source/reports/alpha_s_res_net_5_fold_2_epoch_1k_dataset_size already exists.\n",
      "Directory /home/arsalan/Projects/110_JetscapeML/hm_jetscapeml_source/reports/figures/alpha_s_res_net_5_fold_2_epoch_1k_dataset_size already exists.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1724945987.025502  477888 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1724945987.046565  477888 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1724945987.046703  477888 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Project Root: /home/arsalan/Projects/110_JetscapeML/hm_jetscapeml_source\\nData Directory: /home/arsalan/Projects/110_JetscapeML/hm_jetscapeml_source/data\\nModels Directory: /home/arsalan/Projects/110_JetscapeML/hm_jetscapeml_source/models\\nReports Directory: /home/arsalan/Projects/110_JetscapeML/hm_jetscapeml_source/reports\\nFigures Directory: /home/arsalan/Projects/110_JetscapeML/hm_jetscapeml_source/reports/figures\\nSimulation Models Directory: /home/arsalan/Projects/110_JetscapeML/hm_jetscapeml_source/models/alpha_s_res_net_5_fold_2_epoch_1k_dataset_size\\nSimulation Reports Directory: /home/arsalan/Projects/110_JetscapeML/hm_jetscapeml_source/reports/alpha_s_res_net_5_fold_2_epoch_1k_dataset_size\\nSimulation Figures Directory: /home/arsalan/Projects/110_JetscapeML/hm_jetscapeml_source/reports/figures/alpha_s_res_net_5_fold_2_epoch_1k_dataset_size\\nEnvironment Details:\\n  TensorFlow Version: 2.17.0\\n  Keras Version: 3.5.0\\n  Python Version: 3.12.5 | packaged by conda-forge | (main, Aug  8 2024, 18:36:51) [GCC 12.4.0]\\n  Pandas Version: 2.2.2\\n  Scikit-Learn Version: 1.5.1\\n  GPU is available'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loading/Preparing Environment for simulation\n",
    "from jet_ml.config import Config\n",
    "folds=5\n",
    "epochs=2\n",
    "dataset_size=1000 #10800000 #1000000\n",
    "model_name=\"res_net\"\n",
    "simulation_name=f\"alpha_s_{model_name}_{folds}_fold_{epochs}_epoch_{int(dataset_size/1000)}k_dataset_size\"\n",
    "\n",
    "config=Config(simulation_name=simulation_name)\n",
    "config.__str__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Preprocessor\n",
      "Loading the whole dataset\n",
      "Extract the working column#1 for classification\n",
      "dataset.x: <class 'numpy.ndarray'> 1024000 (1000, 32, 32)\n",
      "dataset.y: <class 'numpy.ndarray'> 1000 (1000,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'y_classes: '"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Index(['0.2', '0.3', '0.4'], dtype='object')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'y: '"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [1, 0, 0],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'y_raw: '"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array(['0.4', '0.4', '0.2', '0.4', '0.4'], dtype='<U32')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display\n",
    "# with tf.device(\"CPU\"):\n",
    "import jet_ml.classifiers.alpha_s.preprocess_dataset as pred\n",
    "(x,y_raw,y_df)=pred.preprocess_dataset_for_alpha_s(dataset_size)\n",
    "y_classes=y_df.columns\n",
    "y=y_df.values\n",
    "display(\"y_classes: \",y_classes)\n",
    "display(\"y: \",y[:5])\n",
    "display(\"y_raw: \",y_raw[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training size: 900\n",
      "Validate size: 100\n"
     ]
    }
   ],
   "source": [
    "TRAIN_PCT = 0.9\n",
    "TRAIN_CUT = int(len(x) * TRAIN_PCT)\n",
    "\n",
    "df_train_cut = x[0:TRAIN_CUT]\n",
    "df_validate_cut = x[TRAIN_CUT:]\n",
    "\n",
    "print(f\"Training size: {len(df_train_cut)}\")\n",
    "print(f\"Validate size: {len(df_validate_cut)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#checking data is normalize\n",
    "import numpy as np\n",
    "x_max=np.max(x)\n",
    "display(x_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 32, 32, 1)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(1000, 3)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(x.shape)\n",
    "display(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transposed shape: (3, 1000)\n",
      "Final shape: (1000, 3, 1)\n"
     ]
    }
   ],
   "source": [
    "# Transpose and then rearrange the dimensions\n",
    "y_transposed = np.transpose(y)  # Shape will be (3, 1000)\n",
    "\n",
    "# y_transposed is now (3, 1000)\n",
    "print(\"Transposed shape:\", y_transposed.shape)\n",
    "\n",
    "# Optionally, you might want to add an extra dimension if needed\n",
    "y_final = np.expand_dims(y, axis=2)  # Shape will be (1, 3, 1000)\n",
    "\n",
    "# Check the final shape\n",
    "print(\"Final shape:\", y_final.shape)  # Should be (1, 3, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "WIDTH = 256\n",
    "HEIGHT = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x shape: (1000, 32, 32, 1)\n",
      "x samples:(32, 32, 1)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0  1  2\n",
       "0  0  0  1\n",
       "1  0  0  1\n",
       "2  1  0  0\n",
       "3  0  0  1\n",
       "4  0  0  1\n",
       "5  0  1  0\n",
       "6  0  0  1\n",
       "7  0  1  0\n",
       "8  0  0  1\n",
       "9  0  0  1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from jet_ml.classifiers.alpha_s.preprocess_dataset import get_preprocess_dataset_info\n",
    "get_preprocess_dataset_info(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "# Convert grayscale to RGB (if needed)\n",
    "x_rgb = np.concatenate([x] * 3, axis=-1)  # Convert to RGB\n",
    "\n",
    "# Resize images to the target size\n",
    "TARGET_WIDTH = 256\n",
    "TARGET_HEIGHT = 256\n",
    "with tf.device(\"CPU\"):\n",
    "    x_resized = np.array([tf.image.resize(image, [HEIGHT, WIDTH]) for image in x_rgb])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 256, 256, 3)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_resized.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define ImageDataGenerator\n",
    "datagen = ImageDataGenerator(\n",
    "    # rescale=1./255,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "# Create the data generator\n",
    "batch_size = 32\n",
    "\n",
    "train_generator = datagen.flow(\n",
    "    x_resized,\n",
    "    y_final,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    seed=42  # For reproducibility\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1724949635.882884  478043 service.cc:146] XLA service 0x707f88071990 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1724949635.882914  478043 service.cc:154]   StreamExecutor device (0): Host, Default Version\n",
      "2024-08-29 12:40:35.894847: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "I0000 00:00:1724949636.073038  478043 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 674ms/step - accuracy: 0.1945 - loss: 1.1122\n",
      "Epoch 2/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 194us/step - accuracy: 0.4792 - loss: 1.1039 \n",
      "Epoch 3/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/arsalan/miniconda3/envs/tensorflow/lib/python3.12/contextlib.py:158: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
      "  self.gen.throw(value)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 668ms/step - accuracy: 0.4091 - loss: 1.0829\n",
      "Epoch 4/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 119us/step - accuracy: 0.3854 - loss: 1.0772 \n",
      "Epoch 5/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-29 12:41:19.422670: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 672ms/step - accuracy: 0.3236 - loss: 1.0477\n",
      "Epoch 6/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 85us/step - accuracy: 0.3021 - loss: 1.0719  \n",
      "Epoch 7/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 673ms/step - accuracy: 0.2775 - loss: 1.0218\n",
      "Epoch 8/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 136us/step - accuracy: 0.2812 - loss: 1.0622 \n",
      "Epoch 9/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 675ms/step - accuracy: 0.2953 - loss: 0.9800\n",
      "Epoch 10/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 86us/step - accuracy: 0.2292 - loss: 0.9343  \n"
     ]
    }
   ],
   "source": [
    "with tf.device(\"CPU\"):\n",
    "    # Define a simple model with the updated input shape\n",
    "    model = tf.keras.models.Sequential([\n",
    "        tf.keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(HEIGHT, WIDTH, 3)),\n",
    "        tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "        tf.keras.layers.Flatten(),\n",
    "        tf.keras.layers.Dense(64, activation='relu'),\n",
    "        tf.keras.layers.Dense(3, activation='softmax')\n",
    "    ])\n",
    "\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "\n",
    "    # Train the model using the data generator\n",
    "    model.fit(train_generator, epochs=10, steps_per_epoch=len(x_resized) // batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import keras_preprocessing\n",
    "from keras_preprocessing import image\n",
    "from keras_preprocessing.image import ImageDataGenerator\n",
    "\n",
    "\n",
    "training_datagen = ImageDataGenerator(\n",
    "  rescale = 1./1,\n",
    "  horizontal_flip=True,\n",
    "  #vertical_flip=True,\n",
    "  fill_mode='nearest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Define the custom data generator class\n",
    "class NumpyArrayDataGenerator(tf.keras.utils.Sequence):\n",
    "    def __init__(self, x_data, y_data, batch_size, datagen, target_size, shuffle=True):\n",
    "        self.x_data = x_data\n",
    "        self.y_data = y_data\n",
    "        self.batch_size = batch_size\n",
    "        self.datagen = datagen\n",
    "        self.target_size = target_size\n",
    "\n",
    "        self.shuffle = shuffle\n",
    "        self.indexes = np.arange(len(self.x_data))\n",
    "        self.on_epoch_end()\n",
    "        \n",
    "    def __len__(self):\n",
    "        # Number of batches per epoch\n",
    "        return int(np.floor(len(self.x_data) / self.batch_size))\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        # Generate one batch of data\n",
    "        indexes = self.indexes[index * self.batch_size:(index + 1) * self.batch_size]\n",
    "        batch_x = self.x_data[indexes]\n",
    "        batch_y = self.y_data[indexes]\n",
    "        \n",
    "        # Resize images to target size\n",
    "        resized_images = [tf.image.resize(img, [self.target_size[0], self.target_size[1]]) for img in batch_x]\n",
    "        resized_images = np.array(resized_images)\n",
    "        \n",
    "        # Apply data augmentation\n",
    "        augmented_images = []\n",
    "        for img in batch_x:\n",
    "            img = np.expand_dims(img, axis=0)\n",
    "            augmented_img = self.datagen.flow(img, batch_size=1).next()[0]\n",
    "            augmented_images.append(augmented_img)\n",
    "        \n",
    "        return np.array(augmented_images), np.array\n",
    "    def on_epoch_end(self):\n",
    "        if self.shuffle:\n",
    "            np.random.shuffle(self.indexes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the data generator\n",
    "batch_size = 32\n",
    "train_generator = NumpyArrayDataGenerator(x, y, batch_size, training_datagen,target_size=(HEIGHT, WIDTH),shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(train_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "# Define a simple model with the updated input shape\n",
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(HEIGHT, WIDTH,1)),\n",
    "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    tf.keras.layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model using the data generator\n",
    "model.fit(train_generator, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_datagen.flow_from_dataframe(dataframe=df_train_cut,x_col='events',y_col=y,target_size=(HEIGHT,WIDTH),batch_size=32,class_mode='raw')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator = training_datagen.flow_from_dataframe(\n",
    "        dataframe=df_train_cut,\n",
    "        directory=x,\n",
    "        x_col=\"filename\",\n",
    "        y_col=\"clip_count\",\n",
    "        target_size=(HEIGHT, WIDTH),\n",
    "        # Keeping the training batch size small \n",
    "        # USUALLY increases performance\n",
    "        batch_size=32, \n",
    "        class_mode='raw')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import keras_preprocessing\n",
    "from keras_preprocessing import image\n",
    "from keras_preprocessing.image import ImageDataGenerator\n",
    "\n",
    "WIDTH = 256\n",
    "HEIGHT = 256\n",
    "\n",
    "training_datagen = ImageDataGenerator(\n",
    "  rescale = 1./255,\n",
    "  horizontal_flip=True,\n",
    "  #vertical_flip=True,\n",
    "  fill_mode='nearest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fold, shuffle, x, y_raw\n",
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn import metrics\n",
    "k_fold=StratifiedKFold(folds,shuffle=False)\n",
    "\n",
    "out_of_sample_y=[]\n",
    "out_of_sample_pred=[]\n",
    "fold=0\n",
    "folds_accuracy=[]\n",
    "epochs_needed = []\n",
    "times_taken=[]\n",
    "#Must specify y StratifiedKFold for classification\n",
    "for train,test in k_fold.split(x,y_raw):\n",
    "    fold+=1\n",
    "    print(f\"Fold #{fold}\")\n",
    "\n",
    "    x_train=x[train]\n",
    "    y_train=y[train]\n",
    "    x_test=x[test]\n",
    "    y_test=y[test]\n",
    "\n",
    "    from jet_ml.models import vgg16_net\n",
    "    input_shape=x[0].shape\n",
    "    output_shape=y.shape[1]\n",
    "    activation='softmax'\n",
    "    # HIDE OUTPUT\n",
    "    from tensorflow.keras.applications import MobileNet\n",
    "    model = MobileNet(weights='imagenet',include_top=True)\n",
    "    model.summary()\n",
    "    model=vgg16_net.build_model(input_shape,output_shape,activation)\n",
    "    model=vgg16_net.compile_model(model)\n",
    "\n",
    "\n",
    "    batch_size=128\n",
    "    # batch_size=256 #original patch size applies for eloss classification\n",
    "    monitor='val_loss' #'val_accuracy' or 'val_loss'\n",
    "    \n",
    "    model, history,elapsed_time,stopped_epoch=vgg16_net.train_model(model,\n",
    "                                        x_train,y_train, x_test,y_test, \n",
    "                                        epochs, batch_size, monitor,\n",
    "                                        fold=fold)\n",
    "\n",
    "    from jet_ml.evaluation import get_accuracy\n",
    "    pred, score=get_accuracy(model,x_test=x_test,y_test=y_test)\n",
    "    \n",
    "    folds_accuracy.append(score)\n",
    "    times_taken.append(elapsed_time)    \n",
    "    epochs_needed.append(epochs)\n",
    "\n",
    "    out_of_sample_y.append(y_test)\n",
    "    out_of_sample_pred.append(pred)\n",
    "    print(f\"Fold score (accuracy): {score}\")\n",
    "\n",
    "    from jet_ml.evaluation import save_training_history\n",
    "    save_training_history(history=history,fold=fold)\n",
    "\n",
    "    from jet_ml.evaluation import plot_training_history\n",
    "    plot_training_history(history=history,fold=fold)\n",
    "\n",
    "from jet_ml.evaluation import save_training_stats\n",
    "save_training_stats(accuracies=folds_accuracy,\n",
    "                    epochs_needed=epochs_needed,\n",
    "                    times_taken=times_taken)\n",
    "\n",
    "# # Build the oos prediction list and calculate the error.\n",
    "out_of_sample_y=np.concatenate(out_of_sample_y)\n",
    "out_of_sample_pred=np.concatenate(out_of_sample_pred)\n",
    "\n",
    "out_of_sample_y_compare=np.argmax(out_of_sample_y,axis=1)# For accuracy and confusion matrix calculation"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.12.4 (tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
