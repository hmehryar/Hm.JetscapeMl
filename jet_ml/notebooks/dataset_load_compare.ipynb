{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook load both 10.8m and 1k events datasets and invistigate if there is just all first 1000 entry in 10.8 datasets match with the 1k dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading 10.8M events dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_namespace():\n",
    "    import sys\n",
    "    sys.path.insert(1,'/wsu/home/gy/gy40/gy4065/hm_jetscapeml_source')#WSU Grid\n",
    "    sys.path.insert(1,'/content/drive/My Drive/Projects/110_JetscapeMl/hm_jetscapeml_source')#Colab GDrive v1\n",
    "    sys.path.insert(1,'/content/drive/MyDrive/Projects/110_JetscapeMl/hm_jetscapeml_source')#Colab GDrive v2\n",
    "    sys.path.insert(1,f'/mnt/g/My Drive/Projects/110_JetscapeMl/hm_jetscapeml_source')#wsl gdrive\n",
    "    sys.path.insert(1,'G:\\\\My Drive\\\\Projects\\\\110_JetscapeMl\\\\hm_jetscapeml_source') #Windows GDrive\n",
    "    sys.path.insert(1,'/home/arsalan/Projects/110_JetscapeML/hm_jetscapeml_source/') #office tower\n",
    "    \n",
    "load_namespace()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# dataset_file_name = \"/home/arsalan/wsu-grid/hm_jetscapeml_source/data/jet_ml_benchmark_config_01_to_09_alpha_0.2_0.3_0.4_q0_1.5_2.0_2.5_MMAT_MLBT_size_10800000_shuffled.pkl\"\n",
    "dataset_file_name=\"/wsu/home/gy/gy40/gy4065/hm_jetscapeml_source/data/jet_ml_benchmark_config_01_to_09_alpha_0.2_0.3_0.4_q0_1.5_2.0_2.5_MMAT_MLBT_size_10800000_shuffled.pkl\"\n",
    "dataset = pd.read_pickle(dataset_file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Investivating its structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After loading the dataset\n",
      "dataset.x_train: <class 'numpy.ndarray'> 9953270784 (9719991, 32, 32)\n",
      "dataset.y_train: <class 'numpy.ndarray'> 29159973 (9719991, 3)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([['MLBT', '0.4', '2.5'],\n",
       "       ['MLBT', '0.4', '2.5'],\n",
       "       ['MLBT', '0.2', '2.5'],\n",
       "       ['MMAT', '0.4', '1'],\n",
       "       ['MMAT', '0.4', '1']], dtype='<U32')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset.x_test: <class 'numpy.ndarray'> 1105920000 (1080000, 32, 32)\n",
      "dataset.y_test: <class 'numpy.ndarray'> 3240000 (1080000, 3)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([['MMAT', '0.2', '1'],\n",
       "       ['MMAT', '0.2', '1'],\n",
       "       ['MMAT', '0.2', '1'],\n",
       "       ['MMAT', '0.2', '1'],\n",
       "       ['MMAT', '0.2', '1']], dtype='<U32')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"After loading the dataset\")\n",
    "print(\"dataset.x_train:\",type(dataset[0][0]), dataset[0][0].size, dataset[0][0].shape)\n",
    "print(\"dataset.y_train:\",type(dataset[0][1]), dataset[0][1].size,dataset[0][1].shape)\n",
    "display( dataset[0][1][:5])\n",
    "\n",
    "print(\"dataset.x_test:\",type(dataset[1][0]), dataset[1][0].size, dataset[1][0].shape)\n",
    "print(\"dataset.y_test:\",type(dataset[1][1]), dataset[1][1].size, dataset[1][1].shape)\n",
    "display( dataset[1][1][:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparing 10.8m events dataset with 1k dataset entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Preprocessor\n",
      "Directory /wsu/home/gy/gy40/gy4065/hm_jetscapeml_source/models/default_simulation_name already exists.\n",
      "Directory /wsu/home/gy/gy40/gy4065/hm_jetscapeml_source/reports/default_simulation_name already exists.\n",
      "Directory /wsu/home/gy/gy40/gy4065/hm_jetscapeml_source/reports/figures/default_simulation_name already exists.\n",
      "Loading the whole dataset\n",
      "dataset.x: <class 'numpy.ndarray'> 1024000 (1000, 32, 32)\n",
      "dataset.y: <class 'numpy.ndarray'> 3000 (1000, 3)\n"
     ]
    }
   ],
   "source": [
    "import jet_ml.dataset as ds \n",
    "dataset_size= 1000 #1000000\n",
    "(x, y)=ds.load_dataset(size=dataset_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I want to compare that each row in (x, y) is equal to first 1000 rows of ( dataset[0][0], dataset[0][1])\n",
    "def find_one_to_one_entry_comparison(x,y, dataset_x, dataset_y):\n",
    "    comparison_results = []\n",
    "    \n",
    "    for i in range(len(y)):\n",
    "        if ((y[i] == dataset_y[i]).all()) and ((x[i] == dataset_x[i]).all()):\n",
    "            comparison_results.append(True)\n",
    "        else:\n",
    "            comparison_results.append(False)\n",
    "    \n",
    "    return comparison_results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "comparison_results = find_one_to_one_entry_comparison(x,y, dataset[0][0], dataset[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[True, True, True, True, True]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(comparison_results[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total count of True in check_list: 1000\n"
     ]
    }
   ],
   "source": [
    "# count number of True in check_list\n",
    "def check_truthtable(check_list):\n",
    "    count=0\n",
    "    for i in range(len(check_list)):\n",
    "        if check_list[i]:\n",
    "            count+=1\n",
    "    return count\n",
    "count=check_truthtable(comparison_results)\n",
    "print(f\"Total count of True in check_list: {count}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow-gpu-v2.8]",
   "language": "python",
   "name": "conda-env-tensorflow-gpu-v2.8-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
