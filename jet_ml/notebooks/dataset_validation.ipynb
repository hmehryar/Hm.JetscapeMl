{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_namespace():\n",
    "    import sys\n",
    "    sys.path.insert(1,f'/wsu/home/gy/gy40/gy4065/hm.jetscapeml_source')#WSU Grid\n",
    "    sys.path.insert(1,'/content/drive/My Drive/Projects/110_JetscapeMl/hm_jetscapeml_source')#Colab GDrive v1\n",
    "    sys.path.insert(1,'/content/drive/MyDrive/Projects/110_JetscapeMl/hm_jetscapeml_source')#Colab GDrive v2\n",
    "    sys.path.insert(1,f'/mnt/g/My Drive/Projects/110_JetscapeMl/hm_jetscapeml_source')#wsl gdrive\n",
    "    sys.path.insert(1,'G:\\\\My Drive\\\\Projects\\\\110_JetscapeMl\\\\hm_jetscapeml_source') #Windows GDrive\n",
    "    sys.path.insert(1,'/home/arsalan/Projects/110_JetscapeML/hm_jetscapeml_source/') #office tower\n",
    "    \n",
    "load_namespace()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Preprocessor\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-19 17:20:19.337414: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-09-19 17:20:19.506527: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-09-19 17:20:19.567133: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-09-19 17:20:19.584848: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-09-19 17:20:19.694576: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-09-19 17:20:20.635764: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory /home/arsalan/Projects/110_JetscapeML/hm_jetscapeml_source/models/default_simulation_name already exists.\n",
      "Directory /home/arsalan/Projects/110_JetscapeML/hm_jetscapeml_source/reports/default_simulation_name already exists.\n",
      "Directory /home/arsalan/Projects/110_JetscapeML/hm_jetscapeml_source/reports/figures/default_simulation_name already exists.\n",
      "Loading the whole dataset\n",
      "dataset.x: <class 'numpy.ndarray'> 1024000 (1000, 32, 32)\n",
      "dataset.y: <class 'numpy.ndarray'> 3000 (1000, 3)\n"
     ]
    }
   ],
   "source": [
    "dataset_size = 1000\n",
    "import jet_ml.dataset as ds\n",
    "(x, y)=ds.load_dataset(size=dataset_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#implement a method to get one entry of the dataset into a tuple\n",
    "def display_entry(entry):\n",
    "    print(f'x: {entry[0]}')\n",
    "    print(f'y: {entry[1]}')\n",
    "def get_one_entry(x, y, index):\n",
    "    return x[index], y[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array(['MLBT', '0.4', '2.5'], dtype='<U32'),\n",
       " array(['MLBT', '0.4', '2.5'], dtype='<U32'),\n",
       " array(['MLBT', '0.4', '2.5'], dtype='<U32'),\n",
       " array(['MLBT', '0.4', '2.5'], dtype='<U32'),\n",
       " array(['MLBT', '0.4', '2.5'], dtype='<U32'),\n",
       " array(['MLBT', '0.4', '2.5'], dtype='<U32'),\n",
       " array(['MLBT', '0.4', '2.5'], dtype='<U32'),\n",
       " array(['MLBT', '0.4', '2.5'], dtype='<U32'),\n",
       " array(['MLBT', '0.4', '2.5'], dtype='<U32'),\n",
       " array(['MLBT', '0.4', '2.5'], dtype='<U32'),\n",
       " array(['MLBT', '0.4', '2.5'], dtype='<U32'),\n",
       " array(['MLBT', '0.4', '2.5'], dtype='<U32'),\n",
       " array(['MLBT', '0.4', '2.5'], dtype='<U32'),\n",
       " array(['MLBT', '0.4', '2.5'], dtype='<U32'),\n",
       " array(['MLBT', '0.4', '2.5'], dtype='<U32'),\n",
       " array(['MLBT', '0.4', '2.5'], dtype='<U32'),\n",
       " array(['MLBT', '0.4', '2.5'], dtype='<U32'),\n",
       " array(['MLBT', '0.4', '2.5'], dtype='<U32'),\n",
       " array(['MLBT', '0.4', '2.5'], dtype='<U32'),\n",
       " array(['MLBT', '0.4', '2.5'], dtype='<U32'),\n",
       " array(['MLBT', '0.4', '2.5'], dtype='<U32'),\n",
       " array(['MLBT', '0.4', '2.5'], dtype='<U32'),\n",
       " array(['MLBT', '0.4', '2.5'], dtype='<U32'),\n",
       " array(['MLBT', '0.4', '2.5'], dtype='<U32'),\n",
       " array(['MLBT', '0.4', '2.5'], dtype='<U32'),\n",
       " array(['MLBT', '0.4', '2.5'], dtype='<U32'),\n",
       " array(['MLBT', '0.4', '2.5'], dtype='<U32'),\n",
       " array(['MLBT', '0.4', '2.5'], dtype='<U32'),\n",
       " array(['MLBT', '0.4', '2.5'], dtype='<U32'),\n",
       " array(['MLBT', '0.4', '2.5'], dtype='<U32'),\n",
       " array(['MLBT', '0.4', '2.5'], dtype='<U32'),\n",
       " array(['MLBT', '0.4', '2.5'], dtype='<U32'),\n",
       " array(['MLBT', '0.4', '2.5'], dtype='<U32'),\n",
       " array(['MLBT', '0.4', '2.5'], dtype='<U32'),\n",
       " array(['MLBT', '0.4', '2.5'], dtype='<U32'),\n",
       " array(['MLBT', '0.4', '2.5'], dtype='<U32'),\n",
       " array(['MLBT', '0.4', '2.5'], dtype='<U32'),\n",
       " array(['MLBT', '0.4', '2.5'], dtype='<U32'),\n",
       " array(['MLBT', '0.4', '2.5'], dtype='<U32'),\n",
       " array(['MLBT', '0.4', '2.5'], dtype='<U32'),\n",
       " array(['MLBT', '0.4', '2.5'], dtype='<U32'),\n",
       " array(['MLBT', '0.4', '2.5'], dtype='<U32'),\n",
       " array(['MLBT', '0.4', '2.5'], dtype='<U32'),\n",
       " array(['MLBT', '0.4', '2.5'], dtype='<U32'),\n",
       " array(['MLBT', '0.4', '2.5'], dtype='<U32'),\n",
       " array(['MLBT', '0.4', '2.5'], dtype='<U32'),\n",
       " array(['MLBT', '0.4', '2.5'], dtype='<U32'),\n",
       " array(['MLBT', '0.4', '2.5'], dtype='<U32'),\n",
       " array(['MLBT', '0.4', '2.5'], dtype='<U32'),\n",
       " array(['MLBT', '0.4', '2.5'], dtype='<U32'),\n",
       " array(['MLBT', '0.4', '2.5'], dtype='<U32'),\n",
       " array(['MLBT', '0.4', '2.5'], dtype='<U32'),\n",
       " array(['MLBT', '0.4', '2.5'], dtype='<U32'),\n",
       " array(['MLBT', '0.4', '2.5'], dtype='<U32'),\n",
       " array(['MLBT', '0.4', '2.5'], dtype='<U32'),\n",
       " array(['MLBT', '0.4', '2.5'], dtype='<U32'),\n",
       " array(['MLBT', '0.4', '2.5'], dtype='<U32'),\n",
       " array(['MLBT', '0.4', '2.5'], dtype='<U32'),\n",
       " array(['MLBT', '0.4', '2.5'], dtype='<U32')]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x: [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "y: ['MLBT' '0.4' '2.5']\n"
     ]
    }
   ],
   "source": [
    "# implement a method that filter the dataset based on the value of y and return the filtered dataset\n",
    "def filter_dataset(x, y, value):\n",
    "    x_filtered = []\n",
    "    y_filtered = []\n",
    "    for i in range(len(y)):\n",
    "\n",
    "        if (y[i] == value).all():\n",
    "            x_filtered.append(x[i])\n",
    "            y_filtered.append(y[i])\n",
    "    return x_filtered, y_filtered\n",
    "x_filtered, y_filtered = filter_dataset(x, y, value= ['MLBT' ,'0.4' ,'2.5'])\n",
    "display(y_filtered)\n",
    "entry = get_one_entry(x_filtered, y_filtered, 0)\n",
    "#get one entry of the dataset nad print it\n",
    "entry = get_one_entry(x, y, 0)\n",
    "display_entry(entry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#give me all permutations of     alpha_s_items=[0.2 ,0.3 ,0.4] , q0_items=[1.5 ,2.0 ,2.5] and assign a unique id to each permutation\n",
    "import itertools\n",
    "def get_permutations(alpha_s_items, q0_items):\n",
    "    permutations = list(itertools.product( q0_items,alpha_s_items))\n",
    "    permutation_ids = [i+1 for i in range(len(permutations))]\n",
    "    return permutations, permutation_ids\n",
    "alpha_s_items=[0.2 ,0.3 ,0.4]\n",
    "q0_items=[1.5 ,2.0 ,2.5]\n",
    "permutations, permutation_ids = get_permutations(alpha_s_items, q0_items)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#implment a method that take a 'alpha_s' and 'q0' parameter and build an string like this 'config_01_alpha_0.2_q0_1.5_MMAT_MLBT_size_1200000_shuffled.pkl' and look for the file in the dataset folder and load it\n",
    "def load_dataset(alpha_s, q0):\n",
    "#find permutation id from alpha_s and q0 and build the file Name\n",
    "    dataset_size = 1200000\n",
    "    permutation_id = permutation_ids[permutations.index((q0,alpha_s))]\n",
    "    file_name = f'config_0{permutation_id}_alpha_{alpha_s}_q0_{q0}_MMAT_MLBT_size_{dataset_size}_shuffled.pkl'\n",
    "    print(file_name)\n",
    "    #load the file\n",
    "    import os\n",
    "    import pandas as pd\n",
    "    file_path = f'/home/arsalan/Projects/110_JetscapeML/hm_jetscapeml_source/data/dataset_raw/{file_name}'\n",
    "    if os.path.exists(file_path):\n",
    "        print('file found')\n",
    "        return pd.read_pickle(file_path)\n",
    "    else:\n",
    "        print('file not found')\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x: [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "y: ['MLBT' '0.4' '2.5']\n"
     ]
    }
   ],
   "source": [
    "display_entry(entry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha_s: 0.4\n",
      "q0: 2.5\n",
      "config_09_alpha_0.4_q0_2.5_MMAT_MLBT_size_1200000_shuffled.pkl\n",
      "file found\n"
     ]
    }
   ],
   "source": [
    "# give me a method that uses the entry y side and from index 1 extracts alpha_s and index 2 extracts q0 and then uses the alpha_s and q0 to load the dataset\n",
    "def get_dataset(entry):\n",
    "    alpha_s = float(entry[1][1])\n",
    "    q0 = float(entry[1][2])\n",
    "    \n",
    "    # log alpha_s and q0\n",
    "    print(f'alpha_s: {alpha_s}')\n",
    "    print(f'q0: {q0}')\n",
    "    dataset=load_dataset(alpha_s, q0)\n",
    "    x_train = dataset['x_train']\n",
    "    y_train = dataset['y_train']\n",
    "    # x_train=x_train[540000:]\n",
    "    # y_train=y_train[540000:]\n",
    "    return  x_train, y_train\n",
    "\n",
    "#should load the file 'config_1_alpha_0.2_q0_1.5_MMAT_MLBT_size_1000_shuffled.pkl'\n",
    "# dataset has this structure  merged_dataset = {\n",
    "#         'x_train': x_train,\n",
    "#         'x_test': x_test,\n",
    "#         'y_train': y_train,\n",
    "#         'y_test': y_test\n",
    "#     }\n",
    "#implement a method that takes the dataset and filter x_train and y_train that matches the entry x and y\n",
    "x_train,y_train= get_dataset(entry) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_entry_in_dataset(x_train,y_train, x, y):\n",
    "    \n",
    "    x_filtered = x_train[x_train == x]\n",
    "    y_filtered = y_train[y_train == y]\n",
    "    return x_filtered, y_filtered\n",
    "x_filtered, y_filtered = find_entry_in_dataset(x_train,y_train, entry[0], entry[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1080000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([['MLBT', '0.4', '2.5'],\n",
       "       ['MMAT', '0.4', '1']], dtype='<U32')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(array([['MLBT', '0.4', '2.5'],\n",
       "        ['MMAT', '0.4', '1']], dtype='<U32'),\n",
       " array([540000, 540000]))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(len(y_train))\n",
    "import numpy as np\n",
    "# print all unique vectors in y_train\n",
    "display(np.unique(y_train, axis=0))\n",
    "# print the number of each unique vectors in y_train\n",
    "display(np.unique(y_train, return_counts=True, axis=0))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find all the y_train that has the value of entry[1]\n",
    "def find_entry_in_dataset(x_train,y_train, entry):\n",
    "    x_filtered = []\n",
    "    y_filtered = []\n",
    "    for i in range(len(y_train)):\n",
    "        if ((y_train[i] == entry[1]).all()) and ((x_train[i] == entry[0]).all()):\n",
    "            x_filtered.append(x_train[i])\n",
    "            y_filtered.append(y_train[i])\n",
    "    if (len(x_filtered) and len(y_filtered)):\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "\n",
    "entry_found = find_entry_in_dataset(x_train,y_train, entry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "print (entry_found)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.12.4 (tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
