{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\ProgramData\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "2.15.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print (tf.__version__)\n",
    "from tensorflow import keras\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')\n",
    "import sys\n",
    "sys.path.insert(1,'/wsu/home/gy/gy40/gy4065/hm.jetscapeml.source')\n",
    "sys.path.insert(1,'/content/drive/My Drive/Projects/110_JetscapeMl/hm.jetscapeml.source')\n",
    "sys.path.insert(1,'/g/My Drive/Projects/110_JetscapeMl/hm.jetscapeml.source')\n",
    "sys.path.insert(1,'G:\\\\My Drive\\\\Projects\\\\110_JetscapeMl\\\\hm.jetscapeml.source')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading/Installing Package => Begin\n",
      "\n",
      "\n",
      "\n",
      "Loading/Installing Package => End\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Loading/Installing Package => Begin\\n\\n')\n",
    "import jet_ml_dataset_builder.jet_ml_dataset_builder_utilities as util\n",
    "from jet_ml_dataset_builder.jet_ml_dataset_builder_utilities import set_directory_paths\n",
    "from jet_ml_dataset_builder.jet_ml_dataset_builder_utilities import parse_parameters\n",
    "from jet_ml_dataset_builder.jet_ml_dataset_builder_utilities import load_dataset\n",
    "from jet_ml_dataset_builder.jet_ml_dataset_builder_utilities import install\n",
    "# install(\"trimesh\")\n",
    "import os\n",
    "from time import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, History\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, KFold\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "import json\n",
    "\n",
    "\n",
    "tf.random.set_seed(1234)\n",
    "print('\\nLoading/Installing Package => End\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "########################################################################\n",
      "Checking the running platforms\n",
      "\n",
      "Python version: 3.11.5\n",
      "OS: Windows\n",
      "OS version: 10\n",
      "running on Colab: False\n",
      "Dataset Directory Path: G:\\My Drive\\Projects\\110_JetscapeMl\\hm.jetscapeml.data\\\n",
      "Simulation Results Path: G:\\My Drive\\Projects\\110_JetscapeMl\\hm.jetscapeml.data\\simulation_results\\\n",
      "Dataset Directory Path: G:\\My Drive\\Projects\\110_JetscapeMl\\hm.jetscapeml.data\\\n",
      "Simulation Directory Path: G:\\My Drive\\Projects\\110_JetscapeMl\\hm.jetscapeml.data\\simulation_results\\\n",
      "########################################################################\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('\\n########################################################################')\n",
    "print('Checking the running platforms\\n')\n",
    "\n",
    "# Call the function and retrieve the dataset_directory_path and simulation_directory_path\n",
    "dataset_directory_path, simulation_directory_path = set_directory_paths()\n",
    "\n",
    "# Access the dataset_directory_path and simulation_directory_path\n",
    "print(\"Dataset Directory Path:\", dataset_directory_path)\n",
    "print(\"Simulation Directory Path:\", simulation_directory_path)\n",
    "print('########################################################################\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "option --f not recognized\n",
      "Tokenized Arguments:\n",
      "\n",
      "Tokenized Values:\n",
      "y_class_label_items: ['MMAT', 'MLBT']\n",
      "alpha_s_items: [0.2, 0.3, 0.4]\n",
      "q0_items: [1.5, 2.0, 2.5]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Call the function and retrieve the tokenized parameters\n",
    "tokenized_arguments, tokenized_values = parse_parameters()\n",
    "\n",
    "# Access the tokenized arguments and values\n",
    "print(\"Tokenized Arguments:\")\n",
    "for argument in tokenized_arguments:\n",
    "    print(argument)\n",
    "\n",
    "print(\"\\nTokenized Values:\")\n",
    "for argument, value in tokenized_values.items():\n",
    "    print(f\"{argument}: {value}\")\n",
    "\n",
    "y_class_label_items=['MMAT','MLBT']\n",
    "alpha_s_items=[0.2 ,0.3 ,0.4]\n",
    "q0_items=[1.5 ,2.0 ,2.5]\n",
    "\n",
    "print(\"y_class_label_items:\",y_class_label_items)\n",
    "print(\"alpha_s_items:\",alpha_s_items)\n",
    "print(\"q0_items:\",q0_items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building required params for the loading the dataset file\n"
     ]
    }
   ],
   "source": [
    "print(\"Building required params for the loading the dataset file\")\n",
    "\n",
    "class_labels_str = '_'.join(y_class_label_items)\n",
    "alpha_s_items_str='_'.join(map(str, alpha_s_items))\n",
    "q0_items_str='_'.join(map(str, q0_items))\n",
    "total_size=9*1200000\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading dataset by size and getting just the first column\n",
    "# Function to load datasets of different sizes\n",
    "def get_dataset(size,filter_y_by_column_number=None):\n",
    "    dataset_file_name = f\"jet_ml_benchmark_config_01_to_09_alpha_{alpha_s_items_str}_q0_{q0_items_str}_{class_labels_str}_size_{size}_shuffled.pkl\"\n",
    "\n",
    "    dataset_file_name=simulation_directory_path+dataset_file_name\n",
    "    print(\"dataset_file_name:\",dataset_file_name)\n",
    "\n",
    "    dataset=load_dataset(dataset_file_name,has_test=False)\n",
    "    (dataset_x, dataset_y) = dataset\n",
    "    if filter_y_by_column_number !=None:\n",
    "        print('Extract the first column for binary classification')\n",
    "        dataset_y = dataset_y[:, filter_y_by_column_number]\n",
    "    print(\"dataset.x:\",type(dataset_x), dataset_x.size, dataset_x.shape)\n",
    "    print(\"dataset.y:\",type(dataset_y), dataset_y.size,dataset_y.shape)\n",
    "    return dataset_x, dataset_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "G:\\My Drive\\Projects\\110_JetscapeMl\\hm.jetscapeml.data\\simulation_results\\\n"
     ]
    }
   ],
   "source": [
    "# Sizes of datasets\n",
    "dataset_sizes = [1000]\n",
    "# dataset_sizes = [100000]\n",
    "# dataset_sizes = [1000000]\n",
    "# dataset_sizes = [1000, 10000]\n",
    "#dataset_sizes = [1000, 10000,100000]\n",
    "# dataset_sizes = [1000, 10000, 100000, 1000000]\n",
    "\n",
    "print(simulation_directory_path)\n",
    "simulation_path=f'{simulation_directory_path}jetml_pointnet_classification_eloss_{class_labels_str}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "G:\\My Drive\\Projects\\110_JetscapeMl\\hm.jetscapeml.data\\simulation_results\\jetml_pointnet_classification_eloss_MMAT_MLBT_size_1000\n",
      "dataset_file_name: G:\\My Drive\\Projects\\110_JetscapeMl\\hm.jetscapeml.data\\simulation_results\\jet_ml_benchmark_config_01_to_09_alpha_0.2_0.3_0.4_q0_1.5_2.0_2.5_MMAT_MLBT_size_1000_shuffled.pkl\n",
      "dataset.x: <class 'numpy.ndarray'> 1024000 (1000, 32, 32)\n",
      "dataset.y: <class 'numpy.ndarray'> 3000 (1000, 3)\n",
      "dataset.x: <class 'numpy.ndarray'> 1024000 (1000, 32, 32)\n",
      "dataset.y: <class 'numpy.ndarray'> 3000 (1000, 3)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "size=1000\n",
    "current_simulation_name=f'_size_{size}'\n",
    "current_simulation_path=simulation_path+current_simulation_name\n",
    "print(current_simulation_path)\n",
    "# Generate dataset\n",
    "# x, y = get_dataset(size)\n",
    "(dataset_x, dataset_y)= get_dataset(size)\n",
    "len(dataset_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32, 32)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_x.shape\n",
    "dataset_x[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['MLBT', '0.4', '2.5'], dtype='<U32')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAaMAAAGkCAYAAACckEpMAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8pXeV/AAAACXBIWXMAAA9hAAAPYQGoP6dpAAAdVUlEQVR4nO3db2xUZd7/8c/0DyPidLJdaGdmqf01iu4qSrLiQhuVwob+7C9LUHYT1MSUuGtEgaSpBhd9YLMPKGIkmnRls+6GlawGHqyo+YlKN9CyhGVTDMTeaAzGutTY2a5d7NSKU9pe94O9mXuH8qenncN3Zvp+JScy51yd+V69wE+uOedcJ+CccwIAwFCBdQEAABBGAABzhBEAwBxhBAAwRxgBAMwRRgAAc4QRAMAcYQQAMEcYAQDMEUYAAHM5E0YvvfSSqqqqdNVVV+m2227TX/7yF+uSMqq5uVmBQCBti0Qi1mVN2cGDB7VixQrFYjEFAgG98cYbacedc2publYsFtPMmTNVW1urEydO2BQ7BZfr55o1a8aN7+LFi22KnYKWlhbdfvvtCoVCKisr0z333KOPP/44rU0+jOlE+pkPY7p9+3bdeuutKikpUUlJiaqrq/XOO++kjl/JscyJMNq9e7caGxv19NNP69ixY7rzzjtVX1+vU6dOWZeWUTfffLN6e3tTW1dXl3VJUzY0NKQFCxaotbX1gse3bt2qbdu2qbW1VZ2dnYpEIlq+fLkGBwevcKVTc7l+StLdd9+dNr579+69ghVmRkdHh9atW6cjR46ora1NIyMjqqur09DQUKpNPozpRPop5f6Yzp07V1u2bNHRo0d19OhRLVu2TCtXrkwFzhUdS5cDfvSjH7m1a9em7fv+97/vfvnLXxpVlHnPPPOMW7BggXUZvpLk9uzZk3o9NjbmIpGI27JlS2rft99+68LhsPvNb35jUGFmnN9P55xraGhwK1euNKnHT319fU6S6+jocM7l75ie30/n8ndMv/Od77jf/e53V3wss35mNDw8rPfff191dXVp++vq6nT48GGjqvxx8uRJxWIxVVVV6b777tOnn35qXZKvuru7FY/H08Y2GAxqyZIleTe2ktTe3q6ysjLdcMMNevjhh9XX12dd0pQNDAxIkkpLSyXl75ie389z8mlMR0dHtWvXLg0NDam6uvqKj2XWh9GXX36p0dFRlZeXp+0vLy9XPB43qirzFi1apJ07d+q9997Tyy+/rHg8rpqaGvX391uX5ptz45fvYytJ9fX1evXVV7V//349//zz6uzs1LJly5RMJq1LmzTnnJqamnTHHXdo/vz5kvJzTC/UTyl/xrSrq0vXXHONgsGg1q5dqz179uimm2664mNZlPF39EkgEEh77Zwbty+X1dfXp/58yy23qLq6Wtddd51eeeUVNTU1GVbmv3wfW0lavXp16s/z58/XwoULVVlZqbffflurVq0yrGzy1q9frw8++ECHDh0adyyfxvRi/cyXMb3xxht1/PhxffXVV/rTn/6khoYGdXR0pI5fqbHM+pnR7NmzVVhYOC6J+/r6xiV2Ppk1a5ZuueUWnTx50roU35y7WnC6ja0kRaNRVVZW5uz4btiwQW+99ZYOHDiguXPnpvbn25herJ8XkqtjOmPGDF1//fVauHChWlpatGDBAr344otXfCyzPoxmzJih2267TW1tbWn729raVFNTY1SV/5LJpD766CNFo1HrUnxTVVWlSCSSNrbDw8Pq6OjI67GVpP7+fvX09OTc+DrntH79er3++uvav3+/qqqq0o7ny5herp8Xkqtjej7nnJLJ5JUfy4xfEuGDXbt2ueLiYvf73//effjhh66xsdHNmjXLffbZZ9alZczjjz/u2tvb3aeffuqOHDnifvKTn7hQKJTzfRwcHHTHjh1zx44dc5Lctm3b3LFjx9zf//5355xzW7ZsceFw2L3++uuuq6vL3X///S4ajbpEImFcuTeX6ufg4KB7/PHH3eHDh113d7c7cOCAq66udt/73vdyrp+PPvqoC4fDrr293fX29qa2b775JtUmH8b0cv3MlzHdtGmTO3jwoOvu7nYffPCBe+qpp1xBQYHbt2+fc+7KjmVOhJFzzv361792lZWVbsaMGe6HP/xh2iWW+WD16tUuGo264uJiF4vF3KpVq9yJEyesy5qyAwcOOEnjtoaGBufcvy8FfuaZZ1wkEnHBYNDdddddrqury7boSbhUP7/55htXV1fn5syZ44qLi921117rGhoa3KlTp6zL9uxCfZTkduzYkWqTD2N6uX7my5g+9NBDqf+vzpkzx/34xz9OBZFzV3YsA845l/n5FgAAE5f154wAAPmPMAIAmCOMAADmCCMAgDnCCABgjjACAJjLmTBKJpNqbm7OuUUIvZou/ZSmT1/pZ36hn/7ImfuMEomEwuGwBgYGVFJSYl2Ob6ZLP6Xp01f6mV/opz9yZmYEAMhfhBEAwFzWPc9obGxMX3zxhUKhUNozMxKJRNp/89V06ac0ffpKP/ML/Zw455wGBwcVi8VUUHDpuU/WnTP6/PPPVVFRYV0GACBDenp6Lvs8qKybGYVCIUnSHfp/KlKxcTXIdkVzY57aj3z+hU+VIFMCxTMm3NadHfaxEkzViM7qkPam/r9+Kb6F0UsvvaTnnntOvb29uvnmm/XCCy/ozjvvvOzPnftqrkjFKgoQRri0ooKgtx/g71TWC3gYIxfIqi92cL7/GZ6JPKbclwsYdu/ercbGRj399NM6duyY7rzzTtXX1+vUqVN+fBwAIMf5Ekbbtm3Tz3/+c/3iF7/QD37wA73wwguqqKjQ9u3b/fg4AECOy3gYDQ8P6/3331ddXV3a/rq6Oh0+fHhc+2QyqUQikbYBAKaXjIfRl19+qdHRUZWXl6ftLy8vVzweH9e+paVF4XA4tXElHQBMP77d9Hr+CSvn3AVPYm3atEkDAwOpraenx6+SAABZKuNX082ePVuFhYXjZkF9fX3jZkuSFAwGFQx6vCIKAJBXMj4zmjFjhm677Ta1tbWl7W9ra1NNTU2mPw4AkAd8uc+oqalJDz74oBYuXKjq6mr99re/1alTp7R27Vo/Pg4AkON8CaPVq1erv79fv/rVr9Tb26v58+dr7969qqys9OPjAAA5LuvWpjv3DI1arWQFBgA5w8syRtL0WMpoxJ1Vu96c0DOReIQEAMAcYQQAMEcYAQDMEUYAAHOEEQDAHGEEADBHGAEAzBFGAABzhBEAwBxhBAAw58vadAAw3UyH5X38xMwIAGCOMAIAmCOMAADmCCMAgDnCCABgjjACAJgjjAAA5ggjAIA5wggAYI4wAgCYI4wAAOZYmw4AMGGBoonHRsA5aWRibZkZAQDMEUYAAHOEEQDAHGEEADBHGAEAzBFGAABzhBEAwBxhBAAwRxgBAMwRRgAAcywHBACYMDcywfV9JDk38bbMjAAA5ggjAIA5wggAYI4wAgCYI4wAAOYIIwCAOcIIAGCOMAIAmCOMAADmCCMAgDnCCABgjrXpckigaOLD5WX9KGDaCAS8tXfOnzowDjMjAIC5jIdRc3OzAoFA2haJRDL9MQCAPOLL13Q333yz/vznP6deFxYW+vExAIA84UsYFRUVMRsCAEyYL+eMTp48qVgspqqqKt1333369NNPL9o2mUwqkUikbQCA6SXjYbRo0SLt3LlT7733nl5++WXF43HV1NSov7//gu1bWloUDodTW0VFRaZLAgBkuYBz/l67ODQ0pOuuu04bN25UU1PTuOPJZFLJZDL1OpFIqKKiQrVaqaJAsZ+l5Rwu7QamiEu7r6gRd1btelMDAwMqKSm5ZFvf7zOaNWuWbrnlFp08efKCx4PBoILBoN9lAACymO/3GSWTSX300UeKRqN+fxQAIEdlPIyeeOIJdXR0qLu7W3/729/0s5/9TIlEQg0NDZn+KABAnsj413Sff/657r//fn355ZeaM2eOFi9erCNHjqiysjLTHwUAyBMZD6Ndu3Zl+i3zVkEo5Kn92OCgT5UAOarA4w31Y6P+1IEpY206AIA5wggAYI4wAgCYI4wAAOYIIwCAOcIIAGCOMAIAmCOMAADmCCMAgDnCCABgzvdHSODiWN4HWcPLsjpuzNt7+/lMIJb3yRvMjAAA5ggjAIA5wggAYI4wAgCYI4wAAOYIIwCAOcIIAGCOMAIAmCOMAADmCCMAgDnCCABgjrXpALDGG8wxMwIAmCOMAADmCCMAgDnCCABgjjACAJgjjAAA5ggjAIA5wggAYI4wAgCYI4wAAOYIIwCAOdamA4wUfrfUU/vR/n/5VAlgj5kRAMAcYQQAMEcYAQDMEUYAAHOEEQDAHGEEADBHGAEAzBFGAABzhBEAwBxhBAAwx3JAgBFfl/cJBLy1d86fOoAJYmYEADDnOYwOHjyoFStWKBaLKRAI6I033kg77pxTc3OzYrGYZs6cqdraWp04cSJT9QIA8pDnMBoaGtKCBQvU2tp6weNbt27Vtm3b1Nraqs7OTkUiES1fvlyDg4NTLhYAkJ88nzOqr69XfX39BY855/TCCy/o6aef1qpVqyRJr7zyisrLy/Xaa6/pkUcemVq1AIC8lNFzRt3d3YrH46qrq0vtCwaDWrJkiQ4fPnzBn0kmk0okEmkbAGB6yWgYxeNxSVJ5eXna/vLy8tSx87W0tCgcDqe2ioqKTJYEAMgBvlxNFzjvslLn3Lh952zatEkDAwOpraenx4+SAABZLKP3GUUiEUn/niFFo9HU/r6+vnGzpXOCwaCCwWAmywAA5JiMzoyqqqoUiUTU1taW2jc8PKyOjg7V1NRk8qMAAHnE88zo66+/1ieffJJ63d3drePHj6u0tFTXXnutGhsbtXnzZs2bN0/z5s3T5s2bdfXVV+uBBx7IaOEAgPzhOYyOHj2qpUuXpl43NTVJkhoaGvSHP/xBGzdu1JkzZ/TYY4/p9OnTWrRokfbt26dQKJS5qgEAeSXgXHYtSpVIJBQOh1WrlSoKFFuXg+nOyxpv2fVPCTA34s6qXW9qYGBAJSUll2zL2nQAAHOEEQDAHGEEADBHGAEAzBFGAABzhBEAwBxhBAAwRxgBAMwRRgAAc4QRAMBcRh8hAeQdH5f4CXh8dEpB6JoJtx39st9rOYApZkYAAHOEEQDAHGEEADBHGAEAzBFGAABzhBEAwBxhBAAwRxgBAMwRRgAAc4QRAMAcYQQAMMfadIYKS0o8tR9NJHyqBBdT9H+unXDbkc9OeXpvl0x6aj/qsb1fCr9b6qn9aP+/fKrEf4HiGRNu684O+1hJ/mNmBAAwRxgBAMwRRgAAc4QRAMAcYQQAMEcYAQDMEUYAAHOEEQDAHGEEADBHGAEAzBFGAABzWbs2XcGsq1UQmNi6UGNDQz5X4w/WmrvyCkIhT+29rjfnReGN13tqP/rxJxNu62VNNcnbumq5vNacV6w3d+UwMwIAmCOMAADmCCMAgDnCCABgjjACAJgjjAAA5ggjAIA5wggAYI4wAgCYI4wAAOaydjmgsaFvNBY4a10G8szY4KCn9kUVcyfc9u2//X9P7/1/Y56ae+JGcvffjpclm7yOJ7IXMyMAgDnPYXTw4EGtWLFCsVhMgUBAb7zxRtrxNWvWKBAIpG2LFy/OVL0AgDzkOYyGhoa0YMECtba2XrTN3Xffrd7e3tS2d+/eKRUJAMhvns8Z1dfXq76+/pJtgsGgIpHIpIsCAEwvvpwzam9vV1lZmW644QY9/PDD6uvru2jbZDKpRCKRtgEAppeMh1F9fb1effVV7d+/X88//7w6Ozu1bNkyJZPJC7ZvaWlROBxObRUVFZkuCQCQ5TJ+affq1atTf54/f74WLlyoyspKvf3221q1atW49ps2bVJTU1PqdSKRIJAAYJrx/T6jaDSqyspKnTx58oLHg8GggsGg32UAALKY7/cZ9ff3q6enR9Fo1O+PAgDkKM8zo6+//lqffPJJ6nV3d7eOHz+u0tJSlZaWqrm5WT/96U8VjUb12Wef6amnntLs2bN17733ZrRwAED+8BxGR48e1dKlS1Ovz53vaWho0Pbt29XV1aWdO3fqq6++UjQa1dKlS7V7926FPCzxAQCYXgLOOWddxH9KJBIKh8Oq1UoVBYqty8kugcDE22bXsGYPL79DydPvMbBwvrdS/uuTyzf6D2PffuupvReFc+ZMuO3oP//pWx2+Kyj01LwwXDLhtqOnT3utJu+NuLNq15saGBhQScmlf5esTQcAMEcYAQDMEUYAAHOEEQDAHGEEADBHGAEAzBFGAABzhBEAwBxhBAAwRxgBAMwRRgAAc74/zwgZxHpzU1bodcHeiIc1247+l6e3zqbRzNX15gpmzfLUfmxoyFN71pu7cpgZAQDMEUYAAHOEEQDAHGEEADBHGAEAzBFGAABzhBEAwBxhBAAwRxgBAMwRRgAAcywHBP8FAt7a+7js0Wgi4e0HvLbPUQVXXTXhtmPffutjJd54Xd4H2YuZEQDAHGEEADBHGAEAzBFGAABzhBEAwBxhBAAwRxgBAMwRRgAAc4QRAMAcYQQAMEcYAQDMTbu16Yoi5Z7aj8T/4VMl00fBzJme2o99841PlWSXwu+Wemo/2v8vnyrJrvXmMD0xMwIAmCOMAADmCCMAgDnCCABgjjACAJgjjAAA5ggjAIA5wggAYI4wAgCYI4wAAOam3XJALO9z5Xle3icQmHhb57y9dxbxc3kfINcwMwIAmCOMAADmPIVRS0uLbr/9doVCIZWVlemee+7Rxx9/nNbGOafm5mbFYjHNnDlTtbW1OnHiREaLBgDkF09h1NHRoXXr1unIkSNqa2vTyMiI6urqNDQ0lGqzdetWbdu2Ta2trers7FQkEtHy5cs1ODiY8eIBAPkh4NzkzwD/85//VFlZmTo6OnTXXXfJOadYLKbGxkY9+eSTkqRkMqny8nI9++yzeuSRR8a9RzKZVDKZTL1OJBKqqKhQrVaqKFA82dKQy6bJBQxAvhtxZ9WuNzUwMKCSkpJLtp3SOaOBgQFJUmnpvx8S1t3drXg8rrq6ulSbYDCoJUuW6PDhwxd8j5aWFoXD4dRWUVExlZIAADlo0mHknFNTU5PuuOMOzZ8/X5IUj8clSeXl6U9TLS8vTx0736ZNmzQwMJDaenp6JlsSACBHTfo+o/Xr1+uDDz7QoUOHxh0LnPc1i3Nu3L5zgsGggsHgZMsAAOSBSc2MNmzYoLfeeksHDhzQ3LlzU/sjkYgkjZsF9fX1jZstAQBwjqcwcs5p/fr1ev3117V//35VVVWlHa+qqlIkElFbW1tq3/DwsDo6OlRTU5OZigEAecfT13Tr1q3Ta6+9pjfffFOhUCg1AwqHw5o5c6YCgYAaGxu1efNmzZs3T/PmzdPmzZt19dVX64EHHvClAwCA3OcpjLZv3y5Jqq2tTdu/Y8cOrVmzRpK0ceNGnTlzRo899phOnz6tRYsWad++fQqFQhkpGNMAl2tjogoKvbUfG/WnDkzZlO4z8kMikVA4HOY+IwCXRxhltSt2nxEAAJlAGAEAzBFGAABzhBEAwBxhBAAwRxgBAMwRRgAAc4QRAMAcYQQAMEcYAQDMTfp5RtkkUDxjwm3d2WEfK8keBbNmeWo/NjTkUyWAj1jeJ28wMwIAmCOMAADmCCMAgDnCCABgjjACAJgjjAAA5ggjAIA5wggAYI4wAgCYI4wAAObyYjmg6bLEjxcs7wMglzAzAgCYI4wAAOYIIwCAOcIIAGCOMAIAmCOMAADmCCMAgDnCCABgjjACAJgjjAAA5ggjAIC5vFibDsgGBVdd5an92Lff+lQJkHuYGQEAzBFGAABzhBEAwBxhBAAwRxgBAMwRRgAAc4QRAMAcYQQAMEcYAQDMEUYAAHOEEQDAHGvTARnCWnPA5DEzAgCY8xRGLS0tuv322xUKhVRWVqZ77rlHH3/8cVqbNWvWKBAIpG2LFy/OaNEAgPziKYw6Ojq0bt06HTlyRG1tbRoZGVFdXZ2GhobS2t19993q7e1NbXv37s1o0QCA/OLpnNG7776b9nrHjh0qKyvT+++/r7vuuiu1PxgMKhKJZKZCAEDem9I5o4GBAUlSaWlp2v729naVlZXphhtu0MMPP6y+vr6LvkcymVQikUjbAADTy6TDyDmnpqYm3XHHHZo/f35qf319vV599VXt379fzz//vDo7O7Vs2TIlk8kLvk9LS4vC4XBqq6iomGxJAIAcFXDOucn84Lp16/T222/r0KFDmjt37kXb9fb2qrKyUrt27dKqVavGHU8mk2lBlUgkVFFRoVqtVFGgeDKlAQCywIg7q3a9qYGBAZWUlFyy7aTuM9qwYYPeeustHTx48JJBJEnRaFSVlZU6efLkBY8Hg0EFg8HJlAEAyBOewsg5pw0bNmjPnj1qb29XVVXVZX+mv79fPT09ikajky4SAJDfPJ0zWrdunf74xz/qtddeUygUUjweVzwe15kzZyRJX3/9tZ544gn99a9/1Weffab29natWLFCs2fP1r333utLBwAAuc/TzGj79u2SpNra2rT9O3bs0Jo1a1RYWKiuri7t3LlTX331laLRqJYuXardu3crFAplrOh8ESjy9i2pGxmZ+Ht7/OrTXeQCEwC4Ejx/TXcpM2fO1HvvvTelggAA0w9r0wEAzBFGAABzhBEAwBxhBAAwRxgBAMwRRgAAc4QRAMAcYQQAMEcYAQDMEUYAAHOTeoQEMsPLWnOe35u15gDkEGZGAABzhBEAwBxhBAAwRxgBAMwRRgAAc4QRAMAcYQQAMEcYAQDMEUYAAHOEEQDAHGEEADBHGAEAzBFGAABzhBEAwBxhBAAwRxgBAMwRRgAAc4QRAMAcYQQAMEcYAQDMEUYAAHOEEQDAHGEEADBHGAEAzBFGAABzhBEAwBxhBAAwRxgBAMwRRgAAc4QRAMAcYQQAMEcYAQDMEUYAAHOEEQDAHGEEADBHGAEAzHkKo+3bt+vWW29VSUmJSkpKVF1drXfeeSd13Dmn5uZmxWIxzZw5U7W1tTpx4kTGiwYA5BdPYTR37lxt2bJFR48e1dGjR7Vs2TKtXLkyFThbt27Vtm3b1Nraqs7OTkUiES1fvlyDg4O+FA8AyA8B55ybyhuUlpbqueee00MPPaRYLKbGxkY9+eSTkqRkMqny8nI9++yzeuSRRyb0folEQuFwWLVaqaJA8VRKAwAYGnFn1a43NTAwoJKSkku2nfQ5o9HRUe3atUtDQ0Oqrq5Wd3e34vG46urqUm2CwaCWLFmiw4cPX/R9ksmkEolE2gYAmF48h1FXV5euueYaBYNBrV27Vnv27NFNN92keDwuSSovL09rX15enjp2IS0tLQqHw6mtoqLCa0kAgBznOYxuvPFGHT9+XEeOHNGjjz6qhoYGffjhh6njgUAgrb1zbty+/7Rp0yYNDAyktp6eHq8lAQByXJHXH5gxY4auv/56SdLChQvV2dmpF198MXWeKB6PKxqNptr39fWNmy39p2AwqGAw6LUMAEAemfJ9Rs45JZNJVVVVKRKJqK2tLXVseHhYHR0dqqmpmerHAADymKeZ0VNPPaX6+npVVFRocHBQu3btUnt7u959910FAgE1NjZq8+bNmjdvnubNm6fNmzfr6quv1gMPPOBX/QCAPOApjP7xj3/owQcfVG9vr8LhsG699Va9++67Wr58uSRp48aNOnPmjB577DGdPn1aixYt0r59+xQKhXwp/koIePgK0SWTPlaSXQLFMybc1p0d9rESAPlgyvcZZVq23WdEGF0YYQTgcq7IfUYAAGQKYQQAMEcYAQDMEUYAAHOEEQDAHGEEADBHGAEAzBFGAABzhBEAwJznVbv9dm5BiBGdlbJgbYiAm3heO3fWx0qyS8Bd/LEg55tOvxcA/2tE//63P5GFfrIujAYHByVJh7TXuJL/MX1W+PGGfAEwQYODgwqHw5dsk3Vr042NjemLL75QKBRKeyhfIpFQRUWFenp6LrvGUS6bLv2Upk9f6Wd+oZ8T55zT4OCgYrGYCgou/S1T1s2MCgoKNHfu3IseLykpyeu/AOdMl35K06ev9DO/0M+JudyM6BwuYAAAmCOMAADmciaMgsGgnnnmGQU9PF8oF02XfkrTp6/0M7/QT39k3QUMAIDpJ2dmRgCA/EUYAQDMEUYAAHOEEQDAHGEEADBHGAEAzBFGAABzhBEAwNx/A0XExRG+ENBfAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 480x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.matshow(dataset_x[0])\n",
    "dataset_y[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = \\\n",
    "        train_test_split(dataset_x, dataset_y, test_size=0.2, random_state=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_0_categorical = np.array(y_train[:,0]).reshape(-1, 1)\n",
    "y_test_0_categorical = np.array(y_test[:,0]).reshape(-1, 1)\n",
    "\n",
    "encoder = OneHotEncoder(sparse_output=False)\n",
    "y_train_0_categorical_encoded = encoder.fit_transform(y_train_0_categorical)\n",
    "y_test_0_categorical_encoded = encoder.transform(y_test_0_categorical)\n",
    "y_test_0_categorical_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.4, 2.5], dtype=float32)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert the second column of y to float32\n",
    "y_train_12 = y_train[:, 1:].astype(np.float32)\n",
    "y_test_12= y_test[:, 1:].astype(np.float32)\n",
    "type(y_train_12)\n",
    "y_train_12\n",
    "y_train_12[1,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "\n",
    "# Assuming 'input_shape' is the shape of each input in dataset.x (e.g., (32, 32))\n",
    "input_shape=(32,32)\n",
    "# Define the model for eloss prediction\n",
    "eloss_model = models.Sequential([\n",
    "    layers.Flatten(input_shape=input_shape),\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.Dense(32, activation='relu'),\n",
    "    layers.Dense(2, activation='sigmoid')  # Assuming two classes: 'MMAT' and 'MLBT'\n",
    "])\n",
    "\n",
    "# Compile the eloss model\n",
    "eloss_model.compile(optimizer='adam',\n",
    "                    loss='binary_crossentropy',\n",
    "                    metrics=['accuracy'])\n",
    "\n",
    "# Train the eloss model using dataset.x and the first column of dataset.y\n",
    "\n",
    "# Repeat the same process for alpha_s prediction\n",
    "alpha_s_model = models.Sequential([\n",
    "    layers.Flatten(input_shape=input_shape),\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.Dense(32, activation='relu'),\n",
    "    layers.Dense(3, activation='softmax')  # Assuming three classes: 0.2, 0.3, 0.4\n",
    "])\n",
    "\n",
    "alpha_s_model.compile(optimizer='adam',\n",
    "                      loss='sparse_categorical_crossentropy',\n",
    "                      metrics=['accuracy'])\n",
    "\n",
    "# # Train the alpha_s model using dataset.x and the second column of dataset.y\n",
    "\n",
    "# Repeat for the third column\n",
    "q_0_model = models.Sequential([\n",
    "    layers.Flatten(input_shape=input_shape),\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.Dense(32, activation='relu'),\n",
    "    layers.Dense(4, activation='softmax')  # Assuming four classes for the third column\n",
    "])\n",
    "\n",
    "q_0_model.compile(optimizer='adam',\n",
    "                           loss='sparse_categorical_crossentropy',\n",
    "                           metrics=['accuracy'])\n",
    "\n",
    "# # Train the third column model using dataset.x and the third column of dataset.y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "25/25 [==============================] - 1s 3ms/step - loss: 0.7510 - accuracy: 0.5200\n",
      "Epoch 2/10\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.5885 - accuracy: 0.7262\n",
      "Epoch 3/10\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.5039 - accuracy: 0.7900\n",
      "Epoch 4/10\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.4294 - accuracy: 0.8525\n",
      "Epoch 5/10\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.3654 - accuracy: 0.8875\n",
      "Epoch 6/10\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.2951 - accuracy: 0.9225\n",
      "Epoch 7/10\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.2350 - accuracy: 0.9450\n",
      "Epoch 8/10\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.1841 - accuracy: 0.9638\n",
      "Epoch 9/10\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.1435 - accuracy: 0.9775\n",
      "Epoch 10/10\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.1100 - accuracy: 0.9887\n",
      "Epoch 1/10\n",
      "25/25 [==============================] - 1s 3ms/step - loss: 0.4520 - accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0068 - accuracy: 0.0000e+00\n",
      "Epoch 3/10\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0022 - accuracy: 0.0000e+00\n",
      "Epoch 4/10\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0014 - accuracy: 0.0000e+00\n",
      "Epoch 5/10\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0011 - accuracy: 0.0000e+00\n",
      "Epoch 6/10\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 8.2427e-04 - accuracy: 0.0000e+00\n",
      "Epoch 7/10\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 6.6295e-04 - accuracy: 0.0000e+00\n",
      "Epoch 8/10\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 5.4184e-04 - accuracy: 0.0000e+00\n",
      "Epoch 9/10\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 4.5107e-04 - accuracy: 0.0000e+00\n",
      "Epoch 10/10\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 3.7977e-04 - accuracy: 0.0000e+00\n",
      "Epoch 1/10\n",
      "25/25 [==============================] - 1s 3ms/step - loss: 1.0009 - accuracy: 0.4350\n",
      "Epoch 2/10\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.5721 - accuracy: 0.5163\n",
      "Epoch 3/10\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.4529 - accuracy: 0.5775\n",
      "Epoch 4/10\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.3797 - accuracy: 0.6062\n",
      "Epoch 5/10\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.3178 - accuracy: 0.6363\n",
      "Epoch 6/10\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.2617 - accuracy: 0.6525\n",
      "Epoch 7/10\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.2092 - accuracy: 0.6675\n",
      "Epoch 8/10\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1625 - accuracy: 0.6762\n",
      "Epoch 9/10\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.1272 - accuracy: 0.6825\n",
      "Epoch 10/10\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0982 - accuracy: 0.6825\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x26086a1e150>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Assuming you have split your data into training and testing sets (X_train, X_test, y_train, y_test)\n",
    "\n",
    "# Train eloss model\n",
    "eloss_model.fit(x_train, y_train_0_categorical_encoded, epochs=10)\n",
    "# eloss_model.fit(x_train, y_train[:, 0], epochs=10, batch_size=32, validation_data=(x_test, y_test[:, 0]))\n",
    "\n",
    "# Train alpha_s model\n",
    "alpha_s_model.fit(x_train, y_train_12[:,0], epochs=10)\n",
    "\n",
    "# Train q_0 model\n",
    "q_0_model.fit(x_train, y_train_12[:, 1], epochs=10)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
