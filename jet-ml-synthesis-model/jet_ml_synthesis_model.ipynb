{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(1,'/wsu/home/gy/gy40/gy4065/hm.jetscapeml.source')\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Loading/Installing Package => Begin\\n\\n')\n",
    "\n",
    "import jet_ml_dataset_builder.jet_ml_dataset_builder_utilities as util\n",
    "\n",
    "print('\\n########################################################################')\n",
    "print('Checking the running platforms\\n')\n",
    "\n",
    "from jet_ml_dataset_builder.jet_ml_dataset_builder_utilities import set_directory_paths\n",
    "# Call the function and retrieve the dataset_directory_path and simulation_directory_path\n",
    "dataset_directory_path, simulation_directory_path = set_directory_paths()\n",
    "\n",
    "# Access the dataset_directory_path and simulation_directory_path\n",
    "print(\"Dataset Directory Path:\", dataset_directory_path)\n",
    "print(\"Simulation Directory Path:\", simulation_directory_path)\n",
    "print('########################################################################\\n')\n",
    "\n",
    "\n",
    "print('\\nLoading/Installing Package => End\\n\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from jet_ml_dataset_builder.jet_ml_dataset_builder_utilities import  parse_parameters\n",
    "\n",
    "# Call the function and retrieve the tokenized parameters\n",
    "tokenized_arguments, tokenized_values = parse_parameters()\n",
    "\n",
    "# Access the tokenized arguments and values\n",
    "print(\"Tokenized Arguments:\")\n",
    "for argument in tokenized_arguments:\n",
    "    print(argument)\n",
    "\n",
    "print(\"\\nTokenized Values:\")\n",
    "for argument, value in tokenized_values.items():\n",
    "    print(f\"{argument}: {value}\")\n",
    "\n",
    "y_class_label_items=['MMAT','MLBT']\n",
    "alpha_s_items=[0.2 ,0.3 ,0.4]\n",
    "q0_items=[1.5 ,2.0 ,2.5]\n",
    "\n",
    "print(\"y_class_label_items:\",y_class_label_items)\n",
    "print(\"alpha_s_items:\",alpha_s_items)\n",
    "print(\"q0_items:\",q0_items)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading the dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Building required params for the loading the dataset file\")\n",
    "\n",
    "class_labels_str = '_'.join(y_class_label_items)\n",
    "alpha_s_items_str='_'.join(map(str, alpha_s_items))\n",
    "q0_items_str='_'.join(map(str, q0_items))\n",
    "total_size=9*1200000\n",
    "# for shuffled_y_processed\n",
    "# dataset_file_name = f\"jet_ml_benchmark_config_01_to_09_alpha_{alpha_s_items_str}_q0_{q0_items_str}_{class_labels_str}_size_{total_size}_split_train_datasets/train_split_0.pkl\"\n",
    "# for shuffled\n",
    "dataset_file_name = f\"jet_ml_benchmark_config_01_to_09_alpha_{alpha_s_items_str}_q0_{q0_items_str}_{class_labels_str}_size_{1000}_shuffled.pkl\"\n",
    "# dataset_file_name = f\"jet_ml_benchmark_config_01_to_09_alpha_{alpha_s_items_str}_q0_{q0_items_str}_{class_labels_str}_size_{10000}_shuffled.pkl\"\n",
    "# dataset_file_name = f\"jet_ml_benchmark_config_01_to_09_alpha_{alpha_s_items_str}_q0_{q0_items_str}_{class_labels_str}_size_{100000}_shuffled.pkl\"\n",
    "# dataset_file_name = f\"jet_ml_benchmark_config_01_to_09_alpha_{alpha_s_items_str}_q0_{q0_items_str}_{class_labels_str}_size_{1000000}_shuffled.pkl\"\n",
    "# dataset_file_name = f\"jet_ml_benchmark_config_01_to_09_alpha_{alpha_s_items_str}_q0_{q0_items_str}_{class_labels_str}_size_{total_size}_shuffled.pkl\"\n",
    "\n",
    "dataset_file_name=simulation_directory_path+dataset_file_name\n",
    "print(\"dataset_file_name:\",dataset_file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The first column of `dataset_y` is extracted (`dataset_y_binary`) for binary classification.\n",
    "- The dataset is split into training and testing sets using `train_test_split`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "implementing k-fold for the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading dataset by size and getting just the first column\n",
    "\n",
    "from jet_ml_dataset_builder.jet_ml_dataset_builder_utilities import load_dataset\n",
    "# Function to load datasets of different sizes\n",
    "def get_dataset(size):\n",
    "    dataset_file_name = f\"jet_ml_benchmark_config_01_to_09_alpha_{alpha_s_items_str}_q0_{q0_items_str}_{class_labels_str}_size_{size}_shuffled.pkl\"\n",
    "    \n",
    "    dataset_file_name=simulation_directory_path+dataset_file_name\n",
    "    print(\"dataset_file_name:\",dataset_file_name)\n",
    "    \n",
    "    dataset=load_dataset(dataset_file_name,has_test=False)\n",
    "    (dataset_x, dataset_y) = dataset\n",
    "    # Extract the first column for binary classification\n",
    "    dataset_y = dataset_y[:, 0]\n",
    "    print(\"dataset.x:\",type(dataset_x), dataset_x.size, dataset_x.shape)\n",
    "    print(\"dataset.y:\",type(dataset_y), dataset_y.size,dataset_y.shape)\n",
    "    return dataset_x, dataset_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining dataset sizes and classifiers\n",
    "\n",
    "# Sizes of datasets\n",
    "# dataset_sizes = [1000]\n",
    "# dataset_sizes = [1000, 10000]\n",
    "dataset_sizes = [1000, 10000, 100000, 1000000]\n",
    "\n",
    "\n",
    "# Classifiers\n",
    "classifiers = {\n",
    "    'Logistic Regression': LogisticRegression(max_iter=1000, random_state=42),\n",
    "    'Decision Tree': DecisionTreeClassifier(random_state=42),\n",
    "    'LinearSVC': LinearSVC(random_state=42),\n",
    "    'KNN': KNeighborsClassifier(),\n",
    "    'Random Forest': RandomForestClassifier(random_state=42)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to train and evaluate classifiers \n",
    "def train_and_evaluate_classifier(model, x_train, y_train, x_test, y_test):\n",
    "    # Assuming x and y are defined\n",
    "    # x should be a 2D array (e.g., (1000, 32*32))\n",
    "    # y should be a 2D array with three columns (e.g., (1000, 3))\n",
    "\n",
    "    # Flatten the 32x32 images to 1D arrays for LogisticRegression, DecisionTreeClassifier, LinearSVM, KNN, RandomForests\n",
    "    x_train_flatten = x_train.reshape(x_train.shape[0], -1)\n",
    "    x_test_flatten = x_test.reshape(x_test.shape[0], -1)\n",
    "    model.fit(x_train_flatten, y_train)\n",
    "    y_pred = model.predict(x_test_flatten)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    return accuracy, cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to train and evaluate classifiers using k-fold cross-validation and giving confusion matrix and accuracy as results\n",
    "def train_and_evaluate_classifier_kfold(model, x, y, k_fold=5):\n",
    "    x_flatten = x.reshape(x.shape[0], -1)\n",
    "    kf = KFold(n_splits=k_fold, shuffle=True, random_state=42)\n",
    "    \n",
    "    scores = []\n",
    "    confusion_matrices = []\n",
    "\n",
    "    for train_index, test_index in kf.split(x_flatten):\n",
    "        x_train, x_test = x_flatten[train_index], x_flatten[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "        model.fit(x_train, y_train)\n",
    "        y_pred = model.predict(x_test)\n",
    "\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "        scores.append(accuracy)\n",
    "        confusion_matrices.append(cm)\n",
    "\n",
    "    return scores, confusion_matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Results storage\n",
    "results_kfold = []\n",
    "results_kfold_errorbar=[]\n",
    "# Loop through different dataset sizes\n",
    "for size in dataset_sizes:\n",
    "    # Generate dataset\n",
    "    x, y = get_dataset(size)\n",
    "    \n",
    "    # Loop through classifiers\n",
    "    for clf_name, clf in classifiers.items():\n",
    "        # Evaluate classifier using k-fold cross-validation\n",
    "        fold_scores, fold_conf_matrices = train_and_evaluate_classifier_kfold(clf, x, y)\n",
    "        \n",
    "        # Store results for each fold\n",
    "        for fold_num, (score, cm) in enumerate(zip(fold_scores, fold_conf_matrices), start=1):\n",
    "            results_kfold.append({\n",
    "                'Dataset Size': size,\n",
    "                'Classifier': clf_name,\n",
    "                'Fold Number': fold_num,\n",
    "                'Accuracy': score,\n",
    "                'Confusion Matrix': cm\n",
    "            })\n",
    "        # Calculate mean and standard deviation of accuracy scores\n",
    "        mean_accuracy = np.mean(fold_scores)\n",
    "        std_accuracy = np.std(fold_scores)\n",
    "        \n",
    "        # Store results\n",
    "        results_kfold_errorbar.append({\n",
    "            'Dataset_Size': size,\n",
    "            'Classifier': clf_name,\n",
    "            'Mean_Accuracy': mean_accuracy,\n",
    "            'Std_Accuracy': std_accuracy\n",
    "        })\n",
    "# Create a DataFrame from k-fold results\n",
    "df_results_kfold = pd.DataFrame(results_kfold)\n",
    "# Save the DataFrame to a text file\n",
    "df_results_kfold.to_csv('binary_classification_results_kfold.txt', index=False, sep='\\t')\n",
    "# Display results in a table\n",
    "print(df_results_kfold)\n",
    "\n",
    "# Create a DataFrame from k-fold results\n",
    "df_results_kfold_errorbar = pd.DataFrame(results_kfold_errorbar)\n",
    "# Save the DataFrame to a text file\n",
    "df_results_kfold_errorbar.to_csv('binary_classification_results_kfold_errorbar.txt', index=False, sep='\\t')\n",
    "# Display results in a table\n",
    "print(df_results_kfold_errorbar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the module labels\n",
    "module_labels = ['MMATTER', 'MLBT']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save confusion matrices for each fold\n",
    "for index, row in df_results_kfold.iterrows():\n",
    "    clf_name = row['Classifier']\n",
    "    dataset_size = row['Dataset Size']\n",
    "    fold_num = row['Fold Number']\n",
    "    cm = row['Confusion Matrix']\n",
    "\n",
    "    plt.figure()\n",
    "    plt.imshow(cm, interpolation='nearest', cmap='Oranges') # plt.cm.Blues\n",
    "\n",
    "    # Annotate each cell with the value\n",
    "    for i in range(len(module_labels)):\n",
    "        for j in range(len(module_labels)):\n",
    "            plt.text(j, i, str(cm[i, j]), ha='center', va='center', color='black')\n",
    "\n",
    "    plt.title(f'Confusion Matrix - {clf_name} - {dataset_size} samples - Fold {fold_num}')\n",
    "    plt.colorbar()\n",
    "    # Set tick labels\n",
    "    plt.xticks(np.arange(len(module_labels)), module_labels)\n",
    "    plt.yticks(np.arange(len(module_labels)), module_labels)\n",
    "\n",
    "    plt.xlabel('Predicted Label')\n",
    "    plt.ylabel('True Label')\n",
    "    # Remove tick marks\n",
    "    plt.tick_params(axis='both', which='both', bottom=False, top=False, left=False, right=False)\n",
    "    plt.savefig(f'confusion_matrix_{clf_name}_{dataset_size}_fold_{fold_num}.png', dpi=300)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "# Load the DataFrame from the saved file\n",
    "#df_results = pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/binary_classification_results_kfold_errorbar.txt\", sep='\\t')\n",
    "df_results= df_results_kfold_errorbar\n",
    "print(df_results)\n",
    "# Set a seaborn style (optional)\n",
    "sns.set(style=\"whitegrid\")\n",
    "\n",
    "\n",
    "# Define a dictionary to map classifiers to markers\n",
    "marker_dict = {\n",
    "    'Logistic Regression': 'o',\n",
    "    'Decision Tree': 's',\n",
    "    'LinearSVC': '^',\n",
    "    'KNN': 'v',\n",
    "    'Random Forest': 'D'\n",
    "}\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "for clf_name, group in df_results.groupby('Classifier'):\n",
    "    plt.errorbar(\n",
    "        group['Dataset_Size'],\n",
    "        group['Mean_Accuracy'],\n",
    "        yerr=group['Std_Accuracy'],\n",
    "        label=clf_name,\n",
    "        marker=marker_dict.get(clf_name, 'o'),  # Use 'o' as default marker if not found in the dictionary\n",
    "        capsize=5\n",
    "    )\n",
    "\n",
    "plt.xscale('log')  # Set x-axis to logarithmic scale\n",
    "plt.xlabel('Dataset Size (log scale)')\n",
    "plt.ylabel('Mean Accuracy')\n",
    "plt.title('Binary Classification Accuracy with Error Bars for Different Dataset Sizes')\n",
    "plt.legend()\n",
    "# plt.grid(True)\n",
    "# Save the plot with high resolution (300 dpi)\n",
    "plt.savefig('binary_classification_accuracy_errorbar_plot.png', dpi=300)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
