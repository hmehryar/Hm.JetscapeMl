{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\ProgramData\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "2.15.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print (tf.__version__)\n",
    "from tensorflow import keras\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')\n",
    "import sys\n",
    "sys.path.insert(1,'/wsu/home/gy/gy40/gy4065/hm.jetscapeml.source')\n",
    "sys.path.insert(1,'/content/drive/My Drive/Projects/110_JetscapeMl/hm.jetscapeml.source')\n",
    "sys.path.insert(1,'/g/My Drive/Projects/110_JetscapeMl/hm.jetscapeml.source')\n",
    "sys.path.insert(1,'G:\\\\My Drive\\\\Projects\\\\110_JetscapeMl\\\\hm.jetscapeml.source')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading/Installing Package => Begin\n",
      "\n",
      "\n",
      "\n",
      "Loading/Installing Package => End\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Loading/Installing Package => Begin\\n\\n')\n",
    "import jet_ml_dataset_builder.jet_ml_dataset_builder_utilities as util\n",
    "from jet_ml_dataset_builder.jet_ml_dataset_builder_utilities import set_directory_paths\n",
    "from jet_ml_dataset_builder.jet_ml_dataset_builder_utilities import parse_parameters\n",
    "from jet_ml_dataset_builder.jet_ml_dataset_builder_utilities import load_dataset\n",
    "from jet_ml_dataset_builder.jet_ml_dataset_builder_utilities import install\n",
    "# install(\"trimesh\")\n",
    "import os\n",
    "from time import time\n",
    "import glob\n",
    "# import trimesh\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, History\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, KFold\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "import json\n",
    "\n",
    "\n",
    "tf.random.set_seed(1234)\n",
    "print('\\nLoading/Installing Package => End\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "########################################################################\n",
      "Checking the running platforms\n",
      "\n",
      "Python version: 3.11.5\n",
      "OS: Windows\n",
      "OS version: 10\n",
      "running on Colab: False\n",
      "Dataset Directory Path: G:\\My Drive\\Projects\\110_JetscapeMl\\hm.jetscapeml.data\\\n",
      "Simulation Results Path: G:\\My Drive\\Projects\\110_JetscapeMl\\hm.jetscapeml.data\\simulation_results\\\n",
      "Dataset Directory Path: G:\\My Drive\\Projects\\110_JetscapeMl\\hm.jetscapeml.data\\\n",
      "Simulation Directory Path: G:\\My Drive\\Projects\\110_JetscapeMl\\hm.jetscapeml.data\\simulation_results\\\n",
      "########################################################################\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('\\n########################################################################')\n",
    "print('Checking the running platforms\\n')\n",
    "\n",
    "# Call the function and retrieve the dataset_directory_path and simulation_directory_path\n",
    "dataset_directory_path, simulation_directory_path = set_directory_paths()\n",
    "\n",
    "# Access the dataset_directory_path and simulation_directory_path\n",
    "print(\"Dataset Directory Path:\", dataset_directory_path)\n",
    "print(\"Simulation Directory Path:\", simulation_directory_path)\n",
    "print('########################################################################\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "option --f not recognized\n",
      "Tokenized Arguments:\n",
      "\n",
      "Tokenized Values:\n",
      "y_class_label_items: ['MMAT', 'MLBT']\n",
      "alpha_s_items: [0.2, 0.3, 0.4]\n",
      "q0_items: [1.5, 2.0, 2.5]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Call the function and retrieve the tokenized parameters\n",
    "tokenized_arguments, tokenized_values = parse_parameters()\n",
    "\n",
    "# Access the tokenized arguments and values\n",
    "print(\"Tokenized Arguments:\")\n",
    "for argument in tokenized_arguments:\n",
    "    print(argument)\n",
    "\n",
    "print(\"\\nTokenized Values:\")\n",
    "for argument, value in tokenized_values.items():\n",
    "    print(f\"{argument}: {value}\")\n",
    "\n",
    "y_class_label_items=['MMAT','MLBT']\n",
    "alpha_s_items=[0.2 ,0.3 ,0.4]\n",
    "q0_items=[1.5 ,2.0 ,2.5]\n",
    "\n",
    "print(\"y_class_label_items:\",y_class_label_items)\n",
    "print(\"alpha_s_items:\",alpha_s_items)\n",
    "print(\"q0_items:\",q0_items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building required params for the loading the dataset file\n"
     ]
    }
   ],
   "source": [
    "print(\"Building required params for the loading the dataset file\")\n",
    "\n",
    "class_labels_str = '_'.join(y_class_label_items)\n",
    "alpha_s_items_str='_'.join(map(str, alpha_s_items))\n",
    "q0_items_str='_'.join(map(str, q0_items))\n",
    "total_size=9*1200000\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading dataset by size and getting just the first column\n",
    "# Function to load datasets of different sizes\n",
    "def get_dataset(size,filter_y_by_column_number=None):\n",
    "    dataset_file_name = f\"jet_ml_benchmark_config_01_to_09_alpha_{alpha_s_items_str}_q0_{q0_items_str}_{class_labels_str}_size_{size}_shuffled.pkl\"\n",
    "\n",
    "    dataset_file_name=simulation_directory_path+dataset_file_name\n",
    "    print(\"dataset_file_name:\",dataset_file_name)\n",
    "\n",
    "    dataset=load_dataset(dataset_file_name,has_test=False)\n",
    "    (dataset_x, dataset_y) = dataset\n",
    "    if filter_y_by_column_number !=None:\n",
    "        print('Extract the first column for binary classification')\n",
    "        dataset_y = dataset_y[:, filter_y_by_column_number]\n",
    "    print(\"dataset.x:\",type(dataset_x), dataset_x.size, dataset_x.shape)\n",
    "    print(\"dataset.y:\",type(dataset_y), dataset_y.size,dataset_y.shape)\n",
    "    return dataset_x, dataset_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "G:\\My Drive\\Projects\\110_JetscapeMl\\hm.jetscapeml.data\\simulation_results\\\n"
     ]
    }
   ],
   "source": [
    "# Sizes of datasets\n",
    "dataset_sizes = [1000]\n",
    "# dataset_sizes = [100000]\n",
    "# dataset_sizes = [1000000]\n",
    "# dataset_sizes = [1000, 10000]\n",
    "#dataset_sizes = [1000, 10000,100000]\n",
    "# dataset_sizes = [1000, 10000, 100000, 1000000]\n",
    "\n",
    "print(simulation_directory_path)\n",
    "simulation_path=f'{simulation_directory_path}jetml_pointnet_classification_eloss_{class_labels_str}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "G:\\My Drive\\Projects\\110_JetscapeMl\\hm.jetscapeml.data\\simulation_results\\jetml_pointnet_classification_eloss_MMAT_MLBT_size_1000\n",
      "dataset_file_name: G:\\My Drive\\Projects\\110_JetscapeMl\\hm.jetscapeml.data\\simulation_results\\jet_ml_benchmark_config_01_to_09_alpha_0.2_0.3_0.4_q0_1.5_2.0_2.5_MMAT_MLBT_size_1000_shuffled.pkl\n",
      "dataset.x: <class 'numpy.ndarray'> 1024000 (1000, 32, 32)\n",
      "dataset.y: <class 'numpy.ndarray'> 3000 (1000, 3)\n",
      "dataset.x: <class 'numpy.ndarray'> 1024000 (1000, 32, 32)\n",
      "dataset.y: <class 'numpy.ndarray'> 3000 (1000, 3)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "size=1000\n",
    "current_simulation_name=f'_size_{size}'\n",
    "current_simulation_path=simulation_path+current_simulation_name\n",
    "print(current_simulation_path)\n",
    "# Generate dataset\n",
    "# x, y = get_dataset(size)\n",
    "(dataset_x, dataset_y)= get_dataset(size)\n",
    "len(dataset_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32, 32)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_x.shape\n",
    "dataset_x[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['MLBT', '0.4', '2.5'], dtype='<U32')"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 480x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.matshow(dataset_x[0])\n",
    "dataset_y[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = \\\n",
    "        train_test_split(dataset_x, dataset_y, test_size=0.2, random_state=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.]])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_0_categorical = np.array(y_train[:,0]).reshape(-1, 1)\n",
    "y_test_0_categorical = np.array(y_test[:,0]).reshape(-1, 1)\n",
    "\n",
    "encoder = OneHotEncoder(sparse_output=False)\n",
    "y_train_0_categorical_encoded = encoder.fit_transform(y_train_0_categorical)\n",
    "y_test_0_categorical_encoded = encoder.transform(y_test_0_categorical)\n",
    "y_test_0_categorical_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "\n",
    "# Assuming 'input_shape' is the shape of each input in dataset.x (e.g., (32, 32))\n",
    "input_shape=(32,32)\n",
    "# Define the model for eloss prediction\n",
    "eloss_model = models.Sequential([\n",
    "    layers.Flatten(input_shape=input_shape),\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.Dense(32, activation='relu'),\n",
    "    layers.Dense(2, activation='softmax')  # Assuming two classes: 'MMAT' and 'MLBT'\n",
    "])\n",
    "\n",
    "# Compile the eloss model\n",
    "eloss_model.compile(optimizer='adam',\n",
    "                    loss='sparse_categorical_crossentropy',\n",
    "                    metrics=['accuracy'])\n",
    "\n",
    "# Train the eloss model using dataset.x and the first column of dataset.y\n",
    "\n",
    "# Repeat the same process for alpha_s prediction\n",
    "alpha_s_model = models.Sequential([\n",
    "    layers.Flatten(input_shape=input_shape),\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.Dense(32, activation='relu'),\n",
    "    layers.Dense(3, activation='softmax')  # Assuming three classes: 0.2, 0.3, 0.4\n",
    "])\n",
    "\n",
    "alpha_s_model.compile(optimizer='adam',\n",
    "                      loss='sparse_categorical_crossentropy',\n",
    "                      metrics=['accuracy'])\n",
    "\n",
    "# Train the alpha_s model using dataset.x and the second column of dataset.y\n",
    "\n",
    "# Repeat for the third column\n",
    "q_0_model = models.Sequential([\n",
    "    layers.Flatten(input_shape=input_shape),\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.Dense(32, activation='relu'),\n",
    "    layers.Dense(4, activation='softmax')  # Assuming four classes for the third column\n",
    "])\n",
    "\n",
    "q_0_model.compile(optimizer='adam',\n",
    "                           loss='sparse_categorical_crossentropy',\n",
    "                           metrics=['accuracy'])\n",
    "\n",
    "# Train the third column model using dataset.x and the third column of dataset.y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "11/25 [============>.................] - ETA: 0s"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Unexpected result of `train_function` (Empty logs). This could be due to issues in input pipeline that resulted in an empty dataset. Otherwise, please use `Model.compile(..., run_eagerly=True)`, or `tf.config.run_functions_eagerly(True)` for more information of where went wrong, or file a issue/bug to `tf.keras`.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[52], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Assuming you have split your data into training and testing sets (X_train, X_test, y_train, y_test)\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Train eloss model\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m eloss_model\u001b[38;5;241m.\u001b[39mfit(x_train, y_train[:, \u001b[38;5;241m0\u001b[39m], epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m)\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\training.py:1819\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1817\u001b[0m logs \u001b[38;5;241m=\u001b[39m tf_utils\u001b[38;5;241m.\u001b[39msync_to_numpy_or_python_type(logs)\n\u001b[0;32m   1818\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m logs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1819\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1820\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnexpected result of `train_function` \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1821\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(Empty logs). This could be due to issues in input \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1822\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpipeline that resulted in an empty dataset. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1823\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOtherwise, please use \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1824\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`Model.compile(..., run_eagerly=True)`, or \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1825\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`tf.config.run_functions_eagerly(True)` for more \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1826\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minformation of where went wrong, or file a \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1827\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124missue/bug to `tf.keras`.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1828\u001b[0m     )\n\u001b[0;32m   1829\u001b[0m \u001b[38;5;66;03m# Override with model metrics instead of last step logs\u001b[39;00m\n\u001b[0;32m   1830\u001b[0m logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_and_get_metrics_result(logs)\n",
      "\u001b[1;31mValueError\u001b[0m: Unexpected result of `train_function` (Empty logs). This could be due to issues in input pipeline that resulted in an empty dataset. Otherwise, please use `Model.compile(..., run_eagerly=True)`, or `tf.config.run_functions_eagerly(True)` for more information of where went wrong, or file a issue/bug to `tf.keras`."
     ]
    }
   ],
   "source": [
    "# Assuming you have split your data into training and testing sets (X_train, X_test, y_train, y_test)\n",
    "\n",
    "# Train eloss model\n",
    "eloss_model.fit(x_train, y_train[:, 0], epochs=10)\n",
    "# eloss_model.fit(x_train, y_train[:, 0], epochs=10, batch_size=32, validation_data=(x_test, y_test[:, 0]))\n",
    "\n",
    "# # Train alpha_s model\n",
    "# alpha_s_model.fit(x_train, y_train[:, 1], epochs=10, batch_size=32, validation_data=(x_test, y_test[:, 1]))\n",
    "\n",
    "# # Train q_0 model\n",
    "# q_0_model.fit(x_train, y_train[:, 2], epochs=10, batch_size=32, validation_data=(x_test, y_test[:, 2]))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
